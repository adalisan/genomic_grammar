{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Only Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import types as python_types\n",
    "import warnings\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.engine.base_layer import Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import Bio.motifs\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import scipy\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('/home/jtao/analysis/genomic_grammar_analysis/'):\n",
    "    os.mkdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "os.chdir('/home/jtao/analysis/genomic_grammar_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequences_to_array(sequences):\n",
    "    '''\n",
    "    inputs: sequence of nucleotides represented as a string composed of A, C, G, T\n",
    "    outputs: a list of numpy array representations of a sequence with:\n",
    "             A = [1, 0, 0, 0]\n",
    "             C = [0, 1, 0, 0]\n",
    "             G = [0, 0, 1, 0]\n",
    "             T = [0, 0, 0, 1]\n",
    "             \n",
    "    '''\n",
    "\n",
    "    nucleotide_array_dict = {'A': [1, 0, 0, 0],\n",
    "                             'C': [0, 1, 0, 0],\n",
    "                             'G': [0, 0, 1, 0],\n",
    "                             'T': [0, 0, 0, 1],\n",
    "                             'N': [0.25,0.25,0.25,0.25]}\n",
    "\n",
    "    sequence_array_list = []\n",
    "    for seq in sequences:\n",
    "        seq_array = []\n",
    "        for nuc in seq:\n",
    "            seq_array.append(nucleotide_array_dict[nuc])\n",
    "        seq_array = np.array(seq_array, dtype=np.float16)\n",
    "        sequence_array_list.append(seq_array)\n",
    "    sequence_array_list = np.array(sequence_array_list,dtype=np.float16)\n",
    "    return sequence_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize_df(df_input):\n",
    "    df = df_input.copy()\n",
    "    #compute rank\n",
    "    dic = {}\n",
    "    for col in df:\n",
    "        dic.update({col : sorted(df[col])})\n",
    "    sorted_df = pd.DataFrame(dic)\n",
    "    rank = sorted_df.mean(axis = 1).tolist()\n",
    "    #sort\n",
    "    for col in df:\n",
    "        t = np.searchsorted(np.sort(df[col]), df[col])\n",
    "        df[col] = [rank[i] for i in t]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_multiply (x,y):\n",
    "    x_shape = []\n",
    "    for i, s in zip(K.int_shape(x), tf.unstack(tf.shape(x))):\n",
    "        if i is not None:\n",
    "            x_shape.append(i)\n",
    "        else:\n",
    "            x_shape.append(s)\n",
    "    x_shape = tuple(x_shape)\n",
    "    y_shape = []\n",
    "    for i, s in zip(K.int_shape(y), tf.unstack(tf.shape(y))):\n",
    "        if i is not None:\n",
    "            y_shape.append(i)\n",
    "        else:\n",
    "            y_shape.append(s)\n",
    "    y_shape = tuple(y_shape)\n",
    "\n",
    "    xt = tf.reshape(x, [-1, x_shape[-1],1])\n",
    "    yt = tf.reshape(y, [y_shape[-2],1])\n",
    "\n",
    "    return tf.multiply(xt,yt)\n",
    "\n",
    "class Projection(Layer):\n",
    "    \"\"\"\n",
    "    Learn linear transform of imput tensor\n",
    "    \"\"\"\n",
    "    def __init__(self, units,\n",
    "                 activation=None,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(Projection, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        output = element_multiply(inputs, self.kernel)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_dotProductAttention_model(total_seq_length,\n",
    "    seq_size=150,\n",
    "    num_motifs=32, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "    #print('forward_motif_scores', forward_motif_scores.get_shape())\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "    #print('cropped_fwd_scores', cropped_fwd_scores.get_shape())\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "    #print('flipped_rev_scores', flipped_rev_scores.get_shape())\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "    #print('concatenated_motif_scores', concatenated_motif_scores.get_shape())\n",
    "\n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(concatenated_motif_scores)\n",
    "    #print('pooled_scores', pooled_scores.get_shape())\n",
    "        \n",
    "    ### compute attention ###\n",
    "    ### weight queries ###\n",
    "    query_transformer = TimeDistributed(Projection(units=1), \n",
    "                                        input_shape=(int(seq_size/adjacent_bp_pool_size), num_motifs*2),\n",
    "                                        name='query_transformer'\n",
    "                                       )\n",
    "    weighted_queries = query_transformer(pooled_scores)\n",
    "#     print('weighted_queries', weighted_queries.shape)\n",
    "    \n",
    "    ### weight keys ###\n",
    "    key_transformer = TimeDistributed(Projection(units=1), \n",
    "                                      input_shape=(int(seq_size/adjacent_bp_pool_size), num_motifs*2),\n",
    "                                      name = 'key_transformer')\n",
    "    weighted_keys = key_transformer(pooled_scores)\n",
    "#     print('weighted_keys', weighted_keys.shape)\n",
    "    \n",
    "    dot_product = Dot(axes=(2,2),name='dot_product')\n",
    "    attention_weights = dot_product([weighted_queries, weighted_keys])\n",
    "    #print('attention_weights', attention_weights.shape)\n",
    "    \n",
    "    scaling_layer = Lambda(lambda x: x/(int(attention_weights.shape[1])**-2),\n",
    "        name='scaling_layer')\n",
    "    scaled_attention_weights = scaling_layer(attention_weights)\n",
    "    \n",
    "\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(scaled_attention_weights)\n",
    "    #print('attention_softmax_layer_out',attention_softmax_layer_out.shape)\n",
    "    \n",
    "    ### weight values ###\n",
    "    value_transformer = TimeDistributed(Projection(units=1), \n",
    "                                        input_shape=(int(seq_size/adjacent_bp_pool_size), num_motifs*2),\n",
    "                                        name='value_transformer'\n",
    "                                       )\n",
    "    \n",
    "    weighted_values = value_transformer(pooled_scores)\n",
    "\n",
    "#     print('weighted_values', weighted_values.shape)\n",
    "    \n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, weighted_values])\n",
    "#     print('atteneded_states', attended_states.shape)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "    dense_output = dense_layer(attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_seqRecords = list(SeqIO.parse('./peak_sequences/c57bl6_kla-1h_peaks.fasta', 'fasta'))\n",
    "negative_seqRecords = list(SeqIO.parse('./background_files/c57bl6_kla-1h_background.fasta', 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "    [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dotProductAttention_model = get_dotProductAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(dotProductAttention_model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fwd (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rev (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convolution_layer (Conv1D)      (None, 200, 100)     4100        input_fwd[0][0]                  \n",
      "                                                                 input_rev[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "crop_layer (Cropping1D)         (None, 150, 100)     0           convolution_layer[0][0]          \n",
      "                                                                 convolution_layer[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flip_layer (Lambda)             (None, 150, 100)     0           crop_layer[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_layer (Concatenate) (None, 150, 200)     0           crop_layer[0][0]                 \n",
      "                                                                 flip_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer (MaxPool (None, 15, 200)      0           concatenate_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "query_transformer (TimeDistribu (None, 15, 200)      200         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "key_transformer (TimeDistribute (None, 15, 200)      200         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 15, 15)       0           query_transformer[0][0]          \n",
      "                                                                 key_transformer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scaling_layer (Lambda)          (None, 15, 15)       0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_softmax_layer (Softma (None, 15, 15)       0           scaling_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "value_transformer (TimeDistribu (None, 15, 200)      200         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "attending_layer (Dot)           (None, 15, 200)      0           attention_softmax_layer[0][0]    \n",
      "                                                                 value_transformer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 15, 32)       6432        attending_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_dropout (Dropout)         (None, 15, 32)       0           dense_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 480)          0           dense_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            962         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,094\n",
      "Trainable params: 12,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12094"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotProductAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n",
      "34841/34841 [==============================] - 48s 1ms/step - loss: 0.6812 - acc: 0.5482 - val_loss: 0.6448 - val_acc: 0.6305\n",
      "Epoch 2/10\n",
      "34841/34841 [==============================] - 15s 427us/step - loss: 0.6167 - acc: 0.6550 - val_loss: 0.5991 - val_acc: 0.6838\n",
      "Epoch 3/10\n",
      "34841/34841 [==============================] - 15s 425us/step - loss: 0.5496 - acc: 0.7202 - val_loss: 0.5393 - val_acc: 0.7216\n",
      "Epoch 4/10\n",
      "34841/34841 [==============================] - 15s 424us/step - loss: 0.5010 - acc: 0.7562 - val_loss: 0.4862 - val_acc: 0.7628\n",
      "Epoch 5/10\n",
      "34841/34841 [==============================] - 15s 425us/step - loss: 0.4648 - acc: 0.7820 - val_loss: 0.4626 - val_acc: 0.7784\n",
      "Epoch 6/10\n",
      "34841/34841 [==============================] - 15s 428us/step - loss: 0.4368 - acc: 0.7988 - val_loss: 0.4438 - val_acc: 0.7923\n",
      "Epoch 7/10\n",
      "34841/34841 [==============================] - 15s 426us/step - loss: 0.4152 - acc: 0.8115 - val_loss: 0.4297 - val_acc: 0.8011\n",
      "Epoch 8/10\n",
      "34841/34841 [==============================] - 15s 426us/step - loss: 0.4005 - acc: 0.8194 - val_loss: 0.4189 - val_acc: 0.8081\n",
      "Epoch 9/10\n",
      "34841/34841 [==============================] - 15s 428us/step - loss: 0.3831 - acc: 0.8291 - val_loss: 0.4171 - val_acc: 0.8075\n",
      "Epoch 10/10\n",
      "34841/34841 [==============================] - 15s 426us/step - loss: 0.3739 - acc: 0.8367 - val_loss: 0.4375 - val_acc: 0.8013\n",
      "0.8901984925084483 0.948377581120944 0.8020893123842054\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = dotProductAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = dotProductAttention_model.evaluate([x_test, x_rc_test], y_test, verbose=0)[1]\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
