{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the size of convolution kernels affect classifier performance? (Assuming parameter count is the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import Bio.motifs\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import scipy\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir('/home/jtao/analysis/genomic_grammar_analysis/'):\n",
    "#     os.mkdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "# os.chdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "working_directory = '/home/jtao/analysis/genomic_grammar_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different k-mer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c57bl6_kla-1h_peaks.fasta\n"
     ]
    }
   ],
   "source": [
    "all_rocs = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "k_list = []\n",
    "all_treatments = []\n",
    "for ps in ['c57bl6_kla-1h_peaks.fasta', 'c57bl6_veh_peaks.fasta', 'c57bl6_il4-24h_peaks.fasta']:\n",
    "    print(ps)\n",
    "    positive_seqRecords = list(SeqIO.parse(working_directory + '/peak_sequences/' + ps, 'fasta'))\n",
    "    negative_seqRecords = list(SeqIO.parse(working_directory + '/background_files/' + ps.replace('_peaks', '_background'), 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "    fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "    fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "        [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "    sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "    sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "    labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "    num_classes = 2\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    for k in range(2,25):\n",
    "        max_kmers = 4**k\n",
    "        param_count=0\n",
    "        kmers_to_use = 0\n",
    "        while param_count <= 1552 - (4*k+1):\n",
    "            kmers_to_use +=1\n",
    "            param_count += (4*k+1)\n",
    "        kmers_to_use = min(kmers_to_use, max_kmers)\n",
    "\n",
    "        current_model = get_convolution_model(\n",
    "            200,\n",
    "            'classification',\n",
    "            num_classes = 2,\n",
    "            num_motifs = kmers_to_use,\n",
    "            motif_size = k,\n",
    "            num_dense_neurons = 32, \n",
    "            dropout_rate = 0.5)\n",
    "\n",
    "        current_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "        probs = current_model.predict([x_test, x_rc_test])\n",
    "\n",
    "        roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "        precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "        acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "        treatment = ps.split('_')[1]\n",
    "        \n",
    "        print(treatment, k, max_kmers, kmers_to_use, param_count)\n",
    "        print(roc, precision, acc)\n",
    "\n",
    "        all_rocs.append(roc)\n",
    "        all_accuracies.append(acc)\n",
    "        all_precisions.append(precision)\n",
    "        k_list.append(k)\n",
    "        all_treatments.append(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'aucROC':all_rocs, \n",
    "                      'Accuracy':all_accuracies, \n",
    "                      'K':k_list, \n",
    "                      'Precision':all_precisions,\n",
    "                      'Treatment':all_treatments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(data = frame, x='K', y='aucROC', hue = 'Treatment', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(data = frame, x='K', y='Precision', hue = 'Treatment', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(data = frame, x='K', y='Accuracy', hue = 'Treatment', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different motif counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rocs = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "m_list = []\n",
    "all_treatments = []\n",
    "for ps in ['c57bl6_kla-1h_peaks.fasta', 'c57bl6_veh_peaks.fasta', 'c57bl6_il4-24h_peaks.fasta']:\n",
    "    print(ps)\n",
    "    positive_seqRecords = list(SeqIO.parse(working_directory + '/peak_sequences/' + ps, 'fasta'))\n",
    "    negative_seqRecords = list(SeqIO.parse(working_directory + '/background_files/' + ps.replace('_peaks', '_background'), 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "    fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "    fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "        [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "    sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "    sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "    labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "    num_classes = 2\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    for m in range(25,250, 25):\n",
    "        current_model = get_convolution_model(\n",
    "            200,\n",
    "            'classification',\n",
    "            num_classes = 2,\n",
    "            num_motifs = m,\n",
    "            motif_size = 10,\n",
    "            num_dense_neurons = 32, \n",
    "            dropout_rate = 0.5)\n",
    "        \n",
    "        current_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "        probs = current_model.predict([x_test, x_rc_test])\n",
    "\n",
    "        roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "        precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "        acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "        treatment = ps.split('_')[1]\n",
    "        \n",
    "        print(treatment, m, current_model.count_params())\n",
    "        print(roc, precision, acc)\n",
    "\n",
    "        all_rocs.append(roc)\n",
    "        all_accuracies.append(acc)\n",
    "        all_precisions.append(precision)\n",
    "        m_list.append(m)\n",
    "        all_treatments.append(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'aucROC':all_rocs, \n",
    "                      'Accuracy':all_accuracies, \n",
    "                      'm':m_list, \n",
    "                      'Precision':all_precisions,\n",
    "                      'Treatment':all_treatments})\n",
    "\n",
    "sns.factorplot(data = frame, x='m', y='aucROC', hue = 'Treatment', size=10)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "sns.factorplot(data = frame, x='m', y='Precision', hue = 'Treatment', size=10)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "\n",
    "sns.factorplot(data = frame, x='m', y='Accuracy', hue = 'Treatment', size=10)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Only Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_model(\n",
    "    total_seq_length=200,\n",
    "    seq_size = 150,\n",
    "    num_classes = 2,\n",
    "    neurons_per_layer=32\n",
    "    motif_size = 20,\n",
    "    num_dense_neurons = 25, \n",
    "    dropout_rate = 0.25\n",
    "    ):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    # find motifs\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "\n",
    "    # crop motif scores to avoid parts of sequence where motif score is computed in only one direction\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "\n",
    "    # calculate max scores for each orientation\n",
    "    seq_pool_layer = MaxPool1D(pool_size=seq_size)\n",
    "    max_fwd_scores = seq_pool_layer(cropped_fwd_scores)\n",
    "    max_rev_scores = seq_pool_layer(cropped_rev_scores)\n",
    "\n",
    "    # calculate max score for strand\n",
    "    orientation_max_layer = Maximum()\n",
    "    max_seq_scores = orientation_max_layer([max_fwd_scores, max_rev_scores])\n",
    "\n",
    "    # fully connected layer\n",
    "    dense_out = Dense(num_dense_neurons, activation='relu', \n",
    "                     )(max_seq_scores)\n",
    "\n",
    "    # drop out\n",
    "    drop_out = Dropout(0.25)(dense_out)\n",
    "\n",
    "    # make prediction\n",
    "    flattened = Flatten()(drop_out)\n",
    "    predictions = Dense(num_classes,\n",
    "                        activation = 'softmax', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    convolution_model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    return convolution_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ps in ['c57bl6_kla-1h_peaks.fasta', 'c57bl6_veh_peaks.fasta', 'c57bl6_il4-24h_peaks.fasta']:\n",
    "    print(ps)\n",
    "    positive_seqRecords = list(SeqIO.parse('./peak_sequences/' + ps, 'fasta'))\n",
    "    negative_seqRecords = list(SeqIO.parse('./background_files/' + ps.replace('_peaks', '_background'), 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "    fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "    fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "        [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "    sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "    sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "    labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "    num_classes = 2\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    \n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    dense_out_1 = Dense(32, activation='relu', \n",
    "                 )(input_fwd)\n",
    "    dense_out_2 = Dense(32, activation='relu', \n",
    "                 )(dense_out_1)\n",
    "    dense_out_3 = Dense(32, activation='relu', \n",
    "                 )(dense_out_2)\n",
    "    # drop out\n",
    "    drop_out = Dropout(0.5)(dense_out_3)\n",
    "\n",
    "    # make prediction\n",
    "    flattened = Flatten()(drop_out)\n",
    "    predictions = Dense(num_classes,\n",
    "                        activation = 'softmax', \n",
    "                       )(flattened)\n",
    "    \n",
    "    current_model = Model(inputs=[input_fwd], outputs=predictions)\n",
    "\n",
    "\n",
    "    current_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "    current_model.fit([x_train], y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=([x_test], y_test))\n",
    "\n",
    "    probs = current_model.predict([x_test])\n",
    "\n",
    "    roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "    precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "    acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "    treatment = ps.split('_')[1]\n",
    "\n",
    "    print(treatment )\n",
    "    print(roc, precision, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
