{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Only Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import Bio.motifs\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import scipy\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('/home/jtao/analysis/genomic_grammar_analysis/'):\n",
    "    os.mkdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "os.chdir('/home/jtao/analysis/genomic_grammar_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequences_to_array(sequences):\n",
    "    '''\n",
    "    inputs: sequence of nucleotides represented as a string composed of A, C, G, T\n",
    "    outputs: a list of numpy array representations of a sequence with:\n",
    "             A = [1, 0, 0, 0]\n",
    "             C = [0, 1, 0, 0]\n",
    "             G = [0, 0, 1, 0]\n",
    "             T = [0, 0, 0, 1]\n",
    "             \n",
    "    '''\n",
    "\n",
    "    nucleotide_array_dict = {'A': [1, 0, 0, 0],\n",
    "                             'C': [0, 1, 0, 0],\n",
    "                             'G': [0, 0, 1, 0],\n",
    "                             'T': [0, 0, 0, 1],\n",
    "                             'N': [0.25,0.25,0.25,0.25]}\n",
    "\n",
    "    sequence_array_list = []\n",
    "    for seq in sequences:\n",
    "        seq_array = []\n",
    "        for nuc in seq:\n",
    "            seq_array.append(nucleotide_array_dict[nuc])\n",
    "        seq_array = np.array(seq_array, dtype=np.float16)\n",
    "        sequence_array_list.append(seq_array)\n",
    "    sequence_array_list = np.array(sequence_array_list,dtype=np.float16)\n",
    "    return sequence_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize_df(df_input):\n",
    "    df = df_input.copy()\n",
    "    #compute rank\n",
    "    dic = {}\n",
    "    for col in df:\n",
    "        dic.update({col : sorted(df[col])})\n",
    "    sorted_df = pd.DataFrame(dic)\n",
    "    rank = sorted_df.mean(axis = 1).tolist()\n",
    "    #sort\n",
    "    for col in df:\n",
    "        t = np.searchsorted(np.sort(df[col]), df[col])\n",
    "        df[col] = [rank[i] for i in t]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_seqRecords = list(SeqIO.parse('./peak_sequences/c57bl6_kla-1h_peaks.fasta', 'fasta'))\n",
    "negative_seqRecords = list(SeqIO.parse('./background_files/c57bl6_kla-1h_background.fasta', 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "    [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additiveAttention_model(total_seq_length,\n",
    "                        seq_size=150,\n",
    "                        num_motifs=32, \n",
    "                        motif_size=10,\n",
    "                        adjacent_bp_pool_size=10,\n",
    "                        attention_dim=32,\n",
    "                        attention_hops=1,\n",
    "                        num_dense_neurons=32,\n",
    "                        dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "\n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(concatenated_motif_scores)\n",
    "    \n",
    "    ### normalize motif scores ###\n",
    "    motif_score_norm_layer = BatchNormalization(name='motif_score_norm_layer')\n",
    "    normed_pooled_scores = motif_score_norm_layer(pooled_scores)\n",
    "    \n",
    "    ### bidirectional LSTM ###\n",
    "    forward_lstm_layer = LSTM(units=int(seq_size/adjacent_bp_pool_size),\n",
    "        return_sequences=True,\n",
    "        input_shape = (int(seq_size/adjacent_bp_pool_size), 2*num_motifs),\n",
    "        name = 'forward_lstm_layer'\n",
    "        )\n",
    "    forward_hidden_states = forward_lstm_layer(normed_pooled_scores)\n",
    "\n",
    "    reverse_lstm_layer = LSTM(units=int(seq_size/adjacent_bp_pool_size),\n",
    "        return_sequences=True,\n",
    "        input_shape = (int(seq_size/adjacent_bp_pool_size), 2*num_motifs),\n",
    "        name = 'reverse_lstm_layer',\n",
    "        go_backwards=True,\n",
    "        )\n",
    "    reverse_hidden_states = reverse_lstm_layer(normed_pooled_scores)\n",
    "    \n",
    "    ### concatenate lstm hidden states ###\n",
    "    lstm_concatenate_layer = Concatenate(axis=2)\n",
    "    bilstm_hidden_states = lstm_concatenate_layer([forward_hidden_states, reverse_hidden_states])\n",
    "    \n",
    "    ### normalize lstm states ###\n",
    "    lstm_norm_layer = BatchNormalization(name='lstm_norm_layer')\n",
    "    normed_bilistm_hidden_states = lstm_norm_layer(bilstm_hidden_states)\n",
    "    \n",
    "    ### attention tanh layer ###\n",
    "    attention_tanh_layer = Dense(attention_dim,\n",
    "        activation='tanh',\n",
    "        use_bias=False,\n",
    "        name = 'attention_tanh_layer')\n",
    "    attention_tanh_layer_out = attention_tanh_layer(normed_bilistm_hidden_states)\n",
    "\n",
    "    ### outer layer ###\n",
    "    attention_outer_layer = Dense(attention_hops,\n",
    "        activation='linear',\n",
    "        use_bias=False,\n",
    "        name = 'attention_outer_layer')\n",
    "    attention_outer_layer_out = attention_outer_layer(attention_tanh_layer_out)\n",
    "\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(attention_outer_layer_out)\n",
    "\n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, normed_bilistm_hidden_states])\n",
    "    \n",
    "    ### normalize attended states ###\n",
    "    attention_norm_layer = BatchNormalization(name='attention_norm_layer')\n",
    "    normed_attended_states = attention_norm_layer(attended_states)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "    dense_output = dense_layer(normed_attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32149"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additiveAttention_model = get_additiveAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    attention_dim=1,\n",
    "    attention_hops=1,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.75\n",
    "    )\n",
    "additiveAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fwd (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rev (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convolution_layer (Conv1D)      (None, 200, 100)     4100        input_fwd[0][0]                  \n",
      "                                                                 input_rev[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "crop_layer (Cropping1D)         (None, 150, 100)     0           convolution_layer[0][0]          \n",
      "                                                                 convolution_layer[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flip_layer (Lambda)             (None, 150, 100)     0           crop_layer[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_layer (Concatenate) (None, 150, 200)     0           crop_layer[0][0]                 \n",
      "                                                                 flip_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer (MaxPool (None, 15, 200)      0           concatenate_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "motif_score_norm_layer (BatchNo (None, 15, 200)      800         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "forward_lstm_layer (LSTM)       (None, 15, 15)       12960       motif_score_norm_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reverse_lstm_layer (LSTM)       (None, 15, 15)       12960       motif_score_norm_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 15, 30)       0           forward_lstm_layer[0][0]         \n",
      "                                                                 reverse_lstm_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_norm_layer (BatchNormaliza (None, 15, 30)       120         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_tanh_layer (Dense)    (None, 15, 1)        30          lstm_norm_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_outer_layer (Dense)   (None, 15, 1)        1           attention_tanh_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attention_softmax_layer (Softma (None, 15, 1)        0           attention_outer_layer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attending_layer (Dot)           (None, 1, 30)        0           attention_softmax_layer[0][0]    \n",
      "                                                                 lstm_norm_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_norm_layer (BatchNorm (None, 1, 30)        120         attending_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 1, 32)        992         attention_norm_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_dropout (Dropout)         (None, 1, 32)        0           dense_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           dense_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            66          flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,149\n",
      "Trainable params: 31,629\n",
      "Non-trainable params: 520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "additiveAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "additiveAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = additiveAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dotProductAttention_model(total_seq_length,\n",
    "    seq_size=150,\n",
    "    num_motifs=32, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "    #print('forward_motif_scores', forward_motif_scores.get_shape())\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "    #print('cropped_fwd_scores', cropped_fwd_scores.get_shape())\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "    #print('flipped_rev_scores', flipped_rev_scores.get_shape())\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "    #print('concatenated_motif_scores', concatenated_motif_scores.get_shape())\n",
    "\n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(concatenated_motif_scores)\n",
    "    #print('pooled_scores', pooled_scores.get_shape())\n",
    "    \n",
    "    ### normalize motif scores ###\n",
    "    motif_score_norm_layer = BatchNormalization(name='motif_score_norm_layer')\n",
    "    normed_pooled_scores = motif_score_norm_layer(pooled_scores)\n",
    "    #print('normed_pooled_scores', normed_pooled_scores.shape)\n",
    "        \n",
    "    ### compute attention ###\n",
    "\n",
    "    # reshape motif scores\n",
    "    linear_projection_reshaper = Reshape((int(normed_pooled_scores.shape[1]), \n",
    "       int(normed_pooled_scores.shape[2]),1), name='linear_projection_reshaper')\n",
    "    \n",
    "    reshaped_normed_pooled_scores = linear_projection_reshaper(normed_pooled_scores)    \n",
    "    #print('reshaped_normed_pooled_scores', reshaped_normed_pooled_scores.shape)\n",
    "    \n",
    "    ### weight queries ###\n",
    "    query_transformer = Conv2D(filters=1, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='query_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_queries = query_transformer(reshaped_normed_pooled_scores)\n",
    "    #print('weighted_queries', weighted_queries.shape)\n",
    "    \n",
    "    ### weight keys ###\n",
    "    key_transformer = Conv2D(filters=1, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='key_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_keys = key_transformer(reshaped_normed_pooled_scores)\n",
    "    #print('weighted_keys', weighted_keys.shape)\n",
    "    \n",
    "    ### calculate unnormalized attention weights ###\n",
    "    dot_product_reshaper = Reshape((int(normed_pooled_scores.shape[1]), \n",
    "       int(normed_pooled_scores.shape[2])), name = 'dot_product_reshaper')\n",
    "    \n",
    "    reshaped_weighted_queries = dot_product_reshaper(weighted_queries)\n",
    "    reshaped_weighted_keys = dot_product_reshaper(weighted_keys)\n",
    "    #print('reshaped weighted queries and keys', reshaped_weighted_queries.shape, reshaped_weighted_keys.shape)\n",
    "    \n",
    "    dot_product = Dot(axes=(2,2),name='dot_product')\n",
    "    attention_weights = dot_product([reshaped_weighted_queries, reshaped_weighted_keys])\n",
    "    #print('attention_weights', attention_weights.shape)\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(attention_weights)\n",
    "    #print('attention_softmax_layer_out',attention_softmax_layer_out.shape)\n",
    "    \n",
    "    ### weight values ###\n",
    "    value_transformer = Conv2D(filters=1, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='value_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_values = value_transformer(reshaped_normed_pooled_scores)\n",
    "    weighted_values = Reshape((int(weighted_values.shape[1]), \n",
    "       int(weighted_values.shape[2])))(weighted_values)\n",
    "    #print('weighted_values', weighted_values.shape)\n",
    "    \n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, weighted_values])\n",
    "    #print('atteneded_states', attended_states.shape)\n",
    "    \n",
    "    ### normalize attended states ###\n",
    "#     attention_norm_layer = BatchNormalization(name='attention_norm_layer')\n",
    "#     normed_attended_states = attention_norm_layer(attended_states)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "#     dense_output = dense_layer(normed_attended_states)\n",
    "    dense_output = dense_layer(attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_motif_scores (?, 200, 100)\n",
      "cropped_fwd_scores (?, 150, 100)\n",
      "flipped_rev_scores (?, 150, 100)\n",
      "concatenated_motif_scores (?, 150, 200)\n",
      "pooled_scores (?, 15, 200)\n",
      "normed_pooled_scores (?, 15, 200)\n",
      "reshaped_normed_pooled_scores (?, 15, 200, 1)\n",
      "weighted_queries (?, 15, 200, 1)\n",
      "weighted_keys (?, 15, 200, 1)\n",
      "reshaped weighted queries and keys (?, 15, 200) (?, 15, 200)\n",
      "attention_weights (?, 15, 15)\n",
      "attention_softmax_layer_out (?, 15, 15)\n",
      "weighted_values (?, 15, 200)\n",
      "atteneded_states (?, 15, 200)\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model = get_dotProductAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(dotProductAttention_model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dotProductAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12300"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotProductAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n",
      "34841/34841 [==============================] - 24s 696us/step - loss: 0.6956 - acc: 0.5023 - val_loss: 0.6932 - val_acc: 0.5072\n",
      "Epoch 2/10\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.6928 - acc: 0.5093 - val_loss: 0.6927 - val_acc: 0.5154\n",
      "Epoch 3/10\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.6857 - acc: 0.5504 - val_loss: 0.6806 - val_acc: 0.5728\n",
      "Epoch 4/10\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.6584 - acc: 0.6128 - val_loss: 0.6794 - val_acc: 0.6072\n",
      "Epoch 5/10\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.6193 - acc: 0.6589 - val_loss: 0.6345 - val_acc: 0.6411\n",
      "Epoch 6/10\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.5161 - acc: 0.7442 - val_loss: 0.6959 - val_acc: 0.6533\n",
      "Epoch 7/10\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.4466 - acc: 0.7907 - val_loss: 0.4805 - val_acc: 0.7760\n",
      "Epoch 8/10\n",
      "34841/34841 [==============================] - 14s 409us/step - loss: 0.4161 - acc: 0.8085 - val_loss: 0.4131 - val_acc: 0.8106\n",
      "Epoch 9/10\n",
      "34841/34841 [==============================] - 14s 409us/step - loss: 0.3974 - acc: 0.8201 - val_loss: 0.5280 - val_acc: 0.7613\n",
      "Epoch 10/10\n",
      "34841/34841 [==============================] - 14s 408us/step - loss: 0.3805 - acc: 0.8274 - val_loss: 0.4205 - val_acc: 0.8136\n",
      "0.9018096359977403 0.875733035464954 0.8034668809551142\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = dotProductAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Pool Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c57bl6_kla-1h_peaks.fasta\n",
      "forward_motif_scores (?, 200, 100)\n",
      "cropped_fwd_scores (?, 150, 100)\n",
      "flipped_rev_scores (?, 150, 100)\n",
      "concatenated_motif_scores (?, 150, 200)\n",
      "pooled_scores (?, 150, 200)\n",
      "pooled_scores (?, 150, 200)\n",
      "reshaped_pooled_scores (?, 150, 200, 1)\n",
      "weighted_queries (?, 150, 200, 1)\n",
      "weighted_keys (?, 150, 200, 1)\n",
      "reshaped weighted queries and keys (?, 150, 200) (?, 150, 200)\n",
      "attention_weights (?, 150, 150)\n",
      "attention_softmax_layer_out (?, 150, 150)\n",
      "weighted_values (?, 150, 200)\n",
      "atteneded_states (?, 150, 200)\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n",
      "16896/34841 [=============>................] - ETA: 30s - loss: 0.6911 - acc: 0.5230"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-63cc46ac8ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m               validation_data=([x_test, x_rc_test], y_test))\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_rc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_rocs = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "p_list = []\n",
    "all_treatments = []\n",
    "for ps in ['c57bl6_kla-1h_peaks.fasta', 'c57bl6_veh_peaks.fasta', 'c57bl6_il4-24h_peaks.fasta']:\n",
    "    print(ps)\n",
    "    positive_seqRecords = list(SeqIO.parse('./peak_sequences/' + ps, 'fasta'))\n",
    "    negative_seqRecords = list(SeqIO.parse('./background_files/' + ps.replace('_peaks', '_background'), 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "    fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "    fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "        [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "    sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "    sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "    labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "    num_classes = 2\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    for p in range(1,20):\n",
    "\n",
    "        current_model = get_dotProductAttention_model(200,\n",
    "            seq_size=150,\n",
    "            num_motifs=100, \n",
    "            motif_size=10,\n",
    "            adjacent_bp_pool_size=p,\n",
    "            num_dense_neurons=32,\n",
    "            dropout_rate=0.5)\n",
    "\n",
    "#         current_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#                   optimizer=keras.optimizers.Adam(),\n",
    "#                   metrics=['accuracy'])\n",
    "        current_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "        probs = current_model.predict([x_test, x_rc_test])\n",
    "\n",
    "        roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "        precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "        acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "        treatment = ps.split('_')[1]\n",
    "        \n",
    "        print(treatment, m, current_model.count_params())\n",
    "        print(roc, precision, acc)\n",
    "\n",
    "        all_rocs.append(roc)\n",
    "        all_accuracies.append(acc)\n",
    "        all_precisions.append(precision)\n",
    "        p_list.append(p)\n",
    "        all_treatments.append(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'aucROC':all_rocs, \n",
    "                      'Accuracy':all_accuracies, \n",
    "                      'p':p_list, \n",
    "                      'Precision':all_precisions,\n",
    "                      'Treatment':all_treatments})\n",
    "\n",
    "sns.factorplot(data = frame, x='p', y='aucROC', hue = 'Treatment', size=10)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "sns.factorplot(data = frame, x='p', y='Precision', hue = 'Treatment', size=10)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "\n",
    "sns.factorplot(data = frame, x='p', y='Accuracy', hue = 'Treatment', size=10)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
