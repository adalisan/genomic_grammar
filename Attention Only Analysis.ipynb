{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Only Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import Bio.motifs\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import scipy\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('/home/jtao/analysis/genomic_grammar_analysis/'):\n",
    "    os.mkdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "os.chdir('/home/jtao/analysis/genomic_grammar_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequences_to_array(sequences):\n",
    "    '''\n",
    "    inputs: sequence of nucleotides represented as a string composed of A, C, G, T\n",
    "    outputs: a list of numpy array representations of a sequence with:\n",
    "             A = [1, 0, 0, 0]\n",
    "             C = [0, 1, 0, 0]\n",
    "             G = [0, 0, 1, 0]\n",
    "             T = [0, 0, 0, 1]\n",
    "             \n",
    "    '''\n",
    "\n",
    "    nucleotide_array_dict = {'A': [1, 0, 0, 0],\n",
    "                             'C': [0, 1, 0, 0],\n",
    "                             'G': [0, 0, 1, 0],\n",
    "                             'T': [0, 0, 0, 1],\n",
    "                             'N': [0.25,0.25,0.25,0.25]}\n",
    "\n",
    "    sequence_array_list = []\n",
    "    for seq in sequences:\n",
    "        seq_array = []\n",
    "        for nuc in seq:\n",
    "            seq_array.append(nucleotide_array_dict[nuc])\n",
    "        seq_array = np.array(seq_array, dtype=np.float16)\n",
    "        sequence_array_list.append(seq_array)\n",
    "    sequence_array_list = np.array(sequence_array_list,dtype=np.float16)\n",
    "    return sequence_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize_df(df_input):\n",
    "    df = df_input.copy()\n",
    "    #compute rank\n",
    "    dic = {}\n",
    "    for col in df:\n",
    "        dic.update({col : sorted(df[col])})\n",
    "    sorted_df = pd.DataFrame(dic)\n",
    "    rank = sorted_df.mean(axis = 1).tolist()\n",
    "    #sort\n",
    "    for col in df:\n",
    "        t = np.searchsorted(np.sort(df[col]), df[col])\n",
    "        df[col] = [rank[i] for i in t]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_seqRecords = list(SeqIO.parse('./peak_sequences/c57bl6_kla-1h_peaks.fasta', 'fasta'))\n",
    "negative_seqRecords = list(SeqIO.parse('./background_files/c57bl6_kla-1h_background.fasta', 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "    [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additiveAttention_model(total_seq_length,\n",
    "                        seq_size=150,\n",
    "                        num_motifs=32, \n",
    "                        motif_size=10,\n",
    "                        adjacent_bp_pool_size=10,\n",
    "                        attention_dim=32,\n",
    "                        attention_hops=1,\n",
    "                        num_dense_neurons=32,\n",
    "                        dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "\n",
    "    ### normalize motif scores ###\n",
    "    motif_score_norm_layer = BatchNormalization(name='motif_score_norm_layer')\n",
    "    normed_motif_scores = motif_score_norm_layer(concatenated_motif_scores)\n",
    "    \n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(normed_motif_scores)\n",
    "    \n",
    "\n",
    "    \n",
    "    ### bidirectional LSTM ###\n",
    "    forward_lstm_layer = LSTM(units=int(seq_size/adjacent_bp_pool_size),\n",
    "        return_sequences=True,\n",
    "        input_shape = (int(seq_size/adjacent_bp_pool_size), 2*num_motifs),\n",
    "        name = 'forward_lstm_layer'\n",
    "        )\n",
    "    forward_hidden_states = forward_lstm_layer(pooled_scores)\n",
    "\n",
    "    reverse_lstm_layer = LSTM(units=int(seq_size/adjacent_bp_pool_size),\n",
    "        return_sequences=True,\n",
    "        input_shape = (int(seq_size/adjacent_bp_pool_size), 2*num_motifs),\n",
    "        name = 'reverse_lstm_layer',\n",
    "        go_backwards=True,\n",
    "        )\n",
    "    reverse_hidden_states = reverse_lstm_layer(pooled_scores)\n",
    "    \n",
    "    ### concatenate lstm hidden states ###\n",
    "    lstm_concatenate_layer = Concatenate(axis=2)\n",
    "    bilstm_hidden_states = lstm_concatenate_layer([forward_hidden_states, reverse_hidden_states])\n",
    "    \n",
    "    ### normalize lstm states ###\n",
    "    lstm_norm_layer = BatchNormalization(name='lstm_norm_layer')\n",
    "    normed_bilistm_hidden_states = lstm_norm_layer(bilstm_hidden_states)\n",
    "    \n",
    "    ### attention tanh layer ###\n",
    "    attention_tanh_layer = Dense(attention_dim,\n",
    "        activation='tanh',\n",
    "        use_bias=False,\n",
    "        name = 'attention_tanh_layer')\n",
    "    attention_tanh_layer_out = attention_tanh_layer(normed_bilistm_hidden_states)\n",
    "\n",
    "    ### outer layer ###\n",
    "    attention_outer_layer = Dense(attention_hops,\n",
    "        activation='linear',\n",
    "        use_bias=False,\n",
    "        name = 'attention_outer_layer')\n",
    "    attention_outer_layer_out = attention_outer_layer(attention_tanh_layer_out)\n",
    "\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(attention_outer_layer_out)\n",
    "\n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, normed_bilistm_hidden_states])\n",
    "    \n",
    "    ### normalize attended states ###\n",
    "    attention_norm_layer = BatchNormalization(name='attention_norm_layer')\n",
    "    normed_attended_states = attention_norm_layer(attended_states)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "    dense_output = dense_layer(normed_attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32149"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additiveAttention_model = get_additiveAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    attention_dim=1,\n",
    "    attention_hops=1,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.75\n",
    "    )\n",
    "additiveAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiveAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "additiveAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = additiveAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dotProductAttention_model(total_seq_length,\n",
    "    seq_size=150,\n",
    "    num_motifs=32, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "    print('forward_motif_scores', forward_motif_scores.get_shape())\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "    print('cropped_fwd_scores', cropped_fwd_scores.get_shape())\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "    print('flipped_rev_scores', flipped_rev_scores.get_shape())\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "    print('concatenated_motif_scores', concatenated_motif_scores.get_shape())\n",
    "\n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(concatenated_motif_scores)\n",
    "    print('pooled_scores', pooled_scores.get_shape())\n",
    "    \n",
    "    ### normalize motif scores ###\n",
    "    motif_score_norm_layer = BatchNormalization(name='motif_score_norm_layer')\n",
    "    normed_pooled_scores = motif_score_norm_layer(pooled_scores)\n",
    "    print('normed_pooled_scores', normed_pooled_scores.shape)\n",
    "        \n",
    "    ### compute attention ###\n",
    "\n",
    "    # reshape motif scores\n",
    "    linear_projection_reshaper = Reshape((int(normed_pooled_scores.shape[1]), \n",
    "       int(normed_pooled_scores.shape[2]),1), name='linear_projection_reshaper')\n",
    "    \n",
    "    reshaped_normed_pooled_scores = linear_projection_reshaper(normed_pooled_scores)    \n",
    "    print('reshaped_normed_pooled_scores', reshaped_normed_pooled_scores.shape)\n",
    "    \n",
    "    ### weight queries ###\n",
    "    query_transformer = Conv2D(filters=1, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='query_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_queries = query_transformer(reshaped_normed_pooled_scores)\n",
    "    print('weighted_queries', weighted_queries.shape)\n",
    "    \n",
    "    ### weight keys ###\n",
    "    key_transformer = Conv2D(filters=1, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='key_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_keys = key_transformer(reshaped_normed_pooled_scores)\n",
    "    print('weighted_keys', weighted_keys.shape)\n",
    "    \n",
    "    ### calculate unnormalized attention weights ###\n",
    "    dot_product_reshaper = Reshape((int(normed_pooled_scores.shape[1]), \n",
    "       int(normed_pooled_scores.shape[2])), name = 'dot_product_reshaper')\n",
    "    \n",
    "    reshaped_weighted_queries = dot_product_reshaper(weighted_queries)\n",
    "    reshaped_weighted_keys = dot_product_reshaper(weighted_keys)\n",
    "    print('reshaped weighted queries and keys', reshaped_weighted_queries.shape, reshaped_weighted_keys.shape)\n",
    "    \n",
    "    dot_product = Dot(axes=(2,2),name='dot_product')\n",
    "    attention_weights = dot_product([reshaped_weighted_queries, reshaped_weighted_keys])\n",
    "    print('attention_weights', attention_weights.shape)\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(attention_weights)\n",
    "    print('attention_softmax_layer_out',attention_softmax_layer_out.shape)\n",
    "    \n",
    "    ### weight values ###\n",
    "    value_transformer = Conv2D(filters=1, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='value_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_values = value_transformer(reshaped_normed_pooled_scores)\n",
    "    weighted_values = Reshape((int(weighted_values.shape[1]), \n",
    "       int(weighted_values.shape[2])))(weighted_values)\n",
    "    print('weighted_values', weighted_values.shape)\n",
    "    \n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, weighted_values])\n",
    "    print('atteneded_states', attended_states.shape)\n",
    "    \n",
    "    ### normalize attended states ###\n",
    "#     attention_norm_layer = BatchNormalization(name='attention_norm_layer')\n",
    "#     normed_attended_states = attention_norm_layer(attended_states)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "#     dense_output = dense_layer(normed_attended_states)\n",
    "    dense_output = dense_layer(attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_motif_scores (?, 200, 100)\n",
      "cropped_fwd_scores (?, 150, 100)\n",
      "flipped_rev_scores (?, 150, 100)\n",
      "concatenated_motif_scores (?, 150, 200)\n",
      "pooled_scores (?, 75, 200)\n",
      "normed_pooled_scores (?, 75, 200)\n",
      "reshaped_normed_pooled_scores (?, 75, 200, 1)\n",
      "weighted_queries (?, 75, 200, 1)\n",
      "weighted_keys (?, 75, 200, 1)\n",
      "reshaped weighted queries and keys (?, 75, 200) (?, 75, 200)\n",
      "attention_weights (?, 75, 75)\n",
      "attention_softmax_layer_out (?, 75, 75)\n",
      "weighted_values (?, 75, 200)\n",
      "atteneded_states (?, 75, 200)\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model = get_dotProductAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=5,\n",
    "    adjacent_bp_pool_size=2,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14140"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotProductAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n",
      "34841/34841 [==============================] - 35s 1ms/step - loss: 0.6078 - acc: 0.6525 - val_loss: 0.5493 - val_acc: 0.7198\n",
      "Epoch 2/10\n",
      "34841/34841 [==============================] - 27s 761us/step - loss: 0.5254 - acc: 0.7383 - val_loss: 0.5109 - val_acc: 0.7511\n",
      "Epoch 3/10\n",
      "34841/34841 [==============================] - 26s 757us/step - loss: 0.4983 - acc: 0.7565 - val_loss: 0.5195 - val_acc: 0.7447\n",
      "Epoch 4/10\n",
      "34841/34841 [==============================] - 26s 753us/step - loss: 0.4799 - acc: 0.7700 - val_loss: 0.4864 - val_acc: 0.7619\n",
      "Epoch 5/10\n",
      "34841/34841 [==============================] - 26s 753us/step - loss: 0.4706 - acc: 0.7776 - val_loss: 0.5228 - val_acc: 0.7404\n",
      "Epoch 6/10\n",
      "34841/34841 [==============================] - 26s 758us/step - loss: 0.4605 - acc: 0.7833 - val_loss: 0.4635 - val_acc: 0.7804\n",
      "Epoch 7/10\n",
      "34841/34841 [==============================] - 26s 755us/step - loss: 0.4528 - acc: 0.7861 - val_loss: 0.4778 - val_acc: 0.7670\n",
      "Epoch 8/10\n",
      "34841/34841 [==============================] - 27s 766us/step - loss: 0.4481 - acc: 0.7920 - val_loss: 0.4695 - val_acc: 0.7760\n",
      "Epoch 9/10\n",
      "34841/34841 [==============================] - 27s 764us/step - loss: 0.4429 - acc: 0.7923 - val_loss: 0.4562 - val_acc: 0.7848\n",
      "Epoch 10/10\n",
      "34841/34841 [==============================] - 26s 760us/step - loss: 0.4380 - acc: 0.7930 - val_loss: 0.4968 - val_acc: 0.7588\n",
      "0.8626752102100756 0.8175513470258736 0.7676500975777752\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = dotProductAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
