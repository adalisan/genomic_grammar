{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Only Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import Bio.motifs\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import scipy\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('/home/jtao/analysis/genomic_grammar_analysis/'):\n",
    "    os.mkdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "os.chdir('/home/jtao/analysis/genomic_grammar_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequences_to_array(sequences):\n",
    "    '''\n",
    "    inputs: sequence of nucleotides represented as a string composed of A, C, G, T\n",
    "    outputs: a list of numpy array representations of a sequence with:\n",
    "             A = [1, 0, 0, 0]\n",
    "             C = [0, 1, 0, 0]\n",
    "             G = [0, 0, 1, 0]\n",
    "             T = [0, 0, 0, 1]\n",
    "             \n",
    "    '''\n",
    "\n",
    "    nucleotide_array_dict = {'A': [1, 0, 0, 0],\n",
    "                             'C': [0, 1, 0, 0],\n",
    "                             'G': [0, 0, 1, 0],\n",
    "                             'T': [0, 0, 0, 1],\n",
    "                             'N': [0.25,0.25,0.25,0.25]}\n",
    "\n",
    "    sequence_array_list = []\n",
    "    for seq in sequences:\n",
    "        seq_array = []\n",
    "        for nuc in seq:\n",
    "            seq_array.append(nucleotide_array_dict[nuc])\n",
    "        seq_array = np.array(seq_array, dtype=np.float16)\n",
    "        sequence_array_list.append(seq_array)\n",
    "    sequence_array_list = np.array(sequence_array_list,dtype=np.float16)\n",
    "    return sequence_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize_df(df_input):\n",
    "    df = df_input.copy()\n",
    "    #compute rank\n",
    "    dic = {}\n",
    "    for col in df:\n",
    "        dic.update({col : sorted(df[col])})\n",
    "    sorted_df = pd.DataFrame(dic)\n",
    "    rank = sorted_df.mean(axis = 1).tolist()\n",
    "    #sort\n",
    "    for col in df:\n",
    "        t = np.searchsorted(np.sort(df[col]), df[col])\n",
    "        df[col] = [rank[i] for i in t]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_seqRecords = list(SeqIO.parse('./peak_sequences/c57bl6_kla-1h_peaks.fasta', 'fasta'))\n",
    "negative_seqRecords = list(SeqIO.parse('./background_files/c57bl6_kla-1h_background.fasta', 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "    [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additiveAttention_model(total_seq_length,\n",
    "                        seq_size=150,\n",
    "                        num_motifs=32, \n",
    "                        motif_size=10,\n",
    "                        adjacent_bp_pool_size=10,\n",
    "                        attention_dim=32,\n",
    "                        attention_hops=1,\n",
    "                        num_dense_neurons=32,\n",
    "                        dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "\n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(concatenated_motif_scores)\n",
    "    \n",
    "    ### normalize motif scores ###\n",
    "    motif_score_norm_layer = BatchNormalization(name='motif_score_norm_layer')\n",
    "    normed_pooled_scores = motif_score_norm_layer(pooled_scores)\n",
    "    \n",
    "    ### bidirectional LSTM ###\n",
    "    forward_lstm_layer = LSTM(units=int(seq_size/adjacent_bp_pool_size),\n",
    "        return_sequences=True,\n",
    "        input_shape = (int(seq_size/adjacent_bp_pool_size), 2*num_motifs),\n",
    "        name = 'forward_lstm_layer'\n",
    "        )\n",
    "    forward_hidden_states = forward_lstm_layer(normed_pooled_scores)\n",
    "\n",
    "    reverse_lstm_layer = LSTM(units=int(seq_size/adjacent_bp_pool_size),\n",
    "        return_sequences=True,\n",
    "        input_shape = (int(seq_size/adjacent_bp_pool_size), 2*num_motifs),\n",
    "        name = 'reverse_lstm_layer',\n",
    "        go_backwards=True,\n",
    "        )\n",
    "    reverse_hidden_states = reverse_lstm_layer(normed_pooled_scores)\n",
    "    \n",
    "    ### concatenate lstm hidden states ###\n",
    "    lstm_concatenate_layer = Concatenate(axis=2)\n",
    "    bilstm_hidden_states = lstm_concatenate_layer([forward_hidden_states, reverse_hidden_states])\n",
    "    \n",
    "    ### normalize lstm states ###\n",
    "    lstm_norm_layer = BatchNormalization(name='lstm_norm_layer')\n",
    "    normed_bilistm_hidden_states = lstm_norm_layer(bilstm_hidden_states)\n",
    "    \n",
    "    ### attention tanh layer ###\n",
    "    attention_tanh_layer = Dense(attention_dim,\n",
    "        activation='tanh',\n",
    "        use_bias=False,\n",
    "        name = 'attention_tanh_layer')\n",
    "    attention_tanh_layer_out = attention_tanh_layer(normed_bilistm_hidden_states)\n",
    "\n",
    "    ### outer layer ###\n",
    "    attention_outer_layer = Dense(attention_hops,\n",
    "        activation='linear',\n",
    "        use_bias=False,\n",
    "        name = 'attention_outer_layer')\n",
    "    attention_outer_layer_out = attention_outer_layer(attention_tanh_layer_out)\n",
    "\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(attention_outer_layer_out)\n",
    "\n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, normed_bilistm_hidden_states])\n",
    "    \n",
    "    ### normalize attended states ###\n",
    "    attention_norm_layer = BatchNormalization(name='attention_norm_layer')\n",
    "    normed_attended_states = attention_norm_layer(attended_states)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "    dense_output = dense_layer(normed_attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32149"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additiveAttention_model = get_additiveAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    attention_dim=1,\n",
    "    attention_hops=1,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.75\n",
    "    )\n",
    "additiveAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiveAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n",
      "34841/34841 [==============================] - 21s 606us/step - loss: 0.6942 - acc: 0.5601 - val_loss: 0.6341 - val_acc: 0.6428\n",
      "Epoch 2/10\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.6013 - acc: 0.6847 - val_loss: 0.5370 - val_acc: 0.7306\n",
      "Epoch 3/10\n",
      "34841/34841 [==============================] - 16s 456us/step - loss: 0.5260 - acc: 0.7504 - val_loss: 0.5173 - val_acc: 0.7415\n",
      "Epoch 4/10\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.4747 - acc: 0.7843 - val_loss: 0.5112 - val_acc: 0.7449\n",
      "Epoch 5/10\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.4367 - acc: 0.8071 - val_loss: 0.4216 - val_acc: 0.8030\n",
      "Epoch 6/10\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.4096 - acc: 0.8247 - val_loss: 0.3986 - val_acc: 0.8178\n",
      "Epoch 7/10\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3859 - acc: 0.8351 - val_loss: 0.3971 - val_acc: 0.8226\n",
      "Epoch 8/10\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.3703 - acc: 0.8436 - val_loss: 0.3877 - val_acc: 0.8284\n",
      "Epoch 9/10\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3515 - acc: 0.8536 - val_loss: 0.3914 - val_acc: 0.8310\n",
      "Epoch 10/10\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3374 - acc: 0.8625 - val_loss: 0.4752 - val_acc: 0.7904\n",
      "0.9107940613445958 0.9036220472440945 0.7885432212145563\n"
     ]
    }
   ],
   "source": [
    "additiveAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = additiveAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dotProductAttention_model(total_seq_length,\n",
    "    seq_size=150,\n",
    "    num_motifs=32, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_heads=1,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5):\n",
    "    input_fwd = Input(shape=(total_seq_length,4), name='input_fwd')\n",
    "    input_rev = Input(shape=(total_seq_length,4), name='input_rev')\n",
    "\n",
    "    ### find motifs ###\n",
    "    convolution_layer = Conv1D(filters=num_motifs, \n",
    "        kernel_size=motif_size,\n",
    "        activation='relu',\n",
    "        input_shape=(total_seq_length,4),\n",
    "        name='convolution_layer',\n",
    "        padding = 'same'\n",
    "        )\n",
    "    forward_motif_scores = convolution_layer(input_fwd)\n",
    "    reverse_motif_scores = convolution_layer(input_rev)\n",
    "    print('forward_motif_scores', forward_motif_scores.get_shape())\n",
    "\n",
    "    ### crop motif scores to avoid parts of sequence where motif score is computed in only one direction ###\n",
    "    to_crop = int((total_seq_length - seq_size)/2)\n",
    "    crop_layer = Cropping1D(cropping=(to_crop, to_crop), \n",
    "        name='crop_layer')\n",
    "    cropped_fwd_scores = crop_layer(forward_motif_scores)\n",
    "    cropped_rev_scores = crop_layer(reverse_motif_scores)\n",
    "    print('cropped_fwd_scores', cropped_fwd_scores.get_shape())\n",
    "\n",
    "    ### flip motif scores ###\n",
    "    flip_layer = Lambda(lambda x: K.reverse(x,axes=0),\n",
    "        output_shape=(seq_size, num_motifs),\n",
    "        name='flip_layer')\n",
    "    flipped_rev_scores = flip_layer(cropped_rev_scores)\n",
    "    print('flipped_rev_scores', flipped_rev_scores.get_shape())\n",
    "\n",
    "    ### concatenate motif scores ###\n",
    "    concatenate_layer = keras.layers.Concatenate(axis=2, name='concatenate_layer')\n",
    "    concatenated_motif_scores = concatenate_layer([cropped_fwd_scores, flipped_rev_scores])\n",
    "    print('concatenated_motif_scores', concatenated_motif_scores.get_shape())\n",
    "\n",
    "    ### pool across length of sequence ###\n",
    "    sequence_pooling_layer = MaxPool1D(pool_size=adjacent_bp_pool_size, \n",
    "        strides=adjacent_bp_pool_size,\n",
    "        name='sequence_pooling_layer')\n",
    "    pooled_scores = sequence_pooling_layer(concatenated_motif_scores)\n",
    "    print('pooled_scores', pooled_scores.get_shape())\n",
    "    \n",
    "    ### normalize motif scores ###\n",
    "    motif_score_norm_layer = BatchNormalization(name='motif_score_norm_layer')\n",
    "    normed_pooled_scores = motif_score_norm_layer(pooled_scores)\n",
    "    print('normed_pooled_scores', normed_pooled_scores.shape)\n",
    "        \n",
    "    ### compute attention ###\n",
    "\n",
    "    # reshape motif scores\n",
    "    linear_projection_reshaper = Reshape((int(normed_pooled_scores.shape[1]), \n",
    "       int(normed_pooled_scores.shape[2]),1), name='linear_projection_reshaper')\n",
    "    \n",
    "    reshaped_normed_pooled_scores = linear_projection_reshaper(normed_pooled_scores)    \n",
    "    print('reshaped_normed_pooled_scores', reshaped_normed_pooled_scores.shape)\n",
    "    \n",
    "    ### weight queries ###\n",
    "    query_transformer = Conv2D(filters=num_heads, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='query_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_queries = query_transformer(reshaped_normed_pooled_scores)\n",
    "    print('weighted_queries', weighted_queries.shape)\n",
    "    \n",
    "    ### weight keys ###\n",
    "    key_transformer = Conv2D(filters=num_heads, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='key_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_keys = key_transformer(reshaped_normed_pooled_scores)\n",
    "    print('weighted_keys', weighted_keys.shape)\n",
    "    \n",
    "    ### calculate unnormalized attention weights ###\n",
    "    dot_product_reshaper = Reshape((int(normed_pooled_scores.shape[1]), \n",
    "       int(normed_pooled_scores.shape[2])), name = 'dot_product_reshaper')\n",
    "    \n",
    "    reshaped_weighted_queries = dot_product_reshaper(weighted_queries)\n",
    "    reshaped_weighted_keys = dot_product_reshaper(weighted_keys)\n",
    "    print('reshaped weighted queries and keys', reshaped_weighted_queries.shape, reshaped_weighted_keys.shape)\n",
    "    \n",
    "    dot_product = Dot(axes=(2,2),name='dot_product')\n",
    "    attention_weights = dot_product([reshaped_weighted_queries, reshaped_weighted_keys])\n",
    "    print('attention_weights', attention_weights.shape)\n",
    "    ### apply softmax ###\n",
    "    softmax_layer = Softmax(axis=1, name='attention_softmax_layer')\n",
    "    attention_softmax_layer_out = softmax_layer(attention_weights)\n",
    "    print('attention_softmax_layer_out',attention_softmax_layer_out.shape)\n",
    "    \n",
    "    ### weight values ###\n",
    "    value_transformer = Conv2D(filters=num_heads, \n",
    "        kernel_size=1,\n",
    "        activation='linear',\n",
    "        input_shape=(seq_size/adjacent_bp_pool_size,num_motifs*2),\n",
    "        name='value_transformer',\n",
    "        data_format='channels_last',\n",
    "        padding = 'same'\n",
    "    )\n",
    "    \n",
    "    weighted_values = value_transformer(reshaped_normed_pooled_scores)\n",
    "    weighted_values = Reshape((int(weighted_values.shape[1]), \n",
    "       int(weighted_values.shape[2])))(weighted_values)\n",
    "    print('weighted_values', weighted_values.shape)\n",
    "    \n",
    "    ### attend to hidden states ###\n",
    "    attending_layer = Dot(axes=(1,1),\n",
    "        name='attending_layer')\n",
    "    attended_states = attending_layer([attention_softmax_layer_out, weighted_values])\n",
    "    print('atteneded_states', attended_states.shape)\n",
    "    \n",
    "    ### normalize attended states ###\n",
    "#     attention_norm_layer = BatchNormalization(name='attention_norm_layer')\n",
    "#     normed_attended_states = attention_norm_layer(attended_states)\n",
    "    \n",
    "    ### fully connected layer ###\n",
    "    dense_layer = Dense(num_dense_neurons, \n",
    "        activation='relu', \n",
    "        name = 'dense_layer'\n",
    "        )\n",
    "\n",
    "#     dense_output = dense_layer(normed_attended_states)\n",
    "    dense_output = dense_layer(attended_states)\n",
    "    \n",
    "    # drop out\n",
    "    drop_out = Dropout(dropout_rate,name='dense_dropout')(dense_output)\n",
    "    \n",
    "    # make prediction\n",
    "    flattened = Flatten(name='flatten')(drop_out)\n",
    "    \n",
    "    predictions = Dense(num_classes,\n",
    "                        name='predictions',\n",
    "                        activation = 'sigmoid', \n",
    "                       )(flattened)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = Model(inputs=[input_fwd, input_rev], outputs=predictions)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_motif_scores (?, 200, 100)\n",
      "cropped_fwd_scores (?, 150, 100)\n",
      "flipped_rev_scores (?, 150, 100)\n",
      "concatenated_motif_scores (?, 150, 200)\n",
      "pooled_scores (?, 15, 200)\n",
      "normed_pooled_scores (?, 15, 200)\n",
      "reshaped_normed_pooled_scores (?, 15, 200, 1)\n",
      "weighted_queries (?, 15, 200, 2)\n",
      "weighted_keys (?, 15, 200, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-942c2d34143f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_dense_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     dropout_rate=0.5)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-226-6489ae44c5c1>\u001b[0m in \u001b[0;36mget_dotProductAttention_model\u001b[0;34m(total_seq_length, seq_size, num_motifs, motif_size, adjacent_bp_pool_size, num_heads, num_dense_neurons, dropout_rate)\u001b[0m\n\u001b[1;32m     93\u001b[0m        int(normed_pooled_scores.shape[2])), name = 'dot_product_reshaper')\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mreshaped_weighted_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_reshaper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mreshaped_weighted_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_reshaper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reshaped weighted queries and keys'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_weighted_queries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_weighted_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             if all([s is not None\n\u001b[1;32m    479\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# input shape known? then we can compute the output shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             return (input_shape[0],) + self._fix_unknown_dimension(\n\u001b[0;32m--> 404\u001b[0;31m                 input_shape[1:], self.target_shape)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model = get_dotProductAttention_model(200,\n",
    "    seq_size=150,\n",
    "    num_motifs=100, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    num_heads=2,\n",
    "    num_dense_neurons=32,\n",
    "    dropout_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotProductAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/10\n",
      " 6016/34841 [====>.........................] - ETA: 1:12 - loss: 0.7005 - acc: 0.4935"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-744cf89a8e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m               validation_data=([x_test, x_rc_test], y_test))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdotProductAttention_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_rc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = dotProductAttention_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "acc = sklearn.metrics.accuracy_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
