{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Only Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import Bio.motifs\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import scipy\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir('/home/jtao/analysis/genomic_grammar_analysis/'):\n",
    "#     os.mkdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "# os.chdir('/home/jtao/analysis/genomic_grammar_analysis')\n",
    "working_directory = '/home/jtao/analysis/genomic_grammar_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequences_to_array(sequences):\n",
    "    '''\n",
    "    inputs: sequence of nucleotides represented as a string composed of A, C, G, T\n",
    "    outputs: a list of numpy array representations of a sequence with:\n",
    "             A = [1, 0, 0, 0]\n",
    "             C = [0, 1, 0, 0]\n",
    "             G = [0, 0, 1, 0]\n",
    "             T = [0, 0, 0, 1]\n",
    "             \n",
    "    '''\n",
    "\n",
    "    nucleotide_array_dict = {'A': [1, 0, 0, 0],\n",
    "                             'C': [0, 1, 0, 0],\n",
    "                             'G': [0, 0, 1, 0],\n",
    "                             'T': [0, 0, 0, 1],\n",
    "                             'N': [0.25,0.25,0.25,0.25]}\n",
    "\n",
    "    sequence_array_list = []\n",
    "    for seq in sequences:\n",
    "        seq_array = []\n",
    "        for nuc in seq:\n",
    "            seq_array.append(nucleotide_array_dict[nuc])\n",
    "        seq_array = np.array(seq_array, dtype=np.float16)\n",
    "        sequence_array_list.append(seq_array)\n",
    "    sequence_array_list = np.array(sequence_array_list,dtype=np.float16)\n",
    "    return sequence_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize_df(df_input):\n",
    "    df = df_input.copy()\n",
    "    #compute rank\n",
    "    dic = {}\n",
    "    for col in df:\n",
    "        dic.update({col : sorted(df[col])})\n",
    "    sorted_df = pd.DataFrame(dic)\n",
    "    rank = sorted_df.mean(axis = 1).tolist()\n",
    "    #sort\n",
    "    for col in df:\n",
    "        t = np.searchsorted(np.sort(df[col]), df[col])\n",
    "        df[col] = [rank[i] for i in t]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_seqRecords = list(SeqIO.parse(working_directory + '/peak_sequences/c57bl6_kla-1h_peaks.fasta', 'fasta'))\n",
    "# negative_seqRecords = list(SeqIO.parse(working_directory + '/background_files/c57bl6_kla-1h_background.fasta', 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "positive_seqRecords = list(SeqIO.parse(working_directory + '/peak_sequences/c57bl6_il4-24h_peaks.fasta', 'fasta'))\n",
    "negative_seqRecords = list(SeqIO.parse(working_directory + './background_files/c57bl6_il4-24h_background.fasta', 'fasta'))[:len(positive_seqRecords)]\n",
    "fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "    [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10752"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additiveAttention_model = get_additiveAttention_model(200,\n",
    "    mode='classification',\n",
    "    num_motifs=150, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    attention_dim=10,\n",
    "    attention_hops=10,\n",
    "    dropout_rate=0.1\n",
    "    )\n",
    "additiveAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fwd (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convolution_layer (Conv1D)      (None, 200, 150)     6150        input_fwd[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_tanh_layer (Dense)    (None, 200, 10)      1500        convolution_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_outer_layer (Dense)   (None, 200, 10)      100         attention_tanh_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attention_softmax_layer (Softma (None, 200, 10)      0           attention_outer_layer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attention_dropout (Dropout)     (None, 200, 10)      0           attention_softmax_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attending_layer (Dot)           (None, 10, 150)      0           attention_dropout[0][0]          \n",
      "                                                                 convolution_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1500)         0           attending_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            3002        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,752\n",
      "Trainable params: 10,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "additiveAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53628 samples, validate on 13408 samples\n",
      "Epoch 1/10\n",
      "53628/53628 [==============================] - 17s 315us/step - loss: 0.3453 - categorical_accuracy: 0.8504 - val_loss: 0.3707 - val_categorical_accuracy: 0.8341\n",
      "Epoch 2/10\n",
      "53628/53628 [==============================] - 17s 312us/step - loss: 0.3410 - categorical_accuracy: 0.8521 - val_loss: 0.3697 - val_categorical_accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "53628/53628 [==============================] - 17s 314us/step - loss: 0.3335 - categorical_accuracy: 0.8564 - val_loss: 0.3622 - val_categorical_accuracy: 0.8387\n",
      "Epoch 4/10\n",
      "53628/53628 [==============================] - 17s 316us/step - loss: 0.3317 - categorical_accuracy: 0.8567 - val_loss: 0.3468 - val_categorical_accuracy: 0.8479\n",
      "Epoch 5/10\n",
      "53628/53628 [==============================] - 17s 314us/step - loss: 0.3247 - categorical_accuracy: 0.8590 - val_loss: 0.3431 - val_categorical_accuracy: 0.8487\n",
      "Epoch 6/10\n",
      "53628/53628 [==============================] - 17s 313us/step - loss: 0.3225 - categorical_accuracy: 0.8620 - val_loss: 0.3804 - val_categorical_accuracy: 0.8299\n",
      "Epoch 7/10\n",
      "53628/53628 [==============================] - 17s 313us/step - loss: 0.3185 - categorical_accuracy: 0.8634 - val_loss: 0.3440 - val_categorical_accuracy: 0.8499\n",
      "Epoch 8/10\n",
      "53628/53628 [==============================] - 17s 314us/step - loss: 0.3154 - categorical_accuracy: 0.8638 - val_loss: 0.3702 - val_categorical_accuracy: 0.8406\n",
      "Epoch 9/10\n",
      "53628/53628 [==============================] - 17s 313us/step - loss: 0.3122 - categorical_accuracy: 0.8665 - val_loss: 0.3435 - val_categorical_accuracy: 0.8520\n",
      "Epoch 10/10\n",
      "53628/53628 [==============================] - 17s 316us/step - loss: 0.3089 - categorical_accuracy: 0.8696 - val_loss: 0.3497 - val_categorical_accuracy: 0.8482\n",
      "0.9084160241684404 0.8726526747672401 0.8481503579952268\n"
     ]
    }
   ],
   "source": [
    "additiveAttention_model.fit([x_train], y_train,\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test], y_test))\n",
    "\n",
    "probs = additiveAttention_model.predict([x_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [0 if x[0] > x[1] else 1 for x in probs])\n",
    "acc = additiveAttention_model.evaluate([x_test], y_test, verbose=0)[1]\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dotProductAttention_model = get_dotProductAttention_model(200,\n",
    "    mode='classification',\n",
    "    num_motifs=150, \n",
    "    motif_size=10,\n",
    "    adjacent_bp_pool_size=10,\n",
    "    dropout_rate=0.1,\n",
    "    num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(dotProductAttention_model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fwd (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convolution_layer (Conv1D)      (None, 200, 150)     6150        input_fwd[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer (MaxPool (None, 20, 150)      0           convolution_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "query_transformer (TimeDistribu (None, 20, 150)      150         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "key_transformer (TimeDistribute (None, 20, 150)      150         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 20, 20)       0           query_transformer[0][0]          \n",
      "                                                                 key_transformer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_softmax_layer (Softma (None, 20, 20)       0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_dropout (Dropout)     (None, 20, 20)       0           attention_softmax_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "value_transformer (TimeDistribu (None, 20, 150)      150         sequence_pooling_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "attending_layer (Dot)           (None, 20, 150)      0           attention_dropout[0][0]          \n",
      "                                                                 value_transformer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3000)         0           attending_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            6002        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,602\n",
      "Trainable params: 12,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotProductAttention_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53628 samples, validate on 13408 samples\n",
      "Epoch 1/10\n",
      "53628/53628 [==============================] - 13s 238us/step - loss: 0.3300 - categorical_accuracy: 0.8556 - val_loss: 0.3410 - val_categorical_accuracy: 0.8506\n",
      "Epoch 2/10\n",
      "53628/53628 [==============================] - 13s 236us/step - loss: 0.3224 - categorical_accuracy: 0.8591 - val_loss: 0.3365 - val_categorical_accuracy: 0.8536\n",
      "Epoch 3/10\n",
      "53628/53628 [==============================] - 13s 236us/step - loss: 0.3151 - categorical_accuracy: 0.8646 - val_loss: 0.3341 - val_categorical_accuracy: 0.8540\n",
      "Epoch 4/10\n",
      "53628/53628 [==============================] - 13s 238us/step - loss: 0.3112 - categorical_accuracy: 0.8657 - val_loss: 0.3302 - val_categorical_accuracy: 0.8559\n",
      "Epoch 5/10\n",
      "53628/53628 [==============================] - 13s 237us/step - loss: 0.3019 - categorical_accuracy: 0.8712 - val_loss: 0.3335 - val_categorical_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "53628/53628 [==============================] - 13s 238us/step - loss: 0.2996 - categorical_accuracy: 0.8712 - val_loss: 0.3366 - val_categorical_accuracy: 0.8539\n",
      "Epoch 7/10\n",
      "53628/53628 [==============================] - 13s 241us/step - loss: 0.2931 - categorical_accuracy: 0.8747 - val_loss: 0.3248 - val_categorical_accuracy: 0.8602\n",
      "Epoch 8/10\n",
      "53628/53628 [==============================] - 13s 241us/step - loss: 0.2888 - categorical_accuracy: 0.8782 - val_loss: 0.3311 - val_categorical_accuracy: 0.8597\n",
      "Epoch 9/10\n",
      "53628/53628 [==============================] - 13s 241us/step - loss: 0.2827 - categorical_accuracy: 0.8811 - val_loss: 0.3298 - val_categorical_accuracy: 0.8561\n",
      "Epoch 10/10\n",
      "53628/53628 [==============================] - 13s 238us/step - loss: 0.2819 - categorical_accuracy: 0.8795 - val_loss: 0.3312 - val_categorical_accuracy: 0.8548\n",
      "0.9198394164420314 0.8840996168582376 0.854788186157518\n"
     ]
    }
   ],
   "source": [
    "dotProductAttention_model.fit([x_train], y_train,\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test], y_test))\n",
    "\n",
    "probs = dotProductAttention_model.predict([x_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [0 if x[0] > x[1] else 1 for x in probs])\n",
    "acc = dotProductAttention_model.evaluate([x_test], y_test, verbose=0)[1]\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convolution_model = get_convolution_model(200,\n",
    "    mode='classification',\n",
    "    num_motifs=150, \n",
    "    motif_size=10,\n",
    "    num_dense_neurons=50,\n",
    "    dropout_rate=0.1,\n",
    "    num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(dotProductAttention_model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_fwd (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rev (InputLayer)          (None, 200, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convolution_layer (Conv1D)      (None, 200, 150)     6150        input_fwd[0][0]                  \n",
      "                                                                 input_rev[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 150)       0           convolution_layer[0][0]          \n",
      "                                                                 convolution_layer[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "maximum_3 (Maximum)             (None, 1, 150)       0           max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 50)        7550        maximum_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 50)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 50)           0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            102         flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,802\n",
      "Trainable params: 13,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convolution_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13802"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53628 samples, validate on 13408 samples\n",
      "Epoch 1/10\n",
      "53628/53628 [==============================] - 13s 237us/step - loss: 0.4904 - categorical_accuracy: 0.7512 - val_loss: 0.3668 - val_categorical_accuracy: 0.8392\n",
      "Epoch 2/10\n",
      "53628/53628 [==============================] - 12s 229us/step - loss: 0.3635 - categorical_accuracy: 0.8393 - val_loss: 0.3460 - val_categorical_accuracy: 0.8472\n",
      "Epoch 3/10\n",
      "53628/53628 [==============================] - 12s 230us/step - loss: 0.3391 - categorical_accuracy: 0.8526 - val_loss: 0.3488 - val_categorical_accuracy: 0.8446\n",
      "Epoch 4/10\n",
      "53628/53628 [==============================] - 12s 231us/step - loss: 0.3216 - categorical_accuracy: 0.8631 - val_loss: 0.3538 - val_categorical_accuracy: 0.8405\n",
      "Epoch 5/10\n",
      "53628/53628 [==============================] - 12s 231us/step - loss: 0.3081 - categorical_accuracy: 0.8684 - val_loss: 0.3414 - val_categorical_accuracy: 0.8521\n",
      "Epoch 6/10\n",
      "53628/53628 [==============================] - 12s 231us/step - loss: 0.3024 - categorical_accuracy: 0.8720 - val_loss: 0.3310 - val_categorical_accuracy: 0.8536\n",
      "Epoch 7/10\n",
      "53628/53628 [==============================] - 12s 233us/step - loss: 0.2932 - categorical_accuracy: 0.8763 - val_loss: 0.3576 - val_categorical_accuracy: 0.8432\n",
      "Epoch 8/10\n",
      "53628/53628 [==============================] - 12s 232us/step - loss: 0.2837 - categorical_accuracy: 0.8813 - val_loss: 0.3253 - val_categorical_accuracy: 0.8598\n",
      "Epoch 9/10\n",
      "53628/53628 [==============================] - 12s 232us/step - loss: 0.2803 - categorical_accuracy: 0.8827 - val_loss: 0.3232 - val_categorical_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "20544/53628 [==========>...................] - ETA: 7s - loss: 0.2640 - categorical_accuracy: 0.8906"
     ]
    }
   ],
   "source": [
    "convolution_model.fit([x_train, x_rc_train], y_train,\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "probs = convolution_model.predict([x_test, x_rc_test])\n",
    "\n",
    "roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "precision = sklearn.metrics.precision_score([y[1] for y in y_test], [0 if x[0] > x[1] else 1 for x in probs])\n",
    "acc = convolution_model.evaluate([x_test, x_rc_test], y_test, verbose=0)[1]\n",
    "print(roc, precision, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c57bl6_kla-1h_peaks.fasta\n",
      "kla-1h num dense 50 num motifs 50 pool size 5 dropout rate 0.25 param count 10402\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 479us/step - loss: 0.6759 - acc: 0.5573 - val_loss: 0.6470 - val_acc: 0.6178\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.6044 - acc: 0.6719 - val_loss: 0.6077 - val_acc: 0.6661\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 13s 368us/step - loss: 0.5516 - acc: 0.7190 - val_loss: 0.5445 - val_acc: 0.7255\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 13s 375us/step - loss: 0.5183 - acc: 0.7455 - val_loss: 0.5316 - val_acc: 0.7336\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 13s 372us/step - loss: 0.4985 - acc: 0.7570 - val_loss: 0.5049 - val_acc: 0.7518\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 13s 370us/step - loss: 0.4803 - acc: 0.7700 - val_loss: 0.5050 - val_acc: 0.7526\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 13s 365us/step - loss: 0.4654 - acc: 0.7783 - val_loss: 0.4892 - val_acc: 0.7627\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 13s 365us/step - loss: 0.4523 - acc: 0.7874 - val_loss: 0.4910 - val_acc: 0.7626\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 13s 364us/step - loss: 0.4405 - acc: 0.7976 - val_loss: 0.4720 - val_acc: 0.7761\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 13s 367us/step - loss: 0.4301 - acc: 0.8027 - val_loss: 0.4617 - val_acc: 0.7805\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 13s 363us/step - loss: 0.4215 - acc: 0.8084 - val_loss: 0.4546 - val_acc: 0.7861\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 12s 358us/step - loss: 0.4127 - acc: 0.8114 - val_loss: 0.4970 - val_acc: 0.7679\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 12s 355us/step - loss: 0.4091 - acc: 0.8134 - val_loss: 0.4804 - val_acc: 0.7720\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 12s 356us/step - loss: 0.4010 - acc: 0.8192 - val_loss: 0.4431 - val_acc: 0.7920\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.3951 - acc: 0.8226 - val_loss: 0.4525 - val_acc: 0.7838\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.3880 - acc: 0.8258 - val_loss: 0.4507 - val_acc: 0.7872\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.3874 - acc: 0.8254 - val_loss: 0.4469 - val_acc: 0.7920\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.3783 - acc: 0.8311 - val_loss: 0.4664 - val_acc: 0.7806\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 12s 355us/step - loss: 0.3767 - acc: 0.8310 - val_loss: 0.4507 - val_acc: 0.7895\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3710 - acc: 0.8335 - val_loss: 0.4332 - val_acc: 0.8009\n",
      "kla-1h num dense 50 num motifs 50 pool size 5 dropout rate 0.5 param count 10402\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 13s 362us/step - loss: 0.6784 - acc: 0.5544 - val_loss: 0.6481 - val_acc: 0.6240\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.6188 - acc: 0.6580 - val_loss: 0.5973 - val_acc: 0.6797\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 12s 357us/step - loss: 0.5686 - acc: 0.7045 - val_loss: 0.5573 - val_acc: 0.7140\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 12s 355us/step - loss: 0.5262 - acc: 0.7415 - val_loss: 0.5146 - val_acc: 0.7501\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.4919 - acc: 0.7640 - val_loss: 0.4888 - val_acc: 0.7666\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.4652 - acc: 0.7794 - val_loss: 0.4732 - val_acc: 0.7782\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 12s 348us/step - loss: 0.4421 - acc: 0.7944 - val_loss: 0.4558 - val_acc: 0.7849\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.4288 - acc: 0.8027 - val_loss: 0.4477 - val_acc: 0.7866\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.4205 - acc: 0.8072 - val_loss: 0.4435 - val_acc: 0.7916\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.4119 - acc: 0.8107 - val_loss: 0.4828 - val_acc: 0.7737\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.4031 - acc: 0.8157 - val_loss: 0.4342 - val_acc: 0.7965\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3943 - acc: 0.8216 - val_loss: 0.4358 - val_acc: 0.8013\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 12s 347us/step - loss: 0.3900 - acc: 0.8234 - val_loss: 0.4462 - val_acc: 0.7936\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3833 - acc: 0.8273 - val_loss: 0.4223 - val_acc: 0.8052\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3820 - acc: 0.8291 - val_loss: 0.4230 - val_acc: 0.8031\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3744 - acc: 0.8319 - val_loss: 0.4191 - val_acc: 0.8077\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3712 - acc: 0.8350 - val_loss: 0.4156 - val_acc: 0.8123\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.3700 - acc: 0.8349 - val_loss: 0.4179 - val_acc: 0.8104\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3655 - acc: 0.8359 - val_loss: 0.4137 - val_acc: 0.8105\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 12s 348us/step - loss: 0.3624 - acc: 0.8378 - val_loss: 0.4147 - val_acc: 0.8106\n",
      "kla-1h num dense 50 num motifs 50 pool size 5 dropout rate 0.75 param count 10402\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 13s 362us/step - loss: 0.6863 - acc: 0.5349 - val_loss: 0.6577 - val_acc: 0.6119\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.6309 - acc: 0.6438 - val_loss: 0.6229 - val_acc: 0.6485\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.5907 - acc: 0.6834 - val_loss: 0.5849 - val_acc: 0.6873\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.5547 - acc: 0.7191 - val_loss: 0.5678 - val_acc: 0.7031\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 12s 346us/step - loss: 0.5222 - acc: 0.7425 - val_loss: 0.5303 - val_acc: 0.7354\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 12s 344us/step - loss: 0.4921 - acc: 0.7623 - val_loss: 0.4827 - val_acc: 0.7740\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.4659 - acc: 0.7798 - val_loss: 0.4624 - val_acc: 0.7834\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 12s 346us/step - loss: 0.4474 - acc: 0.7944 - val_loss: 0.4533 - val_acc: 0.7898\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 12s 348us/step - loss: 0.4357 - acc: 0.7998 - val_loss: 0.4416 - val_acc: 0.7992\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.4255 - acc: 0.8032 - val_loss: 0.4368 - val_acc: 0.8008\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.4125 - acc: 0.8140 - val_loss: 0.4346 - val_acc: 0.8023\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.4110 - acc: 0.8109 - val_loss: 0.4243 - val_acc: 0.8078\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3972 - acc: 0.8217 - val_loss: 0.4305 - val_acc: 0.8045\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 12s 345us/step - loss: 0.3930 - acc: 0.8211 - val_loss: 0.4326 - val_acc: 0.7993\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 12s 342us/step - loss: 0.3884 - acc: 0.8275 - val_loss: 0.4321 - val_acc: 0.8030\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3795 - acc: 0.8309 - val_loss: 0.4165 - val_acc: 0.8129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3741 - acc: 0.8337 - val_loss: 0.4168 - val_acc: 0.8153\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 12s 344us/step - loss: 0.3724 - acc: 0.8358 - val_loss: 0.4158 - val_acc: 0.8101\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 12s 348us/step - loss: 0.3680 - acc: 0.8352 - val_loss: 0.4059 - val_acc: 0.8158\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3634 - acc: 0.8411 - val_loss: 0.4120 - val_acc: 0.8127\n",
      "kla-1h num dense 50 num motifs 50 pool size 10 dropout rate 0.25 param count 8902\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 11s 326us/step - loss: 0.6737 - acc: 0.5666 - val_loss: 0.6270 - val_acc: 0.6539\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.5712 - acc: 0.7008 - val_loss: 0.5300 - val_acc: 0.7367\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.5002 - acc: 0.7569 - val_loss: 0.5122 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4624 - acc: 0.7817 - val_loss: 0.4589 - val_acc: 0.7823\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 308us/step - loss: 0.4348 - acc: 0.7972 - val_loss: 0.4530 - val_acc: 0.7836\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4212 - acc: 0.8057 - val_loss: 0.4384 - val_acc: 0.7999\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4082 - acc: 0.8140 - val_loss: 0.4327 - val_acc: 0.7972\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 308us/step - loss: 0.3985 - acc: 0.8190 - val_loss: 0.4269 - val_acc: 0.8023\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 316us/step - loss: 0.3906 - acc: 0.8216 - val_loss: 0.4290 - val_acc: 0.8016\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3867 - acc: 0.8249 - val_loss: 0.4265 - val_acc: 0.8042\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 11s 319us/step - loss: 0.3807 - acc: 0.8285 - val_loss: 0.4214 - val_acc: 0.8084\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3742 - acc: 0.8332 - val_loss: 0.4152 - val_acc: 0.8104\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 11s 317us/step - loss: 0.3721 - acc: 0.8334 - val_loss: 0.4147 - val_acc: 0.8151\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3660 - acc: 0.8370 - val_loss: 0.4122 - val_acc: 0.8178\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3601 - acc: 0.8404 - val_loss: 0.4354 - val_acc: 0.8009\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 322us/step - loss: 0.3571 - acc: 0.8404 - val_loss: 0.4177 - val_acc: 0.8154\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3541 - acc: 0.8432 - val_loss: 0.4125 - val_acc: 0.8155\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 316us/step - loss: 0.3504 - acc: 0.8452 - val_loss: 0.4077 - val_acc: 0.8214\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 320us/step - loss: 0.3471 - acc: 0.8477 - val_loss: 0.4318 - val_acc: 0.8073\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3449 - acc: 0.8477 - val_loss: 0.4063 - val_acc: 0.8183\n",
      "kla-1h num dense 50 num motifs 50 pool size 10 dropout rate 0.5 param count 8902\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 11s 325us/step - loss: 0.6694 - acc: 0.5663 - val_loss: 0.6110 - val_acc: 0.6663\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.5667 - acc: 0.7091 - val_loss: 0.5236 - val_acc: 0.7414\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.4999 - acc: 0.7584 - val_loss: 0.4950 - val_acc: 0.7644\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.4644 - acc: 0.7821 - val_loss: 0.4927 - val_acc: 0.7648\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 308us/step - loss: 0.4418 - acc: 0.7959 - val_loss: 0.4520 - val_acc: 0.7848\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 11s 308us/step - loss: 0.4283 - acc: 0.8029 - val_loss: 0.4530 - val_acc: 0.7848\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4180 - acc: 0.8076 - val_loss: 0.4358 - val_acc: 0.7984\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.4076 - acc: 0.8148 - val_loss: 0.4594 - val_acc: 0.7844\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3980 - acc: 0.8192 - val_loss: 0.4243 - val_acc: 0.8058\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.3892 - acc: 0.8252 - val_loss: 0.4291 - val_acc: 0.8047\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3831 - acc: 0.8275 - val_loss: 0.4198 - val_acc: 0.8092\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.3761 - acc: 0.8325 - val_loss: 0.4096 - val_acc: 0.8136\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.3715 - acc: 0.8349 - val_loss: 0.4163 - val_acc: 0.8092\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.3648 - acc: 0.8374 - val_loss: 0.4278 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3619 - acc: 0.8412 - val_loss: 0.4108 - val_acc: 0.8100\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.3581 - acc: 0.8431 - val_loss: 0.4018 - val_acc: 0.8160\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.3536 - acc: 0.8443 - val_loss: 0.4053 - val_acc: 0.8200\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3537 - acc: 0.8439 - val_loss: 0.4006 - val_acc: 0.8207\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 308us/step - loss: 0.3478 - acc: 0.8481 - val_loss: 0.4242 - val_acc: 0.8097\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.3462 - acc: 0.8477 - val_loss: 0.4119 - val_acc: 0.8183\n",
      "kla-1h num dense 50 num motifs 50 pool size 10 dropout rate 0.75 param count 8902\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 11s 327us/step - loss: 0.6862 - acc: 0.5332 - val_loss: 0.6456 - val_acc: 0.6268\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.6123 - acc: 0.6640 - val_loss: 0.5674 - val_acc: 0.7106\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.5379 - acc: 0.7336 - val_loss: 0.5145 - val_acc: 0.7454\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.4909 - acc: 0.7646 - val_loss: 0.4866 - val_acc: 0.7651\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.4648 - acc: 0.7809 - val_loss: 0.4720 - val_acc: 0.7725\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.4472 - acc: 0.7917 - val_loss: 0.4631 - val_acc: 0.7809\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4304 - acc: 0.8009 - val_loss: 0.4653 - val_acc: 0.7811\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.4195 - acc: 0.8081 - val_loss: 0.4362 - val_acc: 0.7936\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4093 - acc: 0.8146 - val_loss: 0.4305 - val_acc: 0.8005\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3981 - acc: 0.8208 - val_loss: 0.4256 - val_acc: 0.8016\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 11s 307us/step - loss: 0.3900 - acc: 0.8245 - val_loss: 0.4246 - val_acc: 0.8043\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.3858 - acc: 0.8258 - val_loss: 0.4223 - val_acc: 0.8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 11s 309us/step - loss: 0.3829 - acc: 0.8294 - val_loss: 0.4202 - val_acc: 0.8078\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 11s 308us/step - loss: 0.3764 - acc: 0.8325 - val_loss: 0.4148 - val_acc: 0.8110\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3739 - acc: 0.8322 - val_loss: 0.4109 - val_acc: 0.8147\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 316us/step - loss: 0.3685 - acc: 0.8383 - val_loss: 0.4078 - val_acc: 0.8109\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3645 - acc: 0.8402 - val_loss: 0.4219 - val_acc: 0.8112\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.3642 - acc: 0.8404 - val_loss: 0.4049 - val_acc: 0.8154\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3616 - acc: 0.8419 - val_loss: 0.4240 - val_acc: 0.8039\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.3609 - acc: 0.8412 - val_loss: 0.4179 - val_acc: 0.8059\n",
      "kla-1h num dense 50 num motifs 50 pool size 20 dropout rate 0.25 param count 8102\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.6601 - acc: 0.5832 - val_loss: 0.5703 - val_acc: 0.7055\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.5359 - acc: 0.7290 - val_loss: 0.5204 - val_acc: 0.7393\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4869 - acc: 0.7654 - val_loss: 0.4925 - val_acc: 0.7551\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.4589 - acc: 0.7831 - val_loss: 0.5228 - val_acc: 0.7426\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4376 - acc: 0.7948 - val_loss: 0.4673 - val_acc: 0.7788\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4198 - acc: 0.8051 - val_loss: 0.4590 - val_acc: 0.7840\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4116 - acc: 0.8091 - val_loss: 0.4448 - val_acc: 0.7939\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.4030 - acc: 0.8171 - val_loss: 0.4402 - val_acc: 0.7962\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3971 - acc: 0.8204 - val_loss: 0.4353 - val_acc: 0.7969\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 10s 294us/step - loss: 0.3901 - acc: 0.8237 - val_loss: 0.4360 - val_acc: 0.7975\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3864 - acc: 0.8259 - val_loss: 0.4320 - val_acc: 0.7993\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3833 - acc: 0.8290 - val_loss: 0.4282 - val_acc: 0.8011\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 10s 295us/step - loss: 0.3797 - acc: 0.8289 - val_loss: 0.4381 - val_acc: 0.7992\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 10s 291us/step - loss: 0.3723 - acc: 0.8342 - val_loss: 0.4619 - val_acc: 0.7874\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3703 - acc: 0.8352 - val_loss: 0.4398 - val_acc: 0.7937\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3670 - acc: 0.8379 - val_loss: 0.4225 - val_acc: 0.8096\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 10s 292us/step - loss: 0.3647 - acc: 0.8378 - val_loss: 0.4193 - val_acc: 0.8116\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3624 - acc: 0.8391 - val_loss: 0.4204 - val_acc: 0.8122\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3596 - acc: 0.8412 - val_loss: 0.4286 - val_acc: 0.8063\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 10s 294us/step - loss: 0.3575 - acc: 0.8437 - val_loss: 0.4311 - val_acc: 0.8063\n",
      "kla-1h num dense 50 num motifs 50 pool size 20 dropout rate 0.5 param count 8102\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.6688 - acc: 0.5711 - val_loss: 0.5882 - val_acc: 0.6904\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 10s 293us/step - loss: 0.5384 - acc: 0.7312 - val_loss: 0.5090 - val_acc: 0.7502\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 10s 293us/step - loss: 0.4808 - acc: 0.7686 - val_loss: 0.4856 - val_acc: 0.7662\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.4489 - acc: 0.7885 - val_loss: 0.5052 - val_acc: 0.7544\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4295 - acc: 0.8014 - val_loss: 0.4477 - val_acc: 0.7921\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.4188 - acc: 0.8066 - val_loss: 0.4413 - val_acc: 0.7967\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4072 - acc: 0.8140 - val_loss: 0.4410 - val_acc: 0.7944\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 304us/step - loss: 0.4009 - acc: 0.8173 - val_loss: 0.4325 - val_acc: 0.7989\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3924 - acc: 0.8231 - val_loss: 0.4340 - val_acc: 0.7976\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3898 - acc: 0.8240 - val_loss: 0.4254 - val_acc: 0.8036\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3825 - acc: 0.8292 - val_loss: 0.4271 - val_acc: 0.8052\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 304us/step - loss: 0.3784 - acc: 0.8311 - val_loss: 0.4196 - val_acc: 0.8042\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3724 - acc: 0.8355 - val_loss: 0.4213 - val_acc: 0.8084\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3719 - acc: 0.8341 - val_loss: 0.4143 - val_acc: 0.8104\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3658 - acc: 0.8374 - val_loss: 0.4185 - val_acc: 0.8096\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 301us/step - loss: 0.3635 - acc: 0.8373 - val_loss: 0.4168 - val_acc: 0.8082\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.3607 - acc: 0.8406 - val_loss: 0.4143 - val_acc: 0.8099\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 306us/step - loss: 0.3590 - acc: 0.8419 - val_loss: 0.4251 - val_acc: 0.8069\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 302us/step - loss: 0.3555 - acc: 0.8440 - val_loss: 0.4171 - val_acc: 0.8106\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.3529 - acc: 0.8452 - val_loss: 0.4209 - val_acc: 0.8109\n",
      "kla-1h num dense 50 num motifs 50 pool size 20 dropout rate 0.75 param count 8102\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 11s 320us/step - loss: 0.6855 - acc: 0.5414 - val_loss: 0.6371 - val_acc: 0.6574\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.5790 - acc: 0.6992 - val_loss: 0.5345 - val_acc: 0.7364\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 304us/step - loss: 0.5185 - acc: 0.7483 - val_loss: 0.5001 - val_acc: 0.7593\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.4826 - acc: 0.7714 - val_loss: 0.4847 - val_acc: 0.7609\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 302us/step - loss: 0.4585 - acc: 0.7869 - val_loss: 0.4666 - val_acc: 0.7784\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4450 - acc: 0.7944 - val_loss: 0.4535 - val_acc: 0.7883\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4349 - acc: 0.7992 - val_loss: 0.4522 - val_acc: 0.7885\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.4240 - acc: 0.8075 - val_loss: 0.4469 - val_acc: 0.7893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4168 - acc: 0.8112 - val_loss: 0.4521 - val_acc: 0.7883\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4117 - acc: 0.8120 - val_loss: 0.4375 - val_acc: 0.7963\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.4059 - acc: 0.8181 - val_loss: 0.4527 - val_acc: 0.7928\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 304us/step - loss: 0.4015 - acc: 0.8200 - val_loss: 0.4499 - val_acc: 0.7921\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3975 - acc: 0.8241 - val_loss: 0.4369 - val_acc: 0.7972\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 10s 292us/step - loss: 0.3924 - acc: 0.8268 - val_loss: 0.4489 - val_acc: 0.7882\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3903 - acc: 0.8262 - val_loss: 0.4362 - val_acc: 0.7970\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3883 - acc: 0.8272 - val_loss: 0.4378 - val_acc: 0.7960\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3852 - acc: 0.8305 - val_loss: 0.4285 - val_acc: 0.8008\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3805 - acc: 0.8320 - val_loss: 0.4304 - val_acc: 0.8017\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3787 - acc: 0.8335 - val_loss: 0.4278 - val_acc: 0.8031\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 10s 295us/step - loss: 0.3755 - acc: 0.8328 - val_loss: 0.4345 - val_acc: 0.8012\n",
      "kla-1h num dense 50 num motifs 100 pool size 5 dropout rate 0.25 param count 17752\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 494us/step - loss: 0.6622 - acc: 0.5855 - val_loss: 0.6296 - val_acc: 0.6524\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 16s 470us/step - loss: 0.5834 - acc: 0.6939 - val_loss: 0.5555 - val_acc: 0.7226\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 16s 470us/step - loss: 0.5124 - acc: 0.7497 - val_loss: 0.4854 - val_acc: 0.7685\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 16s 465us/step - loss: 0.4705 - acc: 0.7789 - val_loss: 0.4689 - val_acc: 0.7751\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.4387 - acc: 0.7970 - val_loss: 0.4511 - val_acc: 0.7882\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 16s 464us/step - loss: 0.4200 - acc: 0.8089 - val_loss: 0.4375 - val_acc: 0.7946\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.4040 - acc: 0.8170 - val_loss: 0.4375 - val_acc: 0.7975\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.3947 - acc: 0.8215 - val_loss: 0.4274 - val_acc: 0.8027\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.3849 - acc: 0.8269 - val_loss: 0.4465 - val_acc: 0.7911\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.3734 - acc: 0.8324 - val_loss: 0.5035 - val_acc: 0.7707\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.3663 - acc: 0.8353 - val_loss: 0.4272 - val_acc: 0.8060\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.3556 - acc: 0.8401 - val_loss: 0.4199 - val_acc: 0.8076\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.3508 - acc: 0.8435 - val_loss: 0.4159 - val_acc: 0.8071\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3434 - acc: 0.8478 - val_loss: 0.4102 - val_acc: 0.8175\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3360 - acc: 0.8511 - val_loss: 0.4249 - val_acc: 0.8091\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.3332 - acc: 0.8534 - val_loss: 0.4127 - val_acc: 0.8133\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 16s 465us/step - loss: 0.3286 - acc: 0.8555 - val_loss: 0.4153 - val_acc: 0.8132\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.3213 - acc: 0.8605 - val_loss: 0.4082 - val_acc: 0.8175\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 16s 464us/step - loss: 0.3146 - acc: 0.8632 - val_loss: 0.4155 - val_acc: 0.8199\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 16s 463us/step - loss: 0.3135 - acc: 0.8641 - val_loss: 0.4078 - val_acc: 0.8182\n",
      "kla-1h num dense 50 num motifs 100 pool size 5 dropout rate 0.5 param count 17752\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 483us/step - loss: 0.6677 - acc: 0.5748 - val_loss: 0.6379 - val_acc: 0.6270\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.6050 - acc: 0.6706 - val_loss: 0.5907 - val_acc: 0.6811\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.5493 - acc: 0.7192 - val_loss: 0.5283 - val_acc: 0.7301\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.4976 - acc: 0.7578 - val_loss: 0.4983 - val_acc: 0.7554\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.4542 - acc: 0.7873 - val_loss: 0.4555 - val_acc: 0.7881\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.4211 - acc: 0.8091 - val_loss: 0.4383 - val_acc: 0.7949\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3962 - acc: 0.8210 - val_loss: 0.4322 - val_acc: 0.8058\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3795 - acc: 0.8292 - val_loss: 0.4119 - val_acc: 0.8124\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.3620 - acc: 0.8396 - val_loss: 0.4073 - val_acc: 0.8161\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3538 - acc: 0.8450 - val_loss: 0.3985 - val_acc: 0.8201\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.3445 - acc: 0.8496 - val_loss: 0.4079 - val_acc: 0.8232\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 16s 464us/step - loss: 0.3344 - acc: 0.8540 - val_loss: 0.4008 - val_acc: 0.8221\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 16s 463us/step - loss: 0.3301 - acc: 0.8568 - val_loss: 0.4152 - val_acc: 0.8092\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.3255 - acc: 0.8603 - val_loss: 0.4066 - val_acc: 0.8216\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 16s 465us/step - loss: 0.3215 - acc: 0.8601 - val_loss: 0.3993 - val_acc: 0.8280\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 16s 466us/step - loss: 0.3132 - acc: 0.8658 - val_loss: 0.3969 - val_acc: 0.8268\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 16s 463us/step - loss: 0.3112 - acc: 0.8656 - val_loss: 0.3965 - val_acc: 0.8307\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.3070 - acc: 0.8702 - val_loss: 0.4013 - val_acc: 0.8269\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 16s 463us/step - loss: 0.3108 - acc: 0.8660 - val_loss: 0.4037 - val_acc: 0.8263\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 16s 465us/step - loss: 0.3031 - acc: 0.8699 - val_loss: 0.4220 - val_acc: 0.8117\n",
      "kla-1h num dense 50 num motifs 100 pool size 5 dropout rate 0.75 param count 17752\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 481us/step - loss: 0.6818 - acc: 0.5480 - val_loss: 0.6442 - val_acc: 0.6347\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 16s 462us/step - loss: 0.6291 - acc: 0.6449 - val_loss: 0.6023 - val_acc: 0.6754\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.5843 - acc: 0.6897 - val_loss: 0.5748 - val_acc: 0.6938\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 16s 464us/step - loss: 0.5360 - acc: 0.7296 - val_loss: 0.5215 - val_acc: 0.7406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 16s 465us/step - loss: 0.4907 - acc: 0.7627 - val_loss: 0.4848 - val_acc: 0.7658\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 16s 463us/step - loss: 0.4480 - acc: 0.7911 - val_loss: 0.4546 - val_acc: 0.7821\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.4128 - acc: 0.8133 - val_loss: 0.4185 - val_acc: 0.8066\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.3958 - acc: 0.8211 - val_loss: 0.4055 - val_acc: 0.8154\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.3749 - acc: 0.8334 - val_loss: 0.3961 - val_acc: 0.8248\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 16s 458us/step - loss: 0.3647 - acc: 0.8392 - val_loss: 0.3921 - val_acc: 0.8231\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.3549 - acc: 0.8455 - val_loss: 0.3896 - val_acc: 0.8296\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 16s 461us/step - loss: 0.3480 - acc: 0.8487 - val_loss: 0.3840 - val_acc: 0.8303\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 16s 456us/step - loss: 0.3399 - acc: 0.8522 - val_loss: 0.3999 - val_acc: 0.8224\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.3362 - acc: 0.8543 - val_loss: 0.4059 - val_acc: 0.8192\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.3297 - acc: 0.8598 - val_loss: 0.3793 - val_acc: 0.8331\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.3242 - acc: 0.8609 - val_loss: 0.3816 - val_acc: 0.8356\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 16s 459us/step - loss: 0.3212 - acc: 0.8612 - val_loss: 0.3815 - val_acc: 0.8339\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.3161 - acc: 0.8648 - val_loss: 0.3928 - val_acc: 0.8306\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 16s 460us/step - loss: 0.3167 - acc: 0.8639 - val_loss: 0.3874 - val_acc: 0.8298\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 16s 457us/step - loss: 0.3113 - acc: 0.8648 - val_loss: 0.3885 - val_acc: 0.8325\n",
      "kla-1h num dense 50 num motifs 100 pool size 10 dropout rate 0.25 param count 16252\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 15s 435us/step - loss: 0.6602 - acc: 0.5811 - val_loss: 0.6033 - val_acc: 0.6750\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 14s 408us/step - loss: 0.5472 - acc: 0.7219 - val_loss: 0.5321 - val_acc: 0.7300\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.4756 - acc: 0.7728 - val_loss: 0.4741 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.4253 - acc: 0.8033 - val_loss: 0.4251 - val_acc: 0.8052\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3936 - acc: 0.8225 - val_loss: 0.4121 - val_acc: 0.8122\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3758 - acc: 0.8336 - val_loss: 0.3929 - val_acc: 0.8268\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3593 - acc: 0.8416 - val_loss: 0.4094 - val_acc: 0.8143\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3469 - acc: 0.8477 - val_loss: 0.3850 - val_acc: 0.8283\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3403 - acc: 0.8512 - val_loss: 0.3922 - val_acc: 0.8291\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3359 - acc: 0.8527 - val_loss: 0.3965 - val_acc: 0.8241\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3286 - acc: 0.8576 - val_loss: 0.3812 - val_acc: 0.8337\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3208 - acc: 0.8611 - val_loss: 0.3850 - val_acc: 0.8331\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3172 - acc: 0.8644 - val_loss: 0.3868 - val_acc: 0.8322\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3100 - acc: 0.8669 - val_loss: 0.4083 - val_acc: 0.8239\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3086 - acc: 0.8680 - val_loss: 0.3849 - val_acc: 0.8383\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3033 - acc: 0.8699 - val_loss: 0.3839 - val_acc: 0.8343\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 16s 473us/step - loss: 0.3011 - acc: 0.8713 - val_loss: 0.3853 - val_acc: 0.8371\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 23s 661us/step - loss: 0.2958 - acc: 0.8730 - val_loss: 0.4057 - val_acc: 0.8276\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 18s 505us/step - loss: 0.2922 - acc: 0.8752 - val_loss: 0.3929 - val_acc: 0.8321\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 34s 987us/step - loss: 0.2904 - acc: 0.8768 - val_loss: 0.3940 - val_acc: 0.8369\n",
      "kla-1h num dense 50 num motifs 100 pool size 10 dropout rate 0.5 param count 16252\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 38s 1ms/step - loss: 0.6718 - acc: 0.5665 - val_loss: 0.6264 - val_acc: 0.6438\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 37s 1ms/step - loss: 0.5871 - acc: 0.6880 - val_loss: 0.5329 - val_acc: 0.7362\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 37s 1ms/step - loss: 0.4930 - acc: 0.7599 - val_loss: 0.4694 - val_acc: 0.7726\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 37s 1ms/step - loss: 0.4295 - acc: 0.8013 - val_loss: 0.4298 - val_acc: 0.8042\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 36s 1ms/step - loss: 0.3941 - acc: 0.8220 - val_loss: 0.4268 - val_acc: 0.8053\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 38s 1ms/step - loss: 0.3709 - acc: 0.8339 - val_loss: 0.4050 - val_acc: 0.8221\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 37s 1ms/step - loss: 0.3550 - acc: 0.8435 - val_loss: 0.3920 - val_acc: 0.8304\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 36s 1ms/step - loss: 0.3437 - acc: 0.8502 - val_loss: 0.4080 - val_acc: 0.8188\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 37s 1ms/step - loss: 0.3380 - acc: 0.8532 - val_loss: 0.3835 - val_acc: 0.8322\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 38s 1ms/step - loss: 0.3297 - acc: 0.8566 - val_loss: 0.3844 - val_acc: 0.8329\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 21s 605us/step - loss: 0.3236 - acc: 0.8597 - val_loss: 0.3946 - val_acc: 0.8263\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 14s 409us/step - loss: 0.3196 - acc: 0.8628 - val_loss: 0.3810 - val_acc: 0.8369\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3145 - acc: 0.8653 - val_loss: 0.3896 - val_acc: 0.8321\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 14s 410us/step - loss: 0.3112 - acc: 0.8680 - val_loss: 0.3813 - val_acc: 0.8338\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 408us/step - loss: 0.3073 - acc: 0.8690 - val_loss: 0.3928 - val_acc: 0.8312\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.3015 - acc: 0.8707 - val_loss: 0.3781 - val_acc: 0.8356\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 14s 410us/step - loss: 0.2976 - acc: 0.8743 - val_loss: 0.3893 - val_acc: 0.8340\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.2957 - acc: 0.8734 - val_loss: 0.3895 - val_acc: 0.8343\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.2944 - acc: 0.8757 - val_loss: 0.3959 - val_acc: 0.8327\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 14s 409us/step - loss: 0.2920 - acc: 0.8764 - val_loss: 0.3900 - val_acc: 0.8299\n",
      "kla-1h num dense 50 num motifs 100 pool size 10 dropout rate 0.75 param count 16252\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34841/34841 [==============================] - 15s 440us/step - loss: 0.6800 - acc: 0.5452 - val_loss: 0.6379 - val_acc: 0.6346\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 14s 413us/step - loss: 0.5953 - acc: 0.6809 - val_loss: 0.5396 - val_acc: 0.7300\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.5151 - acc: 0.7473 - val_loss: 0.4820 - val_acc: 0.7702\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.4600 - acc: 0.7856 - val_loss: 0.4448 - val_acc: 0.7911\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.4234 - acc: 0.8049 - val_loss: 0.4237 - val_acc: 0.8069\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.4019 - acc: 0.8177 - val_loss: 0.4213 - val_acc: 0.8075\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3822 - acc: 0.8286 - val_loss: 0.4028 - val_acc: 0.8183\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3711 - acc: 0.8371 - val_loss: 0.3999 - val_acc: 0.8226\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 14s 408us/step - loss: 0.3591 - acc: 0.8416 - val_loss: 0.4417 - val_acc: 0.7988\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3509 - acc: 0.8458 - val_loss: 0.3981 - val_acc: 0.8240\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3434 - acc: 0.8515 - val_loss: 0.3995 - val_acc: 0.8230\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3412 - acc: 0.8518 - val_loss: 0.3885 - val_acc: 0.8291\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3322 - acc: 0.8569 - val_loss: 0.4026 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3263 - acc: 0.8592 - val_loss: 0.3838 - val_acc: 0.8302\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.3230 - acc: 0.8602 - val_loss: 0.3929 - val_acc: 0.8277\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3202 - acc: 0.8634 - val_loss: 0.3825 - val_acc: 0.8334\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3162 - acc: 0.8649 - val_loss: 0.3934 - val_acc: 0.8273\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 14s 408us/step - loss: 0.3119 - acc: 0.8672 - val_loss: 0.3825 - val_acc: 0.8293\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3089 - acc: 0.8695 - val_loss: 0.3914 - val_acc: 0.8293\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3036 - acc: 0.8714 - val_loss: 0.3852 - val_acc: 0.8342\n",
      "kla-1h num dense 50 num motifs 100 pool size 20 dropout rate 0.25 param count 15452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.6529 - acc: 0.5914 - val_loss: 0.5620 - val_acc: 0.7073\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 13s 380us/step - loss: 0.5255 - acc: 0.7398 - val_loss: 0.4944 - val_acc: 0.7573\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 13s 376us/step - loss: 0.4684 - acc: 0.7786 - val_loss: 0.4618 - val_acc: 0.7768\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.4313 - acc: 0.8019 - val_loss: 0.4407 - val_acc: 0.7924\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.4071 - acc: 0.8140 - val_loss: 0.4331 - val_acc: 0.7977\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3902 - acc: 0.8250 - val_loss: 0.4322 - val_acc: 0.7981\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 13s 382us/step - loss: 0.3777 - acc: 0.8326 - val_loss: 0.4266 - val_acc: 0.8038\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 13s 376us/step - loss: 0.3669 - acc: 0.8389 - val_loss: 0.4270 - val_acc: 0.8024\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 13s 374us/step - loss: 0.3581 - acc: 0.8429 - val_loss: 0.4184 - val_acc: 0.8120\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 13s 380us/step - loss: 0.3528 - acc: 0.8433 - val_loss: 0.4294 - val_acc: 0.8063\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 13s 380us/step - loss: 0.3460 - acc: 0.8501 - val_loss: 0.4067 - val_acc: 0.8171\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3415 - acc: 0.8514 - val_loss: 0.4058 - val_acc: 0.8138\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 13s 379us/step - loss: 0.3351 - acc: 0.8563 - val_loss: 0.4035 - val_acc: 0.8167\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 13s 380us/step - loss: 0.3298 - acc: 0.8567 - val_loss: 0.4131 - val_acc: 0.8130\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 13s 383us/step - loss: 0.3278 - acc: 0.8579 - val_loss: 0.4132 - val_acc: 0.8148\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 13s 384us/step - loss: 0.3249 - acc: 0.8598 - val_loss: 0.4067 - val_acc: 0.8215\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 13s 382us/step - loss: 0.3203 - acc: 0.8635 - val_loss: 0.3994 - val_acc: 0.8201\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3147 - acc: 0.8661 - val_loss: 0.4017 - val_acc: 0.8216\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 13s 384us/step - loss: 0.3136 - acc: 0.8654 - val_loss: 0.4091 - val_acc: 0.8216\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.3123 - acc: 0.8663 - val_loss: 0.4114 - val_acc: 0.8186\n",
      "kla-1h num dense 50 num motifs 100 pool size 20 dropout rate 0.5 param count 15452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 14s 412us/step - loss: 0.6698 - acc: 0.5657 - val_loss: 0.5758 - val_acc: 0.7034\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 13s 382us/step - loss: 0.5313 - acc: 0.7388 - val_loss: 0.4936 - val_acc: 0.7629\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 13s 383us/step - loss: 0.4641 - acc: 0.7809 - val_loss: 0.4714 - val_acc: 0.7741\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 13s 385us/step - loss: 0.4257 - acc: 0.8049 - val_loss: 0.4441 - val_acc: 0.7896\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 13s 379us/step - loss: 0.3956 - acc: 0.8205 - val_loss: 0.4166 - val_acc: 0.8073\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 13s 377us/step - loss: 0.3818 - acc: 0.8284 - val_loss: 0.4174 - val_acc: 0.8071\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3709 - acc: 0.8363 - val_loss: 0.4133 - val_acc: 0.8092\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 13s 383us/step - loss: 0.3603 - acc: 0.8417 - val_loss: 0.4052 - val_acc: 0.8168\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3529 - acc: 0.8465 - val_loss: 0.4133 - val_acc: 0.8139\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 13s 383us/step - loss: 0.3462 - acc: 0.8477 - val_loss: 0.4062 - val_acc: 0.8161\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.3403 - acc: 0.8524 - val_loss: 0.3996 - val_acc: 0.8163\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3359 - acc: 0.8535 - val_loss: 0.4074 - val_acc: 0.8167\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3317 - acc: 0.8555 - val_loss: 0.4063 - val_acc: 0.8176\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 13s 377us/step - loss: 0.3255 - acc: 0.8592 - val_loss: 0.4035 - val_acc: 0.8192\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3225 - acc: 0.8611 - val_loss: 0.4013 - val_acc: 0.8186\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 13s 377us/step - loss: 0.3182 - acc: 0.8643 - val_loss: 0.3901 - val_acc: 0.8242\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3124 - acc: 0.8669 - val_loss: 0.4076 - val_acc: 0.8217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 13s 377us/step - loss: 0.3101 - acc: 0.8669 - val_loss: 0.3963 - val_acc: 0.8214\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3086 - acc: 0.8676 - val_loss: 0.3920 - val_acc: 0.8240\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 13s 377us/step - loss: 0.3046 - acc: 0.8707 - val_loss: 0.3998 - val_acc: 0.8253\n",
      "kla-1h num dense 50 num motifs 100 pool size 20 dropout rate 0.75 param count 15452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 14s 410us/step - loss: 0.6929 - acc: 0.5082 - val_loss: 0.6845 - val_acc: 0.5977\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.6121 - acc: 0.6650 - val_loss: 0.5594 - val_acc: 0.7115\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 13s 376us/step - loss: 0.5133 - acc: 0.7533 - val_loss: 0.4788 - val_acc: 0.7704\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 13s 379us/step - loss: 0.4575 - acc: 0.7897 - val_loss: 0.4753 - val_acc: 0.7717\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 13s 379us/step - loss: 0.4277 - acc: 0.8072 - val_loss: 0.4354 - val_acc: 0.7997\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.4128 - acc: 0.8144 - val_loss: 0.4292 - val_acc: 0.8036\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 13s 379us/step - loss: 0.3957 - acc: 0.8271 - val_loss: 0.4546 - val_acc: 0.7854\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 13s 380us/step - loss: 0.3867 - acc: 0.8294 - val_loss: 0.4180 - val_acc: 0.8125\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 13s 376us/step - loss: 0.3793 - acc: 0.8348 - val_loss: 0.4146 - val_acc: 0.8120\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3686 - acc: 0.8400 - val_loss: 0.4432 - val_acc: 0.8081\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.3667 - acc: 0.8408 - val_loss: 0.4204 - val_acc: 0.8090\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 13s 378us/step - loss: 0.3580 - acc: 0.8450 - val_loss: 0.4076 - val_acc: 0.8156\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 13s 381us/step - loss: 0.3537 - acc: 0.8473 - val_loss: 0.4080 - val_acc: 0.8141\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 13s 382us/step - loss: 0.3473 - acc: 0.8516 - val_loss: 0.4049 - val_acc: 0.8171\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 389us/step - loss: 0.3416 - acc: 0.8545 - val_loss: 0.4106 - val_acc: 0.8156\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 13s 386us/step - loss: 0.3410 - acc: 0.8553 - val_loss: 0.4111 - val_acc: 0.8176\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 13s 383us/step - loss: 0.3361 - acc: 0.8553 - val_loss: 0.4072 - val_acc: 0.8177\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 14s 388us/step - loss: 0.3308 - acc: 0.8585 - val_loss: 0.4158 - val_acc: 0.8178\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 13s 384us/step - loss: 0.3281 - acc: 0.8589 - val_loss: 0.4016 - val_acc: 0.8225\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 14s 388us/step - loss: 0.3247 - acc: 0.8607 - val_loss: 0.4120 - val_acc: 0.8198\n",
      "kla-1h num dense 50 num motifs 150 pool size 5 dropout rate 0.25 param count 25102\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 25s 731us/step - loss: 0.6591 - acc: 0.5911 - val_loss: 0.6113 - val_acc: 0.6665\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 25s 709us/step - loss: 0.5884 - acc: 0.6862 - val_loss: 0.5553 - val_acc: 0.7152\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 25s 715us/step - loss: 0.5142 - acc: 0.7470 - val_loss: 0.4830 - val_acc: 0.7677\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 25s 712us/step - loss: 0.4561 - acc: 0.7884 - val_loss: 0.4697 - val_acc: 0.7802\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 25s 711us/step - loss: 0.4224 - acc: 0.8056 - val_loss: 0.4280 - val_acc: 0.8011\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 25s 710us/step - loss: 0.3927 - acc: 0.8218 - val_loss: 0.4167 - val_acc: 0.8108\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 25s 711us/step - loss: 0.3722 - acc: 0.8350 - val_loss: 0.4338 - val_acc: 0.7999\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 25s 717us/step - loss: 0.3538 - acc: 0.8443 - val_loss: 0.4018 - val_acc: 0.8216\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 25s 707us/step - loss: 0.3398 - acc: 0.8531 - val_loss: 0.4004 - val_acc: 0.8206\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 25s 722us/step - loss: 0.3320 - acc: 0.8551 - val_loss: 0.3940 - val_acc: 0.8233\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 25s 716us/step - loss: 0.3203 - acc: 0.8610 - val_loss: 0.3891 - val_acc: 0.8295\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 25s 719us/step - loss: 0.3120 - acc: 0.8664 - val_loss: 0.4085 - val_acc: 0.8233\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 25s 720us/step - loss: 0.3069 - acc: 0.8669 - val_loss: 0.3977 - val_acc: 0.8262\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 25s 719us/step - loss: 0.3005 - acc: 0.8704 - val_loss: 0.3918 - val_acc: 0.8314\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 25s 729us/step - loss: 0.2939 - acc: 0.8756 - val_loss: 0.4019 - val_acc: 0.8254\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 25s 723us/step - loss: 0.2899 - acc: 0.8770 - val_loss: 0.4275 - val_acc: 0.8120\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 25s 720us/step - loss: 0.2812 - acc: 0.8815 - val_loss: 0.3967 - val_acc: 0.8331\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 25s 724us/step - loss: 0.2773 - acc: 0.8833 - val_loss: 0.4198 - val_acc: 0.8201\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 25s 716us/step - loss: 0.2731 - acc: 0.8846 - val_loss: 0.4189 - val_acc: 0.8185\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 25s 720us/step - loss: 0.2656 - acc: 0.8888 - val_loss: 0.4025 - val_acc: 0.8314\n",
      "kla-1h num dense 50 num motifs 150 pool size 5 dropout rate 0.5 param count 25102\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 27s 764us/step - loss: 0.6687 - acc: 0.5745 - val_loss: 0.6407 - val_acc: 0.6419\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 25s 728us/step - loss: 0.6021 - acc: 0.6720 - val_loss: 0.5873 - val_acc: 0.6821\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 25s 730us/step - loss: 0.5414 - acc: 0.7258 - val_loss: 0.5418 - val_acc: 0.7229\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 25s 729us/step - loss: 0.4839 - acc: 0.7693 - val_loss: 0.4892 - val_acc: 0.7650\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 25s 728us/step - loss: 0.4330 - acc: 0.7999 - val_loss: 0.4366 - val_acc: 0.7984\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 25s 729us/step - loss: 0.4001 - acc: 0.8184 - val_loss: 0.4241 - val_acc: 0.8105\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 25s 723us/step - loss: 0.3756 - acc: 0.8330 - val_loss: 0.4077 - val_acc: 0.8151\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 25s 722us/step - loss: 0.3607 - acc: 0.8395 - val_loss: 0.3972 - val_acc: 0.8228\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 25s 727us/step - loss: 0.3462 - acc: 0.8464 - val_loss: 0.3985 - val_acc: 0.8218\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 25s 729us/step - loss: 0.3334 - acc: 0.8540 - val_loss: 0.4241 - val_acc: 0.8106\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 25s 724us/step - loss: 0.3224 - acc: 0.8620 - val_loss: 0.4181 - val_acc: 0.8152\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 25s 725us/step - loss: 0.3180 - acc: 0.8626 - val_loss: 0.3983 - val_acc: 0.8277\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 25s 731us/step - loss: 0.3091 - acc: 0.8664 - val_loss: 0.4267 - val_acc: 0.8135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 25s 722us/step - loss: 0.3038 - acc: 0.8691 - val_loss: 0.3910 - val_acc: 0.8341\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 25s 728us/step - loss: 0.2960 - acc: 0.8736 - val_loss: 0.4127 - val_acc: 0.8250\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 25s 722us/step - loss: 0.2929 - acc: 0.8753 - val_loss: 0.4083 - val_acc: 0.8284\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 25s 724us/step - loss: 0.2868 - acc: 0.8765 - val_loss: 0.4005 - val_acc: 0.8323\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 25s 723us/step - loss: 0.2827 - acc: 0.8800 - val_loss: 0.3968 - val_acc: 0.8330\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 25s 713us/step - loss: 0.2781 - acc: 0.8819 - val_loss: 0.3994 - val_acc: 0.8309\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 25s 718us/step - loss: 0.2742 - acc: 0.8830 - val_loss: 0.3988 - val_acc: 0.8300\n",
      "kla-1h num dense 50 num motifs 150 pool size 5 dropout rate 0.75 param count 25102\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 26s 754us/step - loss: 0.6740 - acc: 0.5613 - val_loss: 0.6343 - val_acc: 0.6363\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 25s 714us/step - loss: 0.6011 - acc: 0.6762 - val_loss: 0.5529 - val_acc: 0.7240\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 25s 706us/step - loss: 0.5290 - acc: 0.7385 - val_loss: 0.4997 - val_acc: 0.7585\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 25s 706us/step - loss: 0.4693 - acc: 0.7778 - val_loss: 0.4542 - val_acc: 0.7905\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 25s 713us/step - loss: 0.4303 - acc: 0.8023 - val_loss: 0.4357 - val_acc: 0.7988\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 25s 707us/step - loss: 0.4006 - acc: 0.8181 - val_loss: 0.4187 - val_acc: 0.8116\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 25s 705us/step - loss: 0.3846 - acc: 0.8289 - val_loss: 0.4112 - val_acc: 0.8129\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 25s 710us/step - loss: 0.3637 - acc: 0.8386 - val_loss: 0.4223 - val_acc: 0.8077\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 24s 702us/step - loss: 0.3524 - acc: 0.8460 - val_loss: 0.3983 - val_acc: 0.8230\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 25s 713us/step - loss: 0.3393 - acc: 0.8507 - val_loss: 0.4001 - val_acc: 0.8223\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 25s 707us/step - loss: 0.3331 - acc: 0.8551 - val_loss: 0.3886 - val_acc: 0.8275\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 25s 705us/step - loss: 0.3232 - acc: 0.8613 - val_loss: 0.3894 - val_acc: 0.8272\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 25s 706us/step - loss: 0.3190 - acc: 0.8648 - val_loss: 0.3871 - val_acc: 0.8322\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 25s 707us/step - loss: 0.3105 - acc: 0.8672 - val_loss: 0.3825 - val_acc: 0.8311\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 24s 703us/step - loss: 0.3079 - acc: 0.8674 - val_loss: 0.3846 - val_acc: 0.8324\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 24s 700us/step - loss: 0.3056 - acc: 0.8674 - val_loss: 0.4154 - val_acc: 0.8174\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 24s 699us/step - loss: 0.2995 - acc: 0.8733 - val_loss: 0.3940 - val_acc: 0.8299\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 24s 702us/step - loss: 0.2930 - acc: 0.8748 - val_loss: 0.3855 - val_acc: 0.8268\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 24s 698us/step - loss: 0.2932 - acc: 0.8754 - val_loss: 0.3889 - val_acc: 0.8309\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 25s 709us/step - loss: 0.2907 - acc: 0.8743 - val_loss: 0.3858 - val_acc: 0.8327\n",
      "kla-1h num dense 50 num motifs 150 pool size 10 dropout rate 0.25 param count 23602\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 21s 614us/step - loss: 0.6325 - acc: 0.6192 - val_loss: 0.5711 - val_acc: 0.7059\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 20s 574us/step - loss: 0.5084 - acc: 0.7524 - val_loss: 0.4994 - val_acc: 0.7536\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 20s 574us/step - loss: 0.4513 - acc: 0.7897 - val_loss: 0.4424 - val_acc: 0.7955\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 20s 575us/step - loss: 0.4109 - acc: 0.8106 - val_loss: 0.4191 - val_acc: 0.8105\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.3796 - acc: 0.8306 - val_loss: 0.4059 - val_acc: 0.8219\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 20s 567us/step - loss: 0.3628 - acc: 0.8380 - val_loss: 0.4084 - val_acc: 0.8146\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.3472 - acc: 0.8458 - val_loss: 0.4080 - val_acc: 0.8179\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 20s 566us/step - loss: 0.3341 - acc: 0.8545 - val_loss: 0.4012 - val_acc: 0.8190\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 20s 574us/step - loss: 0.3247 - acc: 0.8603 - val_loss: 0.4337 - val_acc: 0.8066\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 20s 575us/step - loss: 0.3176 - acc: 0.8638 - val_loss: 0.4152 - val_acc: 0.8159\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.3125 - acc: 0.8657 - val_loss: 0.3924 - val_acc: 0.8283\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 20s 568us/step - loss: 0.3048 - acc: 0.8712 - val_loss: 0.3899 - val_acc: 0.8298\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2969 - acc: 0.8733 - val_loss: 0.3920 - val_acc: 0.8290\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2954 - acc: 0.8739 - val_loss: 0.3888 - val_acc: 0.8299\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.2915 - acc: 0.8755 - val_loss: 0.3905 - val_acc: 0.8283\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2828 - acc: 0.8798 - val_loss: 0.3950 - val_acc: 0.8267\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 20s 570us/step - loss: 0.2787 - acc: 0.8810 - val_loss: 0.4007 - val_acc: 0.8312\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2763 - acc: 0.8838 - val_loss: 0.4070 - val_acc: 0.8268\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 20s 566us/step - loss: 0.2737 - acc: 0.8852 - val_loss: 0.4002 - val_acc: 0.8326\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 20s 575us/step - loss: 0.2739 - acc: 0.8841 - val_loss: 0.4082 - val_acc: 0.8285\n",
      "kla-1h num dense 50 num motifs 150 pool size 10 dropout rate 0.5 param count 23602\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 22s 618us/step - loss: 0.6677 - acc: 0.5676 - val_loss: 0.6100 - val_acc: 0.6576\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 20s 575us/step - loss: 0.5467 - acc: 0.7200 - val_loss: 0.5165 - val_acc: 0.7407\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 20s 575us/step - loss: 0.4590 - acc: 0.7837 - val_loss: 0.4981 - val_acc: 0.7603\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.4073 - acc: 0.8134 - val_loss: 0.4380 - val_acc: 0.7945\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.3817 - acc: 0.8284 - val_loss: 0.4055 - val_acc: 0.8156\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 20s 568us/step - loss: 0.3626 - acc: 0.8398 - val_loss: 0.4042 - val_acc: 0.8207\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 20s 574us/step - loss: 0.3444 - acc: 0.8486 - val_loss: 0.3912 - val_acc: 0.8284\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 20s 570us/step - loss: 0.3344 - acc: 0.8557 - val_loss: 0.3813 - val_acc: 0.8312\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.3263 - acc: 0.8596 - val_loss: 0.3916 - val_acc: 0.8262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 20s 572us/step - loss: 0.3155 - acc: 0.8643 - val_loss: 0.3926 - val_acc: 0.8246\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 20s 567us/step - loss: 0.3059 - acc: 0.8711 - val_loss: 0.3805 - val_acc: 0.8350\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 20s 568us/step - loss: 0.3033 - acc: 0.8696 - val_loss: 0.3912 - val_acc: 0.8287\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.2946 - acc: 0.8760 - val_loss: 0.3762 - val_acc: 0.8323\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 20s 572us/step - loss: 0.2882 - acc: 0.8787 - val_loss: 0.3838 - val_acc: 0.8386\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2834 - acc: 0.8797 - val_loss: 0.4080 - val_acc: 0.8224\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2775 - acc: 0.8843 - val_loss: 0.3981 - val_acc: 0.8279\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2781 - acc: 0.8827 - val_loss: 0.3866 - val_acc: 0.8340\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 20s 570us/step - loss: 0.2717 - acc: 0.8871 - val_loss: 0.3832 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 20s 571us/step - loss: 0.2698 - acc: 0.8877 - val_loss: 0.3896 - val_acc: 0.8370\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 20s 577us/step - loss: 0.2660 - acc: 0.8898 - val_loss: 0.3863 - val_acc: 0.8346\n",
      "kla-1h num dense 50 num motifs 150 pool size 10 dropout rate 0.75 param count 23602\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 22s 619us/step - loss: 0.6802 - acc: 0.5501 - val_loss: 0.6408 - val_acc: 0.6279\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 20s 572us/step - loss: 0.5878 - acc: 0.6884 - val_loss: 0.5356 - val_acc: 0.7381\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 20s 572us/step - loss: 0.4902 - acc: 0.7678 - val_loss: 0.4543 - val_acc: 0.7900\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 20s 568us/step - loss: 0.4283 - acc: 0.8058 - val_loss: 0.4184 - val_acc: 0.8078\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 20s 566us/step - loss: 0.3909 - acc: 0.8269 - val_loss: 0.4068 - val_acc: 0.8137\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 20s 563us/step - loss: 0.3667 - acc: 0.8399 - val_loss: 0.3898 - val_acc: 0.8236\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 20s 567us/step - loss: 0.3516 - acc: 0.8467 - val_loss: 0.3812 - val_acc: 0.8285\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 20s 564us/step - loss: 0.3414 - acc: 0.8518 - val_loss: 0.3905 - val_acc: 0.8302\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 20s 566us/step - loss: 0.3331 - acc: 0.8568 - val_loss: 0.4247 - val_acc: 0.8098\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 20s 568us/step - loss: 0.3221 - acc: 0.8634 - val_loss: 0.3784 - val_acc: 0.8330\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 20s 575us/step - loss: 0.3151 - acc: 0.8671 - val_loss: 0.3863 - val_acc: 0.8307\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 20s 579us/step - loss: 0.3082 - acc: 0.8714 - val_loss: 0.4151 - val_acc: 0.8176\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 20s 573us/step - loss: 0.3055 - acc: 0.8717 - val_loss: 0.3800 - val_acc: 0.8349\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.3014 - acc: 0.8737 - val_loss: 0.3789 - val_acc: 0.8362\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.2938 - acc: 0.8776 - val_loss: 0.3776 - val_acc: 0.8357\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 20s 573us/step - loss: 0.2920 - acc: 0.8779 - val_loss: 0.3798 - val_acc: 0.8372\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 20s 572us/step - loss: 0.2894 - acc: 0.8787 - val_loss: 0.3786 - val_acc: 0.8319\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 20s 570us/step - loss: 0.2839 - acc: 0.8825 - val_loss: 0.4019 - val_acc: 0.8222\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 20s 569us/step - loss: 0.2805 - acc: 0.8836 - val_loss: 0.3826 - val_acc: 0.8364\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 20s 567us/step - loss: 0.2760 - acc: 0.8850 - val_loss: 0.3768 - val_acc: 0.8377\n",
      "kla-1h num dense 50 num motifs 150 pool size 20 dropout rate 0.25 param count 22802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 20s 565us/step - loss: 0.6540 - acc: 0.5907 - val_loss: 0.5558 - val_acc: 0.7145\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 18s 524us/step - loss: 0.5050 - acc: 0.7519 - val_loss: 0.4697 - val_acc: 0.7751\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 18s 528us/step - loss: 0.4420 - acc: 0.7952 - val_loss: 0.4420 - val_acc: 0.7949\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 18s 528us/step - loss: 0.4061 - acc: 0.8145 - val_loss: 0.4237 - val_acc: 0.8065\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 18s 528us/step - loss: 0.3845 - acc: 0.8254 - val_loss: 0.4119 - val_acc: 0.8120\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 18s 527us/step - loss: 0.3647 - acc: 0.8393 - val_loss: 0.4153 - val_acc: 0.8151\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 18s 524us/step - loss: 0.3511 - acc: 0.8454 - val_loss: 0.4044 - val_acc: 0.8215\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 18s 525us/step - loss: 0.3381 - acc: 0.8522 - val_loss: 0.4233 - val_acc: 0.8065\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.3297 - acc: 0.8564 - val_loss: 0.4003 - val_acc: 0.8219\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 19s 537us/step - loss: 0.3235 - acc: 0.8585 - val_loss: 0.3982 - val_acc: 0.8215\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.3157 - acc: 0.8633 - val_loss: 0.3959 - val_acc: 0.8270\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.3081 - acc: 0.8689 - val_loss: 0.4052 - val_acc: 0.8240\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.3046 - acc: 0.8681 - val_loss: 0.3933 - val_acc: 0.8287\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 19s 535us/step - loss: 0.3005 - acc: 0.8719 - val_loss: 0.4027 - val_acc: 0.8275\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 19s 535us/step - loss: 0.2913 - acc: 0.8762 - val_loss: 0.4220 - val_acc: 0.8209\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.2879 - acc: 0.8779 - val_loss: 0.4197 - val_acc: 0.8170\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 19s 537us/step - loss: 0.2863 - acc: 0.8801 - val_loss: 0.4286 - val_acc: 0.8201\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 19s 540us/step - loss: 0.2859 - acc: 0.8788 - val_loss: 0.4071 - val_acc: 0.8233\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.2776 - acc: 0.8837 - val_loss: 0.4224 - val_acc: 0.8176\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 18s 527us/step - loss: 0.2754 - acc: 0.8838 - val_loss: 0.4433 - val_acc: 0.8177\n",
      "kla-1h num dense 50 num motifs 150 pool size 20 dropout rate 0.5 param count 22802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 20s 588us/step - loss: 0.6633 - acc: 0.5738 - val_loss: 0.5560 - val_acc: 0.7169\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 18s 529us/step - loss: 0.5243 - acc: 0.7436 - val_loss: 0.4843 - val_acc: 0.7672\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 18s 530us/step - loss: 0.4536 - acc: 0.7887 - val_loss: 0.4478 - val_acc: 0.7892\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 18s 529us/step - loss: 0.4151 - acc: 0.8124 - val_loss: 0.4507 - val_acc: 0.7859\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 18s 530us/step - loss: 0.3900 - acc: 0.8266 - val_loss: 0.4219 - val_acc: 0.8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 18s 526us/step - loss: 0.3692 - acc: 0.8365 - val_loss: 0.4265 - val_acc: 0.8074\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 19s 531us/step - loss: 0.3564 - acc: 0.8446 - val_loss: 0.4234 - val_acc: 0.8114\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 18s 527us/step - loss: 0.3482 - acc: 0.8499 - val_loss: 0.4301 - val_acc: 0.8043\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 19s 531us/step - loss: 0.3412 - acc: 0.8528 - val_loss: 0.4117 - val_acc: 0.8152\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 18s 527us/step - loss: 0.3300 - acc: 0.8594 - val_loss: 0.4118 - val_acc: 0.8174\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.3219 - acc: 0.8644 - val_loss: 0.4130 - val_acc: 0.8175\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 18s 529us/step - loss: 0.3140 - acc: 0.8665 - val_loss: 0.4158 - val_acc: 0.8199\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.3130 - acc: 0.8671 - val_loss: 0.4259 - val_acc: 0.8179\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 19s 531us/step - loss: 0.3068 - acc: 0.8714 - val_loss: 0.4144 - val_acc: 0.8232\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 19s 539us/step - loss: 0.3027 - acc: 0.8720 - val_loss: 0.4338 - val_acc: 0.8121\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.3009 - acc: 0.8732 - val_loss: 0.4092 - val_acc: 0.8215\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 19s 537us/step - loss: 0.2935 - acc: 0.8764 - val_loss: 0.4450 - val_acc: 0.8068\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 19s 540us/step - loss: 0.2928 - acc: 0.8764 - val_loss: 0.4207 - val_acc: 0.8208\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 19s 536us/step - loss: 0.2873 - acc: 0.8813 - val_loss: 0.4277 - val_acc: 0.8239\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 19s 537us/step - loss: 0.2849 - acc: 0.8803 - val_loss: 0.4385 - val_acc: 0.8186\n",
      "kla-1h num dense 50 num motifs 150 pool size 20 dropout rate 0.75 param count 22802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 20s 585us/step - loss: 0.6933 - acc: 0.4984 - val_loss: 0.6930 - val_acc: 0.5001\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.6352 - acc: 0.6206 - val_loss: 0.5386 - val_acc: 0.7268\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.5069 - acc: 0.7589 - val_loss: 0.4601 - val_acc: 0.7828\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.4410 - acc: 0.7989 - val_loss: 0.4260 - val_acc: 0.8008\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 19s 531us/step - loss: 0.4090 - acc: 0.8194 - val_loss: 0.4094 - val_acc: 0.8148\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 19s 533us/step - loss: 0.3886 - acc: 0.8297 - val_loss: 0.4012 - val_acc: 0.8171\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 18s 531us/step - loss: 0.3698 - acc: 0.8393 - val_loss: 0.3998 - val_acc: 0.8231\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 18s 530us/step - loss: 0.3629 - acc: 0.8447 - val_loss: 0.3922 - val_acc: 0.8262\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 19s 535us/step - loss: 0.3503 - acc: 0.8496 - val_loss: 0.3907 - val_acc: 0.8252\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 19s 534us/step - loss: 0.3418 - acc: 0.8538 - val_loss: 0.3880 - val_acc: 0.8259\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 19s 538us/step - loss: 0.3342 - acc: 0.8587 - val_loss: 0.3991 - val_acc: 0.8170\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 19s 546us/step - loss: 0.3258 - acc: 0.8641 - val_loss: 0.3892 - val_acc: 0.8295\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 19s 540us/step - loss: 0.3199 - acc: 0.8656 - val_loss: 0.3897 - val_acc: 0.8293\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 19s 536us/step - loss: 0.3183 - acc: 0.8664 - val_loss: 0.3916 - val_acc: 0.8286\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 19s 543us/step - loss: 0.3106 - acc: 0.8708 - val_loss: 0.3849 - val_acc: 0.8298\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 19s 539us/step - loss: 0.3069 - acc: 0.8709 - val_loss: 0.4037 - val_acc: 0.8224\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 19s 543us/step - loss: 0.3055 - acc: 0.8728 - val_loss: 0.3894 - val_acc: 0.8321\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 19s 543us/step - loss: 0.2990 - acc: 0.8761 - val_loss: 0.3844 - val_acc: 0.8316\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 19s 545us/step - loss: 0.2959 - acc: 0.8774 - val_loss: 0.3926 - val_acc: 0.8311\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 19s 544us/step - loss: 0.2966 - acc: 0.8766 - val_loss: 0.3855 - val_acc: 0.8346\n",
      "kla-1h num dense 100 num motifs 50 pool size 5 dropout rate 0.25 param count 18452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 15s 424us/step - loss: 0.6637 - acc: 0.5776 - val_loss: 0.6179 - val_acc: 0.6533\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 13s 365us/step - loss: 0.5816 - acc: 0.6913 - val_loss: 0.5485 - val_acc: 0.7176\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 13s 362us/step - loss: 0.5233 - acc: 0.7376 - val_loss: 0.5032 - val_acc: 0.7535\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 12s 357us/step - loss: 0.4833 - acc: 0.7669 - val_loss: 0.4834 - val_acc: 0.7693\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 12s 356us/step - loss: 0.4508 - acc: 0.7888 - val_loss: 0.4584 - val_acc: 0.7833\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 12s 356us/step - loss: 0.4326 - acc: 0.7997 - val_loss: 0.4452 - val_acc: 0.7905\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.4142 - acc: 0.8094 - val_loss: 0.4343 - val_acc: 0.7985\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.4061 - acc: 0.8163 - val_loss: 0.4377 - val_acc: 0.7978\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.3964 - acc: 0.8202 - val_loss: 0.4361 - val_acc: 0.8003\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3903 - acc: 0.8233 - val_loss: 0.4301 - val_acc: 0.8001\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3812 - acc: 0.8280 - val_loss: 0.4296 - val_acc: 0.8042\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3778 - acc: 0.8303 - val_loss: 0.4212 - val_acc: 0.8093\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3715 - acc: 0.8342 - val_loss: 0.4423 - val_acc: 0.7977\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3658 - acc: 0.8388 - val_loss: 0.4183 - val_acc: 0.8121\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.3611 - acc: 0.8384 - val_loss: 0.4271 - val_acc: 0.8081\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3611 - acc: 0.8388 - val_loss: 0.4256 - val_acc: 0.8090\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3554 - acc: 0.8425 - val_loss: 0.4259 - val_acc: 0.8053\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.3508 - acc: 0.8448 - val_loss: 0.5179 - val_acc: 0.7703\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 12s 355us/step - loss: 0.3524 - acc: 0.8451 - val_loss: 0.4450 - val_acc: 0.7997\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 12s 356us/step - loss: 0.3436 - acc: 0.8482 - val_loss: 0.4180 - val_acc: 0.8110\n",
      "kla-1h num dense 100 num motifs 50 pool size 5 dropout rate 0.5 param count 18452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 14s 412us/step - loss: 0.6846 - acc: 0.5378 - val_loss: 0.6521 - val_acc: 0.6124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 12s 357us/step - loss: 0.6189 - acc: 0.6570 - val_loss: 0.5899 - val_acc: 0.6834\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.5457 - acc: 0.7261 - val_loss: 0.5111 - val_acc: 0.7540\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.4918 - acc: 0.7633 - val_loss: 0.4785 - val_acc: 0.7747\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 12s 356us/step - loss: 0.4589 - acc: 0.7862 - val_loss: 0.4647 - val_acc: 0.7789\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.4392 - acc: 0.7978 - val_loss: 0.4599 - val_acc: 0.7782\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.4221 - acc: 0.8087 - val_loss: 0.4380 - val_acc: 0.7945\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.4105 - acc: 0.8121 - val_loss: 0.4507 - val_acc: 0.7888\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3986 - acc: 0.8193 - val_loss: 0.4330 - val_acc: 0.7983\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3889 - acc: 0.8258 - val_loss: 0.4365 - val_acc: 0.7968\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3827 - acc: 0.8274 - val_loss: 0.4123 - val_acc: 0.8116\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3752 - acc: 0.8321 - val_loss: 0.4135 - val_acc: 0.8122\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3675 - acc: 0.8369 - val_loss: 0.4332 - val_acc: 0.8028\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3577 - acc: 0.8407 - val_loss: 0.4061 - val_acc: 0.8200\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.3512 - acc: 0.8458 - val_loss: 0.4023 - val_acc: 0.8191\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3469 - acc: 0.8474 - val_loss: 0.4047 - val_acc: 0.8192\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 12s 348us/step - loss: 0.3426 - acc: 0.8503 - val_loss: 0.3998 - val_acc: 0.8209\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 12s 348us/step - loss: 0.3406 - acc: 0.8501 - val_loss: 0.4019 - val_acc: 0.8236\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3334 - acc: 0.8534 - val_loss: 0.3963 - val_acc: 0.8252\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3335 - acc: 0.8545 - val_loss: 0.4248 - val_acc: 0.8153\n",
      "kla-1h num dense 100 num motifs 50 pool size 5 dropout rate 0.75 param count 18452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 14s 413us/step - loss: 0.6712 - acc: 0.5682 - val_loss: 0.6118 - val_acc: 0.6675\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.5772 - acc: 0.6979 - val_loss: 0.5574 - val_acc: 0.7094\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.5120 - acc: 0.7488 - val_loss: 0.4881 - val_acc: 0.7624\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.4765 - acc: 0.7741 - val_loss: 0.4869 - val_acc: 0.7640\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 12s 352us/step - loss: 0.4520 - acc: 0.7886 - val_loss: 0.4508 - val_acc: 0.7891\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.4405 - acc: 0.7963 - val_loss: 0.4518 - val_acc: 0.7876\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.4240 - acc: 0.8064 - val_loss: 0.4336 - val_acc: 0.7965\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.4059 - acc: 0.8165 - val_loss: 0.4394 - val_acc: 0.7947\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3970 - acc: 0.8217 - val_loss: 0.4144 - val_acc: 0.8129\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 12s 354us/step - loss: 0.3872 - acc: 0.8268 - val_loss: 0.4186 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3794 - acc: 0.8300 - val_loss: 0.4087 - val_acc: 0.8155\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3735 - acc: 0.8323 - val_loss: 0.4015 - val_acc: 0.8202\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3673 - acc: 0.8370 - val_loss: 0.4113 - val_acc: 0.8130\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 12s 351us/step - loss: 0.3622 - acc: 0.8404 - val_loss: 0.4037 - val_acc: 0.8172\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3566 - acc: 0.8415 - val_loss: 0.3890 - val_acc: 0.8290\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3530 - acc: 0.8455 - val_loss: 0.3881 - val_acc: 0.8277\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 12s 353us/step - loss: 0.3485 - acc: 0.8462 - val_loss: 0.3939 - val_acc: 0.8281\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3443 - acc: 0.8497 - val_loss: 0.3881 - val_acc: 0.8296\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 12s 350us/step - loss: 0.3429 - acc: 0.8511 - val_loss: 0.3833 - val_acc: 0.8334\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 12s 349us/step - loss: 0.3387 - acc: 0.8510 - val_loss: 0.3858 - val_acc: 0.8269\n",
      "kla-1h num dense 100 num motifs 50 pool size 10 dropout rate 0.25 param count 15452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 13s 379us/step - loss: 0.6707 - acc: 0.5632 - val_loss: 0.6198 - val_acc: 0.6577\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.5863 - acc: 0.6877 - val_loss: 0.5658 - val_acc: 0.7066\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.5197 - acc: 0.7439 - val_loss: 0.4962 - val_acc: 0.7570\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4717 - acc: 0.7760 - val_loss: 0.4710 - val_acc: 0.7761\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4426 - acc: 0.7912 - val_loss: 0.4816 - val_acc: 0.7711\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4215 - acc: 0.8068 - val_loss: 0.4461 - val_acc: 0.7918\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.4068 - acc: 0.8152 - val_loss: 0.4354 - val_acc: 0.7961\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3942 - acc: 0.8216 - val_loss: 0.4395 - val_acc: 0.7958\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3861 - acc: 0.8260 - val_loss: 0.4256 - val_acc: 0.8044\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.3725 - acc: 0.8330 - val_loss: 0.4124 - val_acc: 0.8186\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3648 - acc: 0.8367 - val_loss: 0.4065 - val_acc: 0.8209\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 310us/step - loss: 0.3575 - acc: 0.8422 - val_loss: 0.4075 - val_acc: 0.8240\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3507 - acc: 0.8441 - val_loss: 0.4150 - val_acc: 0.8172\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.3470 - acc: 0.8482 - val_loss: 0.3997 - val_acc: 0.8261\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.3421 - acc: 0.8510 - val_loss: 0.4016 - val_acc: 0.8298\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3396 - acc: 0.8518 - val_loss: 0.4176 - val_acc: 0.8172\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3333 - acc: 0.8548 - val_loss: 0.4126 - val_acc: 0.8193\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3309 - acc: 0.8565 - val_loss: 0.3953 - val_acc: 0.8265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3267 - acc: 0.8595 - val_loss: 0.4036 - val_acc: 0.8221\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3284 - acc: 0.8572 - val_loss: 0.3896 - val_acc: 0.8299\n",
      "kla-1h num dense 100 num motifs 50 pool size 10 dropout rate 0.5 param count 15452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 13s 368us/step - loss: 0.6661 - acc: 0.5714 - val_loss: 0.6082 - val_acc: 0.6750\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.5590 - acc: 0.7140 - val_loss: 0.5241 - val_acc: 0.7392\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.4978 - acc: 0.7607 - val_loss: 0.4791 - val_acc: 0.7685\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.4672 - acc: 0.7786 - val_loss: 0.4720 - val_acc: 0.7733\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.4418 - acc: 0.7923 - val_loss: 0.4415 - val_acc: 0.7950\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 11s 312us/step - loss: 0.4235 - acc: 0.8042 - val_loss: 0.4335 - val_acc: 0.7990\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.4089 - acc: 0.8123 - val_loss: 0.4201 - val_acc: 0.8086\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3988 - acc: 0.8171 - val_loss: 0.4364 - val_acc: 0.7955\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3882 - acc: 0.8237 - val_loss: 0.4087 - val_acc: 0.8137\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3827 - acc: 0.8278 - val_loss: 0.4063 - val_acc: 0.8128\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3766 - acc: 0.8311 - val_loss: 0.4094 - val_acc: 0.8117\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3699 - acc: 0.8347 - val_loss: 0.4166 - val_acc: 0.8099\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3640 - acc: 0.8377 - val_loss: 0.4049 - val_acc: 0.8148\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3598 - acc: 0.8392 - val_loss: 0.3943 - val_acc: 0.8213\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3556 - acc: 0.8433 - val_loss: 0.4014 - val_acc: 0.8176\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3560 - acc: 0.8407 - val_loss: 0.3972 - val_acc: 0.8209\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 311us/step - loss: 0.3500 - acc: 0.8431 - val_loss: 0.3967 - val_acc: 0.8223\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 316us/step - loss: 0.3484 - acc: 0.8462 - val_loss: 0.3970 - val_acc: 0.8226\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3459 - acc: 0.8493 - val_loss: 0.4038 - val_acc: 0.8153\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 317us/step - loss: 0.3411 - acc: 0.8500 - val_loss: 0.3891 - val_acc: 0.8238\n",
      "kla-1h num dense 100 num motifs 50 pool size 10 dropout rate 0.75 param count 15452\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 13s 375us/step - loss: 0.6645 - acc: 0.5746 - val_loss: 0.5919 - val_acc: 0.6863\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.5659 - acc: 0.7101 - val_loss: 0.5268 - val_acc: 0.7410\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.4949 - acc: 0.7608 - val_loss: 0.5267 - val_acc: 0.7363\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 317us/step - loss: 0.4515 - acc: 0.7892 - val_loss: 0.4463 - val_acc: 0.7913\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.4190 - acc: 0.8075 - val_loss: 0.4328 - val_acc: 0.8016\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 11s 317us/step - loss: 0.4072 - acc: 0.8165 - val_loss: 0.4205 - val_acc: 0.8078\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 317us/step - loss: 0.3922 - acc: 0.8231 - val_loss: 0.4134 - val_acc: 0.8122\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 316us/step - loss: 0.3825 - acc: 0.8303 - val_loss: 0.4053 - val_acc: 0.8180\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3758 - acc: 0.8330 - val_loss: 0.4108 - val_acc: 0.8128\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3649 - acc: 0.8386 - val_loss: 0.4006 - val_acc: 0.8219\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 11s 314us/step - loss: 0.3626 - acc: 0.8393 - val_loss: 0.3940 - val_acc: 0.8238\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3564 - acc: 0.8425 - val_loss: 0.3946 - val_acc: 0.8244\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3530 - acc: 0.8463 - val_loss: 0.3921 - val_acc: 0.8242\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3459 - acc: 0.8503 - val_loss: 0.3936 - val_acc: 0.8256\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 11s 316us/step - loss: 0.3465 - acc: 0.8472 - val_loss: 0.3923 - val_acc: 0.8278\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3409 - acc: 0.8516 - val_loss: 0.4030 - val_acc: 0.8171\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3373 - acc: 0.8530 - val_loss: 0.3879 - val_acc: 0.8254\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 313us/step - loss: 0.3369 - acc: 0.8541 - val_loss: 0.3826 - val_acc: 0.8314\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3335 - acc: 0.8538 - val_loss: 0.3916 - val_acc: 0.8262\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 11s 315us/step - loss: 0.3320 - acc: 0.8559 - val_loss: 0.4043 - val_acc: 0.8199\n",
      "kla-1h num dense 100 num motifs 50 pool size 20 dropout rate 0.25 param count 13852\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 14s 390us/step - loss: 0.6553 - acc: 0.5883 - val_loss: 0.5860 - val_acc: 0.6780\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.5327 - acc: 0.7304 - val_loss: 0.5120 - val_acc: 0.7447\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.4786 - acc: 0.7699 - val_loss: 0.4785 - val_acc: 0.7701\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4528 - acc: 0.7875 - val_loss: 0.4482 - val_acc: 0.7876\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.4280 - acc: 0.8014 - val_loss: 0.4470 - val_acc: 0.7881\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4119 - acc: 0.8114 - val_loss: 0.4348 - val_acc: 0.7957\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.4017 - acc: 0.8170 - val_loss: 0.4738 - val_acc: 0.7724\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3964 - acc: 0.8210 - val_loss: 0.4218 - val_acc: 0.8062\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3853 - acc: 0.8272 - val_loss: 0.4138 - val_acc: 0.8110\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3789 - acc: 0.8297 - val_loss: 0.4081 - val_acc: 0.8149\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3690 - acc: 0.8368 - val_loss: 0.4064 - val_acc: 0.8149\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3677 - acc: 0.8367 - val_loss: 0.4106 - val_acc: 0.8135\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3632 - acc: 0.8406 - val_loss: 0.4050 - val_acc: 0.8149\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 10s 295us/step - loss: 0.3601 - acc: 0.8403 - val_loss: 0.4067 - val_acc: 0.8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3563 - acc: 0.8423 - val_loss: 0.4273 - val_acc: 0.8052\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.3499 - acc: 0.8449 - val_loss: 0.4016 - val_acc: 0.8188\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3475 - acc: 0.8466 - val_loss: 0.3953 - val_acc: 0.8188\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3449 - acc: 0.8475 - val_loss: 0.4230 - val_acc: 0.8155\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3449 - acc: 0.8463 - val_loss: 0.3990 - val_acc: 0.8223\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 10s 295us/step - loss: 0.3381 - acc: 0.8508 - val_loss: 0.3979 - val_acc: 0.8240\n",
      "kla-1h num dense 100 num motifs 50 pool size 20 dropout rate 0.5 param count 13852\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 12s 358us/step - loss: 0.6714 - acc: 0.5675 - val_loss: 0.5945 - val_acc: 0.6948\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.5391 - acc: 0.7283 - val_loss: 0.5206 - val_acc: 0.7433\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.4899 - acc: 0.7630 - val_loss: 0.4824 - val_acc: 0.7696\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.4552 - acc: 0.7848 - val_loss: 0.4638 - val_acc: 0.7802\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 11s 302us/step - loss: 0.4340 - acc: 0.7998 - val_loss: 0.5125 - val_acc: 0.7522\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.4192 - acc: 0.8074 - val_loss: 0.4353 - val_acc: 0.7999\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 11s 302us/step - loss: 0.4034 - acc: 0.8169 - val_loss: 0.4259 - val_acc: 0.8020\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.3947 - acc: 0.8210 - val_loss: 0.4431 - val_acc: 0.7929\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 11s 302us/step - loss: 0.3878 - acc: 0.8260 - val_loss: 0.4187 - val_acc: 0.8114\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3821 - acc: 0.8296 - val_loss: 0.4256 - val_acc: 0.8054\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3738 - acc: 0.8343 - val_loss: 0.4072 - val_acc: 0.8155\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3692 - acc: 0.8343 - val_loss: 0.4130 - val_acc: 0.8115\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3664 - acc: 0.8366 - val_loss: 0.4021 - val_acc: 0.8202\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3598 - acc: 0.8410 - val_loss: 0.4106 - val_acc: 0.8179\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3611 - acc: 0.8411 - val_loss: 0.4052 - val_acc: 0.8200\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.3533 - acc: 0.8453 - val_loss: 0.4224 - val_acc: 0.8133\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3516 - acc: 0.8459 - val_loss: 0.3985 - val_acc: 0.8218\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 11s 303us/step - loss: 0.3482 - acc: 0.8468 - val_loss: 0.4030 - val_acc: 0.8228\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 10s 301us/step - loss: 0.3447 - acc: 0.8505 - val_loss: 0.4043 - val_acc: 0.8213\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3457 - acc: 0.8492 - val_loss: 0.4220 - val_acc: 0.8114\n",
      "kla-1h num dense 100 num motifs 50 pool size 20 dropout rate 0.75 param count 13852\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 13s 372us/step - loss: 0.6867 - acc: 0.5347 - val_loss: 0.6454 - val_acc: 0.6345\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.5841 - acc: 0.6899 - val_loss: 0.5239 - val_acc: 0.7384\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.5018 - acc: 0.7587 - val_loss: 0.4828 - val_acc: 0.7649\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.4580 - acc: 0.7867 - val_loss: 0.4562 - val_acc: 0.7828\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.4340 - acc: 0.7987 - val_loss: 0.4453 - val_acc: 0.7898\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.4233 - acc: 0.8052 - val_loss: 0.4429 - val_acc: 0.7895\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 10s 295us/step - loss: 0.4129 - acc: 0.8097 - val_loss: 0.4458 - val_acc: 0.7911\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 10s 296us/step - loss: 0.4046 - acc: 0.8152 - val_loss: 0.4504 - val_acc: 0.7860\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3980 - acc: 0.8194 - val_loss: 0.4315 - val_acc: 0.8009\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 11s 304us/step - loss: 0.3927 - acc: 0.8242 - val_loss: 0.4266 - val_acc: 0.8030\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3860 - acc: 0.8253 - val_loss: 0.4261 - val_acc: 0.8062\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3841 - acc: 0.8274 - val_loss: 0.4262 - val_acc: 0.8071\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3789 - acc: 0.8304 - val_loss: 0.4383 - val_acc: 0.7969\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3754 - acc: 0.8343 - val_loss: 0.4148 - val_acc: 0.8092\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3724 - acc: 0.8348 - val_loss: 0.4428 - val_acc: 0.7975\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 10s 300us/step - loss: 0.3692 - acc: 0.8369 - val_loss: 0.4312 - val_acc: 0.8090\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3665 - acc: 0.8360 - val_loss: 0.4092 - val_acc: 0.8167\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 10s 299us/step - loss: 0.3620 - acc: 0.8401 - val_loss: 0.4366 - val_acc: 0.8019\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 10s 298us/step - loss: 0.3588 - acc: 0.8429 - val_loss: 0.4055 - val_acc: 0.8190\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 10s 297us/step - loss: 0.3584 - acc: 0.8431 - val_loss: 0.4016 - val_acc: 0.8225\n",
      "kla-1h num dense 100 num motifs 100 pool size 5 dropout rate 0.25 param count 30802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 19s 559us/step - loss: 0.6564 - acc: 0.5921 - val_loss: 0.6177 - val_acc: 0.6592\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 17s 493us/step - loss: 0.5645 - acc: 0.7064 - val_loss: 0.5399 - val_acc: 0.7332\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 17s 491us/step - loss: 0.4771 - acc: 0.7712 - val_loss: 0.4634 - val_acc: 0.7827\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 17s 493us/step - loss: 0.4304 - acc: 0.8011 - val_loss: 0.4535 - val_acc: 0.7906\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.4052 - acc: 0.8143 - val_loss: 0.4135 - val_acc: 0.8114\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.3830 - acc: 0.8294 - val_loss: 0.4266 - val_acc: 0.8023\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 17s 491us/step - loss: 0.3682 - acc: 0.8361 - val_loss: 0.4048 - val_acc: 0.8149\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.3600 - acc: 0.8408 - val_loss: 0.3989 - val_acc: 0.8184\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 17s 493us/step - loss: 0.3448 - acc: 0.8493 - val_loss: 0.3914 - val_acc: 0.8233\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.3400 - acc: 0.8513 - val_loss: 0.3938 - val_acc: 0.8208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.3313 - acc: 0.8564 - val_loss: 0.3918 - val_acc: 0.8247\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.3225 - acc: 0.8614 - val_loss: 0.4008 - val_acc: 0.8230\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.3208 - acc: 0.8591 - val_loss: 0.3906 - val_acc: 0.8237\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.3147 - acc: 0.8641 - val_loss: 0.4149 - val_acc: 0.8161\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 17s 487us/step - loss: 0.3074 - acc: 0.8657 - val_loss: 0.4038 - val_acc: 0.8216\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.3082 - acc: 0.8676 - val_loss: 0.3910 - val_acc: 0.8300\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 17s 491us/step - loss: 0.2998 - acc: 0.8716 - val_loss: 0.3960 - val_acc: 0.8246\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.3006 - acc: 0.8706 - val_loss: 0.4231 - val_acc: 0.8117\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.2923 - acc: 0.8757 - val_loss: 0.4223 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 17s 491us/step - loss: 0.2868 - acc: 0.8793 - val_loss: 0.3995 - val_acc: 0.8223\n",
      "kla-1h num dense 100 num motifs 100 pool size 5 dropout rate 0.5 param count 30802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 19s 555us/step - loss: 0.6743 - acc: 0.5635 - val_loss: 0.6493 - val_acc: 0.6212\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.6026 - acc: 0.6719 - val_loss: 0.5760 - val_acc: 0.7012\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 17s 486us/step - loss: 0.5415 - acc: 0.7264 - val_loss: 0.5339 - val_acc: 0.7337\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.4917 - acc: 0.7640 - val_loss: 0.4849 - val_acc: 0.7670\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.4455 - acc: 0.7923 - val_loss: 0.4533 - val_acc: 0.7861\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 17s 488us/step - loss: 0.4178 - acc: 0.8075 - val_loss: 0.4467 - val_acc: 0.7935\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 17s 487us/step - loss: 0.3969 - acc: 0.8218 - val_loss: 0.4310 - val_acc: 0.8038\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.3790 - acc: 0.8306 - val_loss: 0.4115 - val_acc: 0.8112\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.3669 - acc: 0.8355 - val_loss: 0.4186 - val_acc: 0.8104\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 17s 485us/step - loss: 0.3575 - acc: 0.8415 - val_loss: 0.4190 - val_acc: 0.8169\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.3487 - acc: 0.8468 - val_loss: 0.3977 - val_acc: 0.8236\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 17s 487us/step - loss: 0.3405 - acc: 0.8510 - val_loss: 0.4051 - val_acc: 0.8151\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 17s 486us/step - loss: 0.3364 - acc: 0.8534 - val_loss: 0.4016 - val_acc: 0.8151\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 17s 495us/step - loss: 0.3279 - acc: 0.8574 - val_loss: 0.3871 - val_acc: 0.8230\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 17s 496us/step - loss: 0.3268 - acc: 0.8581 - val_loss: 0.3925 - val_acc: 0.8230\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 17s 494us/step - loss: 0.3174 - acc: 0.8625 - val_loss: 0.3933 - val_acc: 0.8214\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 17s 496us/step - loss: 0.3164 - acc: 0.8625 - val_loss: 0.3904 - val_acc: 0.8265\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.3131 - acc: 0.8659 - val_loss: 0.3953 - val_acc: 0.8260\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.3076 - acc: 0.8693 - val_loss: 0.3932 - val_acc: 0.8268\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 17s 483us/step - loss: 0.3063 - acc: 0.8674 - val_loss: 0.4008 - val_acc: 0.8256\n",
      "kla-1h num dense 100 num motifs 100 pool size 5 dropout rate 0.75 param count 30802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 19s 559us/step - loss: 0.6688 - acc: 0.5688 - val_loss: 0.6335 - val_acc: 0.6300\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 17s 487us/step - loss: 0.6140 - acc: 0.6595 - val_loss: 0.5876 - val_acc: 0.6845\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 17s 488us/step - loss: 0.5549 - acc: 0.7155 - val_loss: 0.5184 - val_acc: 0.7440\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 17s 487us/step - loss: 0.4876 - acc: 0.7656 - val_loss: 0.4810 - val_acc: 0.7716\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 17s 485us/step - loss: 0.4407 - acc: 0.7944 - val_loss: 0.4545 - val_acc: 0.7852\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 17s 499us/step - loss: 0.4119 - acc: 0.8144 - val_loss: 0.4230 - val_acc: 0.8020\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 17s 490us/step - loss: 0.3963 - acc: 0.8207 - val_loss: 0.4222 - val_acc: 0.8023\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 17s 489us/step - loss: 0.3802 - acc: 0.8303 - val_loss: 0.4102 - val_acc: 0.8115\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 17s 488us/step - loss: 0.3715 - acc: 0.8341 - val_loss: 0.4015 - val_acc: 0.8190\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 17s 486us/step - loss: 0.3588 - acc: 0.8420 - val_loss: 0.4027 - val_acc: 0.8198\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 17s 487us/step - loss: 0.3503 - acc: 0.8458 - val_loss: 0.4011 - val_acc: 0.8191\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 17s 488us/step - loss: 0.3437 - acc: 0.8496 - val_loss: 0.3912 - val_acc: 0.8290\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 18s 504us/step - loss: 0.3384 - acc: 0.8517 - val_loss: 0.4074 - val_acc: 0.8190\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.3325 - acc: 0.8557 - val_loss: 0.3884 - val_acc: 0.8307\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 17s 492us/step - loss: 0.3267 - acc: 0.8580 - val_loss: 0.3995 - val_acc: 0.8250\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 17s 497us/step - loss: 0.3225 - acc: 0.8602 - val_loss: 0.3962 - val_acc: 0.8296\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 17s 496us/step - loss: 0.3183 - acc: 0.8632 - val_loss: 0.4036 - val_acc: 0.8254\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 17s 496us/step - loss: 0.3146 - acc: 0.8651 - val_loss: 0.4048 - val_acc: 0.8242\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 17s 496us/step - loss: 0.3089 - acc: 0.8660 - val_loss: 0.3937 - val_acc: 0.8315\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 17s 499us/step - loss: 0.3078 - acc: 0.8670 - val_loss: 0.3926 - val_acc: 0.8307\n",
      "kla-1h num dense 100 num motifs 100 pool size 10 dropout rate 0.25 param count 27802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 18s 512us/step - loss: 0.6476 - acc: 0.5977 - val_loss: 0.5851 - val_acc: 0.6894\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 15s 439us/step - loss: 0.5115 - acc: 0.7484 - val_loss: 0.4977 - val_acc: 0.7533\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 15s 438us/step - loss: 0.4438 - acc: 0.7924 - val_loss: 0.4440 - val_acc: 0.7899\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 15s 432us/step - loss: 0.4077 - acc: 0.8139 - val_loss: 0.4196 - val_acc: 0.8020\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 15s 436us/step - loss: 0.3808 - acc: 0.8295 - val_loss: 0.4055 - val_acc: 0.8174\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 15s 436us/step - loss: 0.3627 - acc: 0.8396 - val_loss: 0.4410 - val_acc: 0.7947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 15s 435us/step - loss: 0.3483 - acc: 0.8475 - val_loss: 0.3818 - val_acc: 0.8309\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 15s 434us/step - loss: 0.3357 - acc: 0.8517 - val_loss: 0.3868 - val_acc: 0.8333\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 15s 433us/step - loss: 0.3254 - acc: 0.8589 - val_loss: 0.3729 - val_acc: 0.8350\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 15s 442us/step - loss: 0.3172 - acc: 0.8636 - val_loss: 0.3746 - val_acc: 0.8372\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 15s 440us/step - loss: 0.3121 - acc: 0.8656 - val_loss: 0.3758 - val_acc: 0.8397\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 15s 439us/step - loss: 0.3047 - acc: 0.8701 - val_loss: 0.3786 - val_acc: 0.8391\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 15s 441us/step - loss: 0.3000 - acc: 0.8717 - val_loss: 0.3763 - val_acc: 0.8350\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 15s 438us/step - loss: 0.2949 - acc: 0.8733 - val_loss: 0.3738 - val_acc: 0.8396\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 15s 441us/step - loss: 0.2920 - acc: 0.8761 - val_loss: 0.3739 - val_acc: 0.8401\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 15s 444us/step - loss: 0.2870 - acc: 0.8790 - val_loss: 0.3844 - val_acc: 0.8368\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 15s 435us/step - loss: 0.2820 - acc: 0.8818 - val_loss: 0.3812 - val_acc: 0.8353\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 15s 432us/step - loss: 0.2793 - acc: 0.8832 - val_loss: 0.3836 - val_acc: 0.8389\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 15s 440us/step - loss: 0.2762 - acc: 0.8854 - val_loss: 0.3910 - val_acc: 0.8394\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 15s 439us/step - loss: 0.2747 - acc: 0.8840 - val_loss: 0.3835 - val_acc: 0.8370\n",
      "kla-1h num dense 100 num motifs 100 pool size 10 dropout rate 0.5 param count 27802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 18s 510us/step - loss: 0.6481 - acc: 0.5948 - val_loss: 0.6108 - val_acc: 0.6731\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 15s 434us/step - loss: 0.5217 - acc: 0.7431 - val_loss: 0.4875 - val_acc: 0.7679\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 15s 435us/step - loss: 0.4521 - acc: 0.7906 - val_loss: 0.4407 - val_acc: 0.7950\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 15s 444us/step - loss: 0.4068 - acc: 0.8141 - val_loss: 0.4259 - val_acc: 0.8046\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 15s 436us/step - loss: 0.3793 - acc: 0.8293 - val_loss: 0.3998 - val_acc: 0.8210\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 15s 431us/step - loss: 0.3683 - acc: 0.8361 - val_loss: 0.4463 - val_acc: 0.7941\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 15s 436us/step - loss: 0.3520 - acc: 0.8450 - val_loss: 0.4113 - val_acc: 0.8120\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 15s 442us/step - loss: 0.3424 - acc: 0.8487 - val_loss: 0.3891 - val_acc: 0.8250\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 15s 433us/step - loss: 0.3323 - acc: 0.8549 - val_loss: 0.3925 - val_acc: 0.8268\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 16s 448us/step - loss: 0.3274 - acc: 0.8586 - val_loss: 0.3860 - val_acc: 0.8314\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 15s 439us/step - loss: 0.3197 - acc: 0.8607 - val_loss: 0.3869 - val_acc: 0.8255\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 15s 432us/step - loss: 0.3159 - acc: 0.8634 - val_loss: 0.3815 - val_acc: 0.8323\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 15s 429us/step - loss: 0.3103 - acc: 0.8665 - val_loss: 0.3854 - val_acc: 0.8343\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 15s 428us/step - loss: 0.3052 - acc: 0.8709 - val_loss: 0.3928 - val_acc: 0.8304\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 15s 424us/step - loss: 0.3039 - acc: 0.8709 - val_loss: 0.3903 - val_acc: 0.8355\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 15s 429us/step - loss: 0.2994 - acc: 0.8730 - val_loss: 0.3956 - val_acc: 0.8280\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 15s 434us/step - loss: 0.2957 - acc: 0.8737 - val_loss: 0.4107 - val_acc: 0.8186\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 15s 434us/step - loss: 0.2938 - acc: 0.8750 - val_loss: 0.3882 - val_acc: 0.8339\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 15s 435us/step - loss: 0.2890 - acc: 0.8771 - val_loss: 0.4092 - val_acc: 0.8225\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 15s 436us/step - loss: 0.2865 - acc: 0.8782 - val_loss: 0.4019 - val_acc: 0.8325\n",
      "kla-1h num dense 100 num motifs 100 pool size 10 dropout rate 0.75 param count 27802\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 18s 517us/step - loss: 0.6887 - acc: 0.5226 - val_loss: 0.6659 - val_acc: 0.5967\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 15s 434us/step - loss: 0.6000 - acc: 0.6735 - val_loss: 0.5358 - val_acc: 0.7348\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 15s 429us/step - loss: 0.4936 - acc: 0.7619 - val_loss: 0.4706 - val_acc: 0.7775\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 15s 433us/step - loss: 0.4364 - acc: 0.7966 - val_loss: 0.4255 - val_acc: 0.8042\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 15s 433us/step - loss: 0.3972 - acc: 0.8193 - val_loss: 0.4168 - val_acc: 0.8097\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 15s 431us/step - loss: 0.3784 - acc: 0.8319 - val_loss: 0.4106 - val_acc: 0.8120\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 15s 431us/step - loss: 0.3635 - acc: 0.8398 - val_loss: 0.4043 - val_acc: 0.8160\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 15s 429us/step - loss: 0.3497 - acc: 0.8463 - val_loss: 0.3990 - val_acc: 0.8186\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 15s 428us/step - loss: 0.3461 - acc: 0.8514 - val_loss: 0.3824 - val_acc: 0.8295\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 15s 430us/step - loss: 0.3349 - acc: 0.8550 - val_loss: 0.3794 - val_acc: 0.8343\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 15s 434us/step - loss: 0.3308 - acc: 0.8568 - val_loss: 0.3763 - val_acc: 0.8330\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 15s 431us/step - loss: 0.3240 - acc: 0.8599 - val_loss: 0.3917 - val_acc: 0.8278\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 15s 431us/step - loss: 0.3171 - acc: 0.8643 - val_loss: 0.4094 - val_acc: 0.8187\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 15s 433us/step - loss: 0.3148 - acc: 0.8638 - val_loss: 0.3901 - val_acc: 0.8306\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 15s 430us/step - loss: 0.3126 - acc: 0.8668 - val_loss: 0.3836 - val_acc: 0.8339\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 15s 430us/step - loss: 0.3045 - acc: 0.8704 - val_loss: 0.3821 - val_acc: 0.8353\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 15s 432us/step - loss: 0.3040 - acc: 0.8708 - val_loss: 0.3847 - val_acc: 0.8329\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 15s 432us/step - loss: 0.3003 - acc: 0.8718 - val_loss: 0.3789 - val_acc: 0.8358\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 15s 433us/step - loss: 0.2982 - acc: 0.8731 - val_loss: 0.4048 - val_acc: 0.8230\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 15s 431us/step - loss: 0.2966 - acc: 0.8732 - val_loss: 0.4163 - val_acc: 0.8174\n",
      "kla-1h num dense 100 num motifs 100 pool size 20 dropout rate 0.25 param count 26202\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 478us/step - loss: 0.6409 - acc: 0.6047 - val_loss: 0.5306 - val_acc: 0.7353\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 14s 399us/step - loss: 0.4977 - acc: 0.7586 - val_loss: 0.4841 - val_acc: 0.7629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.4416 - acc: 0.7942 - val_loss: 0.4449 - val_acc: 0.7898\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.4080 - acc: 0.8130 - val_loss: 0.4255 - val_acc: 0.8007\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3838 - acc: 0.8249 - val_loss: 0.4168 - val_acc: 0.8100\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3693 - acc: 0.8347 - val_loss: 0.4233 - val_acc: 0.8059\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3547 - acc: 0.8421 - val_loss: 0.4182 - val_acc: 0.8097\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3482 - acc: 0.8453 - val_loss: 0.4066 - val_acc: 0.8174\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3385 - acc: 0.8514 - val_loss: 0.4064 - val_acc: 0.8162\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3320 - acc: 0.8546 - val_loss: 0.4005 - val_acc: 0.8232\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 14s 397us/step - loss: 0.3237 - acc: 0.8583 - val_loss: 0.4230 - val_acc: 0.8090\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 14s 398us/step - loss: 0.3200 - acc: 0.8613 - val_loss: 0.3957 - val_acc: 0.8283\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3126 - acc: 0.8642 - val_loss: 0.4032 - val_acc: 0.8254\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3113 - acc: 0.8658 - val_loss: 0.4061 - val_acc: 0.8224\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3078 - acc: 0.8678 - val_loss: 0.4064 - val_acc: 0.8259\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3010 - acc: 0.8712 - val_loss: 0.4107 - val_acc: 0.8250\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3010 - acc: 0.8711 - val_loss: 0.4392 - val_acc: 0.8101\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.2995 - acc: 0.8714 - val_loss: 0.4062 - val_acc: 0.8273\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.2940 - acc: 0.8757 - val_loss: 0.4187 - val_acc: 0.8226\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.2913 - acc: 0.8757 - val_loss: 0.4045 - val_acc: 0.8307\n",
      "kla-1h num dense 100 num motifs 100 pool size 20 dropout rate 0.5 param count 26202\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 481us/step - loss: 0.6785 - acc: 0.5480 - val_loss: 0.6160 - val_acc: 0.6622\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 14s 408us/step - loss: 0.5439 - acc: 0.7233 - val_loss: 0.5038 - val_acc: 0.7542\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.4752 - acc: 0.7745 - val_loss: 0.4706 - val_acc: 0.7749\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 14s 406us/step - loss: 0.4339 - acc: 0.7988 - val_loss: 0.4425 - val_acc: 0.7911\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.4104 - acc: 0.8141 - val_loss: 0.4443 - val_acc: 0.7915\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3944 - acc: 0.8218 - val_loss: 0.4278 - val_acc: 0.8022\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3786 - acc: 0.8314 - val_loss: 0.4194 - val_acc: 0.8051\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3685 - acc: 0.8360 - val_loss: 0.4168 - val_acc: 0.8105\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3598 - acc: 0.8421 - val_loss: 0.4135 - val_acc: 0.8114\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3509 - acc: 0.8450 - val_loss: 0.4096 - val_acc: 0.8109\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 14s 398us/step - loss: 0.3448 - acc: 0.8503 - val_loss: 0.4292 - val_acc: 0.8073\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3400 - acc: 0.8499 - val_loss: 0.4157 - val_acc: 0.8127\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3339 - acc: 0.8547 - val_loss: 0.4113 - val_acc: 0.8186\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3287 - acc: 0.8580 - val_loss: 0.4335 - val_acc: 0.8048\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.3263 - acc: 0.8616 - val_loss: 0.4259 - val_acc: 0.8101\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3240 - acc: 0.8596 - val_loss: 0.4159 - val_acc: 0.8190\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3186 - acc: 0.8631 - val_loss: 0.4263 - val_acc: 0.8166\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3134 - acc: 0.8679 - val_loss: 0.4306 - val_acc: 0.8030\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3149 - acc: 0.8669 - val_loss: 0.4649 - val_acc: 0.7891\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3140 - acc: 0.8659 - val_loss: 0.4055 - val_acc: 0.8155\n",
      "kla-1h num dense 100 num motifs 100 pool size 20 dropout rate 0.75 param count 26202\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 17s 486us/step - loss: 0.6788 - acc: 0.5487 - val_loss: 0.5949 - val_acc: 0.6925\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 14s 404us/step - loss: 0.5439 - acc: 0.7277 - val_loss: 0.5012 - val_acc: 0.7554\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.4757 - acc: 0.7757 - val_loss: 0.4584 - val_acc: 0.7843\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.4311 - acc: 0.8032 - val_loss: 0.4339 - val_acc: 0.7991\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 14s 409us/step - loss: 0.4068 - acc: 0.8164 - val_loss: 0.4206 - val_acc: 0.8096\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 14s 407us/step - loss: 0.3875 - acc: 0.8284 - val_loss: 0.4096 - val_acc: 0.8182\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3769 - acc: 0.8351 - val_loss: 0.4233 - val_acc: 0.8073\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3652 - acc: 0.8404 - val_loss: 0.4016 - val_acc: 0.8210\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3557 - acc: 0.8452 - val_loss: 0.4063 - val_acc: 0.8131\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3490 - acc: 0.8495 - val_loss: 0.4015 - val_acc: 0.8207\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3435 - acc: 0.8534 - val_loss: 0.4020 - val_acc: 0.8178\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 14s 401us/step - loss: 0.3401 - acc: 0.8543 - val_loss: 0.3950 - val_acc: 0.8241\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 14s 400us/step - loss: 0.3332 - acc: 0.8580 - val_loss: 0.4183 - val_acc: 0.8168\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3288 - acc: 0.8606 - val_loss: 0.3984 - val_acc: 0.8262\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3282 - acc: 0.8583 - val_loss: 0.3957 - val_acc: 0.8240\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 14s 399us/step - loss: 0.3258 - acc: 0.8635 - val_loss: 0.4339 - val_acc: 0.8091\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3227 - acc: 0.8626 - val_loss: 0.4001 - val_acc: 0.8272\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 14s 402us/step - loss: 0.3179 - acc: 0.8638 - val_loss: 0.3928 - val_acc: 0.8291\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 14s 403us/step - loss: 0.3132 - acc: 0.8666 - val_loss: 0.3949 - val_acc: 0.8275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 14s 405us/step - loss: 0.3123 - acc: 0.8686 - val_loss: 0.4020 - val_acc: 0.8247\n",
      "kla-1h num dense 100 num motifs 150 pool size 5 dropout rate 0.25 param count 43152\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 27s 770us/step - loss: 0.6682 - acc: 0.5635 - val_loss: 0.6400 - val_acc: 0.6339\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 24s 684us/step - loss: 0.5921 - acc: 0.6828 - val_loss: 0.5907 - val_acc: 0.6859\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 24s 688us/step - loss: 0.5198 - acc: 0.7421 - val_loss: 0.5019 - val_acc: 0.7600\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 24s 687us/step - loss: 0.4646 - acc: 0.7794 - val_loss: 0.4487 - val_acc: 0.7918\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 24s 685us/step - loss: 0.4133 - acc: 0.8129 - val_loss: 0.4353 - val_acc: 0.7936\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 24s 686us/step - loss: 0.3861 - acc: 0.8265 - val_loss: 0.4036 - val_acc: 0.8194\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 24s 687us/step - loss: 0.3568 - acc: 0.8435 - val_loss: 0.4206 - val_acc: 0.8096\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 24s 687us/step - loss: 0.3440 - acc: 0.8502 - val_loss: 0.3922 - val_acc: 0.8261\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 24s 685us/step - loss: 0.3357 - acc: 0.8558 - val_loss: 0.3979 - val_acc: 0.8271\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 24s 694us/step - loss: 0.3219 - acc: 0.8617 - val_loss: 0.3919 - val_acc: 0.8290\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 24s 692us/step - loss: 0.3140 - acc: 0.8668 - val_loss: 0.3920 - val_acc: 0.8298\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 24s 697us/step - loss: 0.3030 - acc: 0.8703 - val_loss: 0.4121 - val_acc: 0.8210\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 24s 693us/step - loss: 0.2971 - acc: 0.8729 - val_loss: 0.4111 - val_acc: 0.8216\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 24s 687us/step - loss: 0.2915 - acc: 0.8759 - val_loss: 0.4010 - val_acc: 0.8307\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 24s 692us/step - loss: 0.2850 - acc: 0.8815 - val_loss: 0.4065 - val_acc: 0.8312\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 24s 688us/step - loss: 0.2772 - acc: 0.8834 - val_loss: 0.4375 - val_acc: 0.8213\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 24s 701us/step - loss: 0.2715 - acc: 0.8865 - val_loss: 0.4261 - val_acc: 0.8242\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 24s 695us/step - loss: 0.2655 - acc: 0.8892 - val_loss: 0.4234 - val_acc: 0.8171\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 24s 694us/step - loss: 0.2610 - acc: 0.8905 - val_loss: 0.4486 - val_acc: 0.8108\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 24s 690us/step - loss: 0.2538 - acc: 0.8947 - val_loss: 0.4235 - val_acc: 0.8259\n",
      "kla-1h num dense 100 num motifs 150 pool size 5 dropout rate 0.5 param count 43152\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 27s 776us/step - loss: 0.6626 - acc: 0.5779 - val_loss: 0.6536 - val_acc: 0.6248\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 24s 694us/step - loss: 0.5858 - acc: 0.6871 - val_loss: 0.5448 - val_acc: 0.7253\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 24s 694us/step - loss: 0.5000 - acc: 0.7570 - val_loss: 0.4792 - val_acc: 0.7727\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 24s 693us/step - loss: 0.4367 - acc: 0.7969 - val_loss: 0.4764 - val_acc: 0.7768\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 24s 695us/step - loss: 0.4024 - acc: 0.8181 - val_loss: 0.4175 - val_acc: 0.8094\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 24s 691us/step - loss: 0.3719 - acc: 0.8359 - val_loss: 0.4310 - val_acc: 0.8006\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 24s 693us/step - loss: 0.3559 - acc: 0.8427 - val_loss: 0.4056 - val_acc: 0.8193\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 24s 698us/step - loss: 0.3413 - acc: 0.8522 - val_loss: 0.4103 - val_acc: 0.8185\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 24s 696us/step - loss: 0.3301 - acc: 0.8576 - val_loss: 0.4357 - val_acc: 0.8052\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 24s 701us/step - loss: 0.3274 - acc: 0.8588 - val_loss: 0.4014 - val_acc: 0.8208\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 25s 708us/step - loss: 0.3140 - acc: 0.8641 - val_loss: 0.3879 - val_acc: 0.8296\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 24s 702us/step - loss: 0.3084 - acc: 0.8696 - val_loss: 0.3901 - val_acc: 0.8341\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 24s 701us/step - loss: 0.3010 - acc: 0.8721 - val_loss: 0.3953 - val_acc: 0.8311\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 24s 692us/step - loss: 0.2937 - acc: 0.8757 - val_loss: 0.4369 - val_acc: 0.8190\n",
      "Epoch 15/20\n",
      "34841/34841 [==============================] - 24s 694us/step - loss: 0.2888 - acc: 0.8767 - val_loss: 0.3922 - val_acc: 0.8323\n",
      "Epoch 16/20\n",
      "34841/34841 [==============================] - 24s 703us/step - loss: 0.2842 - acc: 0.8786 - val_loss: 0.4281 - val_acc: 0.8164\n",
      "Epoch 17/20\n",
      "34841/34841 [==============================] - 25s 716us/step - loss: 0.2780 - acc: 0.8824 - val_loss: 0.3954 - val_acc: 0.8296\n",
      "Epoch 18/20\n",
      "34841/34841 [==============================] - 25s 719us/step - loss: 0.2724 - acc: 0.8875 - val_loss: 0.4270 - val_acc: 0.8105\n",
      "Epoch 19/20\n",
      "34841/34841 [==============================] - 26s 741us/step - loss: 0.2702 - acc: 0.8871 - val_loss: 0.4240 - val_acc: 0.8237\n",
      "Epoch 20/20\n",
      "34841/34841 [==============================] - 26s 733us/step - loss: 0.2663 - acc: 0.8886 - val_loss: 0.4078 - val_acc: 0.8265\n",
      "kla-1h num dense 100 num motifs 150 pool size 5 dropout rate 0.75 param count 43152\n",
      "Train on 34841 samples, validate on 8711 samples\n",
      "Epoch 1/20\n",
      "34841/34841 [==============================] - 28s 802us/step - loss: 0.6615 - acc: 0.5837 - val_loss: 0.5950 - val_acc: 0.6799\n",
      "Epoch 2/20\n",
      "34841/34841 [==============================] - 24s 692us/step - loss: 0.5645 - acc: 0.7081 - val_loss: 0.5194 - val_acc: 0.7462\n",
      "Epoch 3/20\n",
      "34841/34841 [==============================] - 24s 697us/step - loss: 0.4986 - acc: 0.7604 - val_loss: 0.4868 - val_acc: 0.7644\n",
      "Epoch 4/20\n",
      "34841/34841 [==============================] - 24s 693us/step - loss: 0.4568 - acc: 0.7875 - val_loss: 0.4694 - val_acc: 0.7749\n",
      "Epoch 5/20\n",
      "34841/34841 [==============================] - 24s 693us/step - loss: 0.4353 - acc: 0.7994 - val_loss: 0.4397 - val_acc: 0.7952\n",
      "Epoch 6/20\n",
      "34841/34841 [==============================] - 24s 697us/step - loss: 0.4094 - acc: 0.8144 - val_loss: 0.4336 - val_acc: 0.7990\n",
      "Epoch 7/20\n",
      "34841/34841 [==============================] - 24s 697us/step - loss: 0.3899 - acc: 0.8246 - val_loss: 0.4159 - val_acc: 0.8061\n",
      "Epoch 8/20\n",
      "34841/34841 [==============================] - 24s 692us/step - loss: 0.3738 - acc: 0.8326 - val_loss: 0.4022 - val_acc: 0.8152\n",
      "Epoch 9/20\n",
      "34841/34841 [==============================] - 24s 690us/step - loss: 0.3594 - acc: 0.8413 - val_loss: 0.4034 - val_acc: 0.8180\n",
      "Epoch 10/20\n",
      "34841/34841 [==============================] - 24s 698us/step - loss: 0.3419 - acc: 0.8503 - val_loss: 0.4098 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "34841/34841 [==============================] - 24s 697us/step - loss: 0.3326 - acc: 0.8553 - val_loss: 0.3913 - val_acc: 0.8238\n",
      "Epoch 12/20\n",
      "34841/34841 [==============================] - 24s 695us/step - loss: 0.3258 - acc: 0.8572 - val_loss: 0.4158 - val_acc: 0.8169\n",
      "Epoch 13/20\n",
      "34841/34841 [==============================] - 24s 702us/step - loss: 0.3167 - acc: 0.8632 - val_loss: 0.3940 - val_acc: 0.8263\n",
      "Epoch 14/20\n",
      "34841/34841 [==============================] - 25s 711us/step - loss: 0.3110 - acc: 0.8679 - val_loss: 0.3820 - val_acc: 0.8343\n",
      "Epoch 15/20\n",
      "25088/34841 [====================>.........] - ETA: 6s - loss: 0.3067 - acc: 0.8686"
     ]
    }
   ],
   "source": [
    "all_rocs = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "poolSize_list = []\n",
    "all_treatments = []\n",
    "motifCount_list = []\n",
    "numDense_list = []\n",
    "paramCount_list = []\n",
    "dropoutRate_list = []\n",
    "for ps in ['c57bl6_kla-1h_peaks.fasta', 'c57bl6_veh_peaks.fasta', 'c57bl6_il4-24h_peaks.fasta']:\n",
    "    print(ps)\n",
    "    positive_seqRecords = list(SeqIO.parse('./peak_sequences/' + ps, 'fasta'))\n",
    "    negative_seqRecords = list(SeqIO.parse('./background_files/' + ps.replace('_peaks', '_background'), 'fasta'))[:len(positive_seqRecords)]\n",
    "\n",
    "    fasta_seq = [str(x.seq[:200]) for x in positive_seqRecords] + [str(x[:200].seq) for x in negative_seqRecords]\n",
    "\n",
    "    fasta_rc_seq = [str(x[:200].reverse_complement().seq) for x in positive_seqRecords] + \\\n",
    "        [str(x[:200].reverse_complement().seq) for x in negative_seqRecords]\n",
    "\n",
    "    sequence_arrays = convert_sequences_to_array(fasta_seq)\n",
    "\n",
    "    sequence_rc_arrays = convert_sequences_to_array(fasta_rc_seq)\n",
    "\n",
    "\n",
    "    labels = [1 for x in positive_seqRecords] + [0 for x in negative_seqRecords]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    x_train, x_test, x_rc_train, x_rc_test, y_train, y_test = model_selection.train_test_split(sequence_arrays, sequence_rc_arrays, labels, test_size=0.2)\n",
    "\n",
    "    num_classes = 2\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    treatment = ps.split('_')[1]\n",
    "    \n",
    "    for d in range(50,200,50):\n",
    "        for m in range(50,200,50):\n",
    "            for p in [5,10,20]:\n",
    "                for do in [0.25,0.5,0.75]:\n",
    "                    \n",
    "                    current_model = get_dotProductAttention_model(200,\n",
    "                        seq_size=150,\n",
    "                        num_motifs=m, \n",
    "                        motif_size=10,\n",
    "                        adjacent_bp_pool_size=p,\n",
    "                        num_dense_neurons=d,\n",
    "                        dropout_rate=do)\n",
    "                    num_params = current_model.count_params()\n",
    "                    print(treatment, \n",
    "                         'num dense', d,\n",
    "                         'num motifs', m,\n",
    "                         'pool size', p,\n",
    "                         'dropout rate', do,\n",
    "                         'param count', num_params)\n",
    "                    current_model.fit([x_train, x_rc_train], y_train,\n",
    "                          batch_size=64,\n",
    "                          epochs=20,\n",
    "                          verbose=1,\n",
    "                          validation_data=([x_test, x_rc_test], y_test))\n",
    "\n",
    "                    probs = current_model.predict([x_test, x_rc_test])\n",
    "\n",
    "                    roc = sklearn.metrics.roc_auc_score([y[1] for y in y_test], probs[:,1], )\n",
    "                    precision = sklearn.metrics.precision_score([y[1] for y in y_test], [1 if x > 0.5 else 0 for x in probs[:,1]])\n",
    "                    acc = current_model.evaluate([x_test, x_rc_test], y_test, verbose=0)[1]\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    all_rocs.append(roc)\n",
    "                    all_accuracies.append(acc)\n",
    "                    all_precisions.append(precision)\n",
    "                    poolSize_list.append(p)\n",
    "                    all_treatments.append(treatment)\n",
    "                    motifCount_list.append(m)\n",
    "                    numDense_list.append(d)\n",
    "                    paramCount_list.append(num_params)\n",
    "                    dropoutRate_list.append(do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "performance_frame = pd.DataFrame({'aucROC':all_rocs, \n",
    "                      'Accuracy':all_accuracies, \n",
    "                      'Pool Size':poolSize_list, \n",
    "                      'Precision':all_precisions,\n",
    "                      'Treatment':all_treatments,\n",
    "                      'Num Motifs':motifCount_list,\n",
    "                      'Num Dense':numDense_list,\n",
    "                      'Num Params':paramCount_list,\n",
    "                      'Dropout Rate':dropoutRate_list\n",
    "                      })\n",
    "\n",
    "# sns.factorplot(data = frame, x='p', y='aucROC', hue = 'Treatment', size=10)\n",
    "# plt.ylim(0.7,1)\n",
    "# plt.show()\n",
    "# sns.factorplot(data = frame, x='p', y='Precision', hue = 'Treatment', size=10)\n",
    "# plt.ylim(0.7,1)\n",
    "# plt.show()\n",
    "\n",
    "# sns.factorplot(data = frame, x='p', y='Accuracy', hue = 'Treatment', size=10)\n",
    "# plt.ylim(0.7,1)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_frame.to_csv('./grid_search_results.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Dropout Rate</th>\n",
       "      <th>Num Dense</th>\n",
       "      <th>Num Motifs</th>\n",
       "      <th>Num Params</th>\n",
       "      <th>Pool Size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>aucROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.835725</td>\n",
       "      <td>0.75</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>40152</td>\n",
       "      <td>10</td>\n",
       "      <td>0.870618</td>\n",
       "      <td>kla-1h</td>\n",
       "      <td>0.920197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.837447</td>\n",
       "      <td>0.75</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>56702</td>\n",
       "      <td>10</td>\n",
       "      <td>0.873728</td>\n",
       "      <td>kla-1h</td>\n",
       "      <td>0.916011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.837791</td>\n",
       "      <td>0.75</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>23602</td>\n",
       "      <td>10</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>kla-1h</td>\n",
       "      <td>0.915555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.75</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>39352</td>\n",
       "      <td>10</td>\n",
       "      <td>0.896112</td>\n",
       "      <td>kla-1h</td>\n",
       "      <td>0.915317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.831133</td>\n",
       "      <td>0.75</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>17752</td>\n",
       "      <td>5</td>\n",
       "      <td>0.866940</td>\n",
       "      <td>kla-1h</td>\n",
       "      <td>0.914013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Dropout Rate  Num Dense  Num Motifs  Num Params  Pool Size  \\\n",
       "50  0.835725          0.75        100         150       40152         10   \n",
       "77  0.837447          0.75        150         150       56702         10   \n",
       "23  0.837791          0.75         50         150       23602         10   \n",
       "68  0.839972          0.75        150         100       39352         10   \n",
       "11  0.831133          0.75         50         100       17752          5   \n",
       "\n",
       "    Precision Treatment    aucROC  \n",
       "50   0.870618    kla-1h  0.920197  \n",
       "77   0.873728    kla-1h  0.916011  \n",
       "23   0.879173    kla-1h  0.915555  \n",
       "68   0.896112    kla-1h  0.915317  \n",
       "11   0.866940    kla-1h  0.914013  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_frame[performance_frame['Treatment'] == 'kla-1h'].sort_values('aucROC',ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Dropout Rate</th>\n",
       "      <th>Num Dense</th>\n",
       "      <th>Num Motifs</th>\n",
       "      <th>Num Params</th>\n",
       "      <th>Pool Size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>aucROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.853222</td>\n",
       "      <td>0.75</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>23602</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885384</td>\n",
       "      <td>il4-24h</td>\n",
       "      <td>0.930444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.848150</td>\n",
       "      <td>0.75</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>43152</td>\n",
       "      <td>5</td>\n",
       "      <td>0.851699</td>\n",
       "      <td>il4-24h</td>\n",
       "      <td>0.927972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.842035</td>\n",
       "      <td>0.75</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30802</td>\n",
       "      <td>5</td>\n",
       "      <td>0.912084</td>\n",
       "      <td>il4-24h</td>\n",
       "      <td>0.927763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.829430</td>\n",
       "      <td>0.75</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>40152</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818121</td>\n",
       "      <td>il4-24h</td>\n",
       "      <td>0.927611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.847554</td>\n",
       "      <td>0.75</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>56702</td>\n",
       "      <td>10</td>\n",
       "      <td>0.849713</td>\n",
       "      <td>il4-24h</td>\n",
       "      <td>0.927164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Dropout Rate  Num Dense  Num Motifs  Num Params  Pool Size  \\\n",
       "185  0.853222          0.75         50         150       23602         10   \n",
       "209  0.848150          0.75        100         150       43152          5   \n",
       "200  0.842035          0.75        100         100       30802          5   \n",
       "212  0.829430          0.75        100         150       40152         10   \n",
       "239  0.847554          0.75        150         150       56702         10   \n",
       "\n",
       "     Precision Treatment    aucROC  \n",
       "185   0.885384   il4-24h  0.930444  \n",
       "209   0.851699   il4-24h  0.927972  \n",
       "200   0.912084   il4-24h  0.927763  \n",
       "212   0.818121   il4-24h  0.927611  \n",
       "239   0.849713   il4-24h  0.927164  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_frame[performance_frame['Treatment'] == 'il4-24h'].sort_values('aucROC',ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Dropout Rate</th>\n",
       "      <th>Num Dense</th>\n",
       "      <th>Num Motifs</th>\n",
       "      <th>Num Params</th>\n",
       "      <th>Pool Size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>aucROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.854675</td>\n",
       "      <td>0.75</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>23602</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885764</td>\n",
       "      <td>veh</td>\n",
       "      <td>0.928435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.853645</td>\n",
       "      <td>0.75</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>56702</td>\n",
       "      <td>10</td>\n",
       "      <td>0.880882</td>\n",
       "      <td>veh</td>\n",
       "      <td>0.926461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.843978</td>\n",
       "      <td>0.50</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>56702</td>\n",
       "      <td>10</td>\n",
       "      <td>0.887498</td>\n",
       "      <td>veh</td>\n",
       "      <td>0.924575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.848653</td>\n",
       "      <td>0.75</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>61202</td>\n",
       "      <td>5</td>\n",
       "      <td>0.884820</td>\n",
       "      <td>veh</td>\n",
       "      <td>0.923599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.850634</td>\n",
       "      <td>0.75</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>39352</td>\n",
       "      <td>10</td>\n",
       "      <td>0.846551</td>\n",
       "      <td>veh</td>\n",
       "      <td>0.923239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Dropout Rate  Num Dense  Num Motifs  Num Params  Pool Size  \\\n",
       "104  0.854675          0.75         50         150       23602         10   \n",
       "158  0.853645          0.75        150         150       56702         10   \n",
       "157  0.843978          0.50        150         150       56702         10   \n",
       "155  0.848653          0.75        150         150       61202          5   \n",
       "149  0.850634          0.75        150         100       39352         10   \n",
       "\n",
       "     Precision Treatment    aucROC  \n",
       "104   0.885764       veh  0.928435  \n",
       "158   0.880882       veh  0.926461  \n",
       "157   0.887498       veh  0.924575  \n",
       "155   0.884820       veh  0.923599  \n",
       "149   0.846551       veh  0.923239  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_frame[performance_frame['Treatment'] == 'veh'].sort_values('aucROC',ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efae8816198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.factorplot(data = performance_frame, x = 'Num Motifs', y='Accuracy', hue = 'Treatment')\n",
    "plt.ylim(0.8,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efae8883be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.factorplot(data = performance_frame, x = 'Pool Size', y='Accuracy', hue = 'Treatment')\n",
    "plt.ylim(0.8,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.9)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efae8a39f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.factorplot(data = performance_frame, x = 'Num Dense', y='Accuracy', hue = 'Treatment')\n",
    "plt.ylim(0.8,0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_attention(model, sequence, adjacent_bp_pool_size):\n",
    "    get_attention = K.function([model.get_layer('input_fwd').input, \n",
    "                                model.get_layer('input_rev').input,\n",
    "                                K.learning_phase()\n",
    "                               ], \n",
    "                               [model.get_layer('attention_softmax_layer').output])\n",
    "    fwd_seq = sequence[:200]\n",
    "    rev_seq = str(Bio.Seq.Seq(fwd_seq).reverse_complement())\n",
    "    \n",
    "    fwd_seq_array = convert_sequences_to_array([fwd_seq])[0]\n",
    "    rev_seq_array = convert_sequences_to_array([rev_seq])[0]\n",
    "\n",
    "    layer_output = get_attention(([fwd_seq_array], [rev_seq_array], 0))[0]\n",
    "    reshaped_output = layer_output.reshape((layer_output.shape[1], layer_output.shape[2]))\n",
    "\n",
    "\n",
    "    full_attention = []\n",
    "    for x in reshaped_output:\n",
    "        for i in range(adjacent_bp_pool_size):\n",
    "            full_attention.append(x)\n",
    "    full_attention = np.array(full_attention)\n",
    "\n",
    "    crop_distance = int((len(fwd_seq) - full_attention.shape[0])/2)\n",
    "\n",
    "    attended_sequence = fwd_seq[crop_distance:-crop_distance]\n",
    "    return layer_output, full_attention, attended_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output, full_attention, attended_sequence = get_sequence_attention(dotProductAttention_model,\n",
    "                                                                         str(positive_seqRecords[100].seq),\n",
    "                                                                         10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 15)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGACGCCTCCTAGGGCCGAAACCTCACCTCCCTTTGCCCGCCTGTTCCCTATGCATCTTGGAAATCGTAGTCCTCTGTAAACCAGCTGCTGAGGCGAGCGCCTCTAGTGTACTACAAGTCCCAGGATTCCATGCATCCGCAGGGCCTTAG'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attended_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for i in range(0,len(attended_sequence),10):\n",
    "#     print(i, i+5, attended_sequence[i:i+5])\n",
    "    chunks.append(attended_sequence[i:i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5,\n",
       "        11.5, 12.5, 13.5, 14.5]), <a list of 15 Text yticklabel objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efae8c3e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(layer_output.reshape(layer_output.shape[1], \n",
    "                                 layer_output.shape[2]), \n",
    "    square = True,\n",
    "    yticklabels = chunks,\n",
    "    xticklabels=chunks)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.yticks(rotation = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_attention = layer_output.reshape(layer_output.shape[1], \n",
    "                                 layer_output.shape[2]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_attention = summed_attention.reshape((len(summed_attention),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efae8e5f550>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAI8CAYAAADSofByAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYbVV1qP23DtIoInbIVQmKIoOAEsWABr2folexIWKIiuDVGMVgIiZgoqifQvQiUbFBBY1iF7nBJirYQrgm2BATsI2IOgJCsBe7KHaRC3X/WKvO2bXPripO2HPNuaz3x1PPw167as1dp3Yz1phjzLmwuLiIJElSyzbUfgCSJElrMWCRJEnNM2CRJEnNM2CRJEnNM2CRJEnNM2CRJEnNu1HtByBJkv7r9rnD/QZdn+QLV35sYcjxlphhkSRJzTPDIknSiC0sVEl4DM4MiyRJap4BiyRJap5TQpIkjdjCwvrIPayP31KSJI2aAYskSWqeAYskSWqeNSySJI3YBmxrliRJaoIZFkmSRsyF4yRJkhphhkWSpBHb4DoskiRJbTBgkSRJzXNKSJKkEbPoVpIkqREGLJIkqXkGLJIkqXnWsEiSNGILLs0vSZLUBjMskiSNmAvHSZIkNcIMiyRJI+Y6LJIkSY0wwyJJ0ohtMMMiSZLUBgMWSZLUPAMWSZLUPAMWSZLUPItuJUkasYV1kntYH7+lJEkaNTMskiSNmAvHSZIkNcIMiyRJI+bCcZIkSY0wwyJJ0ogtYIZFkiSpCQYskiSpeQYskiSpeQYskiSpeRbdSpI0YhsW1kfuYX38lpIkadTMsEiSNGIuzS9JktQIMyySJI2YS/NLkiQ1wgyLJEkj5tL8kiRJjTBgkSRJzTNgkSRJzTNgkSRJzbPoVpKkEXNpfkmSpEaYYZEkacRcml+SJKkRZlgkSRoxl+aXJElqhBkWSZJGzKX5JUmSGmHAIkmSmmfAIkmSmmfAIkmSmmfRrSRJI+bCcZIkSY0wwyJJ0oi5cJwkSVIjzLBIkjRiLhwnSZLUCDMskiSN2IaF9ZF7WB+/pSRJGjUDFkmS1DynhCRJ0lxFxJuAg4HvZuY+M+6/GfC/gV2BrYCXZ+ZbVzunGRZJkkZsYWFh0K/r6S3AQavc/zTgksy8O3Ag8PKIWDWJYsAiSZLmKjMvAH60yrcsAjv0/78D8IPM/L+rndMpIUmSNLRTgfdHxLeAmwKHrfUDZlgkSRqxDQsLg37NyUHA5zLzdsA9gNMi4qar/p7zGlmSJOl6+kPgvQCZ+VXgCmDP1X7AgEWSpBFbGPi/LXporPgDVwL/AyAidgb2AC5f7WTWsEiSpLmKiDOB+wO3ioivAScA2wCLmfkG4ETgrRHxhf5HnpWZP1ztnAYskiSN2BzrSuYmM49Y4/5vs3rb82acEpIkSc0zYJEkSc0zYJEkSc2zhkWSpBHbguXyR80MiyRJap4ZFkmSRqzFLqESzLBIkqTmGbBIkqTmOSUkSdKIbeFy+aNlhkWSJDXPDIskSSNm0a0kSVIjDFgkSVLzDFgkSVLzrGGRJGnEXJpfkiSpEWZYJEkaMbuEJEmSGmHAIkmSmueUkCRJI+bS/JIkSY0wwyJJ0ohZdCtJktQIAxZJktQ8AxZJktQ8a1gkSRoxl+aXJElqhBkWSZJGzC4hSZKkRphhkSRpxKxhkSRJaoQBiyRJap5TQpIkjZibH0qSJDXCgEWSJDXPgEWSJDXPGhZJkkZsw/ooYTHDIkmS2meGRZKkEXPhOEmSpEaYYZEkacTc/FCSJKkRBiySJKl5TglJkjRiFt1KkiQ1woBFkiQ1z4BFkiQ1zxoWSZJGbAPWsEiSJDXBDIskSSNml5AkSVIjzLBIkjRiLs0vSZLUCDMskiSN2DpJsJhhkSRJ7TNgkSRJzTNgkSRJzTNgkSRJzbPoVpKkEbOtWZIkqRFmWCRJGrEFNz+UJElqgxkWSZJGzM0PJUmSGmGGRZKkEbNLSJIkqREGLJIkqXlOCUmSNGLrZEbIDIskSWqfAYskSWqeAYskSWqeNSySJI2Ybc2SJEmNMMMiSdKIufmhJElSI8ywSJI0YtawSJIkNcIMiyRJI7ZOEixmWCRJUvsMWCRJUvMMWCRJUvMMWCRJUvMsupUkacQW1knVrRkWSZLUPDMskiSNmAvHSZIkNcIMiyRJI7ZOEixmWCRJUvvMsEiSNGLWsEiSJDXCgEWSJDXPgEWSJDXPgEWSJDXPoltJkkZsgfVRdGvAIkmS5ioi3gQcDHw3M/eZcf/9gPcBl/eH3puZJ652TgMWSZJGrNHND98CvAZ42yrf8/HMfMT1PaE1LJIkaa4y8wLgR2t82xZFWmZYJEkasQ1NJliul9+JiM8D3wSemZlfWu2bzbBIkqShfQbYNTPvDpwKnL3WDxiwSJI0YgsLC4N+zUNm/jQzf97//znA1hFxy9V+xoBFkiSVsMAKdSoRsfPE/+8PLGTmD1c7mTUskiRpriLiTOD+wK0i4mvACcA2wGJmvgF4VET8MXAN8AvgsLXOacAiSZLmKjOPWOP+04DTtuScTglJkqTmmWGRJGnEGl04bu7MsEiSpOaZYZEkacRGvHDcFjHDIkmSmmeGRZKkEbOGRZIkqRFmWCRJGrF1kmAxwyJJktpnwCJJkppnwCJJkppnDYskSSO2YZ0UsZhhkSRJzTNgkSRJzXNKSJKkEVvAKSFJkqQmmGGRJGnE1knNrRkWSZLUPjMskiSNmG3NkiRJjTBgkSRJzTNgkSRJzbOGRZKkEVuwhkWSJKkNBiySJKl5TglJkjRi62RGyAyLJElqnxkWSZJGzKJbSZKkRphhkSRpxDasjwSLGRZJktQ+AxZJktQ8AxZJktQ8a1gkSRoxu4QkSZIaYYZFkqQRWycJFjMskiSpfQYskiSpeU4JSZI0YhvWyZyQGRZJktQ8MyySJI2Ybc2SJEmNMGCRJEnNM2CRJEnNs4ZFkqQRWyclLGZYJElS+8ywSJI0YnYJSZIkNcKARZIkNc8pIUmSRmydzAiZYZEkSe0zwyJJ0oi5+aEkSVIjDFgkSVLzDFgkSVLzrGGRJGnE1kkJixkWSZLUPjMskiSNmEvzS5IkNcIMiyRJI7ZOEixmWCRJUvsMWCRJUvOcEpIkacQsupUkSWqEAYskSWqeAYskSWqeNSySJI3YOilhMcMiSZLaZ4ZFkqQR27BOUixmWCRJUvPMsEiSNGLrJMFihkWSJLXPgEWSJDXPKSFJkkbMpfklSZIaYcAiSZKaZ8AiSZKaZw2LJEkjtk5KWMywSJKk9hXPsOxzh/stlh5j2nln/OXQQwLwhD95bZVxH3SXu1UZ909e87gq4177y18OPuaGrbcefEyAr3/kc1XGvfaa66qMu/2tbzL4mFtvv+3gYwLc5j77VRn3Z1+/ssq4Lz32XYOP+eD9dxt8zCUHnnjUYHkPu4QkSZIaYQ2LJEkjtk4SLGZYJElS+8ywSJI0YtawSJIkNcKARZIkNc+ARZIkNc+ARZIkNc+iW0mSRmyd1NyaYZEkSe0zwyJJ0ojZ1ixJktSINTMsEbEncAhw+/7QN4H3Z+aXSz4wSZK0tnWSYFk9wxIRxwHvABaAi/qvBeDtEfHs8g9PkiRp7QzLk4G9M/OayYMR8QrgEuDFpR6YJEla24YGUywR8SbgYOC7mbnPjPuPAI7rb14N/HFmXrzaOdeqYbkOuN2M47ft75MkSZr2FuCgVe6/HPj/MvO3gBOB09c64VoZlmOAf4iIS4Gv98d2BXYHjl7z4UqSpKIaTLCQmRdExB1Wuf9fJm7+C5vqZFe0asCSmedGxB7A/iwvuv1UZl679kOWJEla1ZHAOWt905pdQpl5HV30I0mSNDcRcSDwh8B91/peF46TJEmDi4h9gDcAD8nMH631/S4cJ0mSSljovzYTEbsC7wEen5lfvT4nM8MiSdKItbg0f0ScCdwfuFVEfA04AdgGWMzMNwDPB24JvDYiFoBrMnP/1c5pwCJJkuYqM49Y4/6nAE/ZknMasEiSNGINJliKsIZFkiQ1zwyLJEkjtrBhfaRYzLBIkqTmmWGRJGnErGGRJElqxMLi4mLtxyBJkv6Lzn/e6wf9ID/wxKOq5HTMsEiSpOYZsEiSpOZZdCtJ0oi1uDR/CWZYJElS88ywSJI0YuskwWKGRZIktc+ARZqjiNi19mOQtL4sLCwM+lWLAYuKi4h7134MAzq79gNQGQajv74i4ujaj0FrazpgiYjtI+LxEfGhgce9b0ScVvD8O0XEXjOO7xUROxUc96CIeNSM44+KiAeVGhd4bcFzzxQRz4iIJ884/uSIOKbg0FUuPyJiu1nPnf65tl2hMfeOiEdM3H5lRLy5/9q3xJj9OLX+tusmGK31AR4R+0XEQ2ccf1hE3LPg0E8qeO7iFhaG/aqluaLbiNgGeDhwBHAQ8B7grwcY9x79mI8GrgDeW3C41zD7Q/xWwPP6x1HC8cAjZxz/KPAB4P8UGreGxwGzMjtnAJ8GTik07u0j4tUr3ZmZf1po3FcD57L58/a+wIOBPy4w5ouBv5q4fRDwfOAmrPxcm4daf9tawejewJ0z8/397VcCO/Z3n5qZny0w7JOAUwucdy0vAf5wxvFLgLcADxj24aglzQQsEfFg4HC6N9fzgbcB+2XmrCfvvMbcox/zcOD7wDuBhcw8sNSYvd0z8+PTBzPzExHxuoLjbpuZ35sx7vcjYvuC494pIt6/0p2Z+YiV7rsBbpSZ18wY61cRUfKD5xfAZwqefyX3zMw/mj6YmWdFxImFxrxtZn5y4vZPMvM9ABFxVKExod7ftlYwWiswrGGHzLxy+mBmXhkRty447j4R8ZMZxxeAxcy8WcGxdT01E7DQXR1+ArhvZl4BEBGvKjzmV/oxD87My/oxjy08JsAOq9y3dcFxbxYRN8rM/zt5MCK2Bm5ccNzvAS8veP5ZNkTEzpn53cmDEbFz4XF/kJl/U3iMWW6yyn2lpn6XPY8zczLrcZtCY0K9v22tYLRGYFjrA/wWq9y32nP8hro4M+9R8Pyag5YCln2BxwIfiYjLgXcAWxUe89B+zPMj4tx+zCHSvpdFxMMy88OTB/u528sLjvte4PSIODozf9aPeVPgVZSdAvtpZn6s4PlnORn4UET8ObCUMr9nf/xlBce9bcFzr+aqiNg/My+aPBgR+9EFjCV8KyLulZkXTo15b+BbhcaEen/bWsFojcCw1gf4RyLiRcDzMnMRoM+avQD4xwqPRw1pJmDJzM8DnweeHREH0E3TbB0R5wBnZeYbCox5NnB2Px1yCHAMcJt+WuaszDxv3mP2jgU+GBGPYdMV228DvwMcXGhM6OpjTgSujIiltOuuwJvoUsyl/LDguWfKzLdFxPeAFwJ3BRbp5sGPz8xzCg79nYLnXs0zgXdFxFtZ/px6Al1QXsJxwDv7MScDhz8ADis0Zs2/7a8Knns1tQLDGv4ceCPdRd3n+2O/RVebdGTBcf+u4LnLWycrxy0sLg66K/WKImLXzPza1LENwP8AHpuZc6/iXmF65BZ0hbeHZeYD5z3mxDjb0hXX3rU/dAlwZmb+stSYE2PfGNi9v3lZZv6i8HifzcxiXSMrjHl0Zg5eNFjjd50Y+zbA01j+nDo1M68qPObRwN4TY542PV0z5zFr/W0fAtw0M989dfxRwI8zs0jRekTsT1df91ZmBIbTWbU5jfnczDxp3ufdgvHvxMRzKjNLZp6JiLsCdxq4sHluPvGCNw76Qf7fTziySoTUTIaFrmVw2Rt9Zl4HnNd/lXDRjDF/BLyh/yoiIs7LzAfTVb0PJiL+J11R8RnAxRPHHw9cm5lnDvl4CqvV5bBLjcLMvqX51pl5wtTxvSJicVax9RzHPH7GmNeVGLNX62/7fCp02WXmRX025WnAE/vDlwD3LhgY3jIijsrM108e7GtmdsvMZ5cYNCK2Am7cByiX97/3LhGxC/C5zLy6xLh0Rc2jLWxeL5sfthSw1PgXr/VXLrbWyhqeDszKGr0X+DhQKmCp0SVUS63CzBqt8rXa82up1WVHH5gcv+Y3zs+BdNOM004HvgAUCVjo2pqvAl7a3z6TLjjbji67dFyhcWt1vGkLtBSw1GgZ3CkinrHKmK8oMCbAjhFx6CrjliqA3TozfzpjvJ/1nUKl1OgSqtXlUKsws0arfK32/Fp/2ypddhFxCLBLZp7W376QTRc9x2VmifqLbZeKXidl5nWFW8cfCOw3cfvHmfm7/ZifKDhurY63uVgnCZamApYaV6ZbATdl+EzLjnTFtbPGXaRcx86NI2L7pQ6hJRGxA7BNoTGhTpdQrS6HWoWZNVrla7Xn1/rb1uqyexbLC6e3pftQ355uWrlEwPKLiLhLZl46eTAi7kL3Xl3KhqmA8DiAzFzs/61LWU+FzaPVUsBS48r025n5woHHBLiyRBHx9fAm4N0R8dSlxZki4o7Aaf19pVxR8NxNmboyAyAi7kw3PfLYzNx785+aixqt8rXa82up1WW3TWZ+feL2BZn5A+AHBaeijgfO6RcdnOw6ew5dN2Up20TEDku1KkudmhGxI920UClVOt7mZWHD+kixtBSw1LgyrfVXrjJuZr4sIn4KfHziauWnwIszs2QK/6yIeHxf7LtR4WLfkle8a4qI29G90R0B3I2uoK9UezHUaZWv1Z5fpQW1v/J/dkS8gKkuu8JTqssWU8vMyX1+itTDZeY5EfFIujqWp/eHvwj8fmZevPJP3mCn0wUOT13qGo2IOwCvo2t3LqIvbL4XXcfbE/vDpQubtYVaamsevGWwbxe81fTaDRHxMOC7mVlkiioi9qFbgvqfpo7fB/hOZn610LiHLtXH9NNAFKy6nxz3QuCB0/Uz/dXhxzNz7pua1Wovjog/oltD6PbAu/qv92XmbgOMPXirfKUxXwZcOnQHy4zHsUC3t80RdKtlF1lpNyL+FvhoZp4+dfwo4P6ZeXiBMU/KzOfO+7zXc+ynAs+lm/KCYS6qVnosv0GXGT156LG3xCdf9OZBP8gP+P+ftO7bmmu0DL6YOhttnUSXWp32E7qN23630LjPo888DBGoTKhV7FvDqcA/A0dk5qcBIqL4m0mNVvmI2B3YOTPfMnX8PhFRLPCmXgcLsLGu4Qi696tb0rUb/0XBIY+lW+DyCJZPV2xLuXbbh9AFDYPqL6r+GvjrIS+qph7DTnRrcR0O3A44a8jxtbKWApYaLYO1NtraeVZaNTMv7mtKft3UKPat1UlyW7o3u5dHxH+jy7AMEZTVaJU/hTqBd5UOlog4ie5v+zXg7XTLxX+6dO1dv/DfARHxADYtpvahzCy5VP1W/SKaM/89M7PU6tVVLqr696JD6QLRPfrHsFtm7jLUY9DaWgpYarQM1tpo6+ar3FdyE8I9I+ILM44vfYjvU2jcGsW+VTpJ+mLIpSvEXejqWL4bEV+m2+6h1FVrjVb5WoF3rQ6WI4F/o6un+EBm/ucQ2bMlfYDyj9BNp/YLQR6emQ8vMNyedHVJK3Uy3qnAmDVdRbeQ6PPoipoXI+L3Kj+m68225uHVaBmstdHWpyPiKTPmpI+kbGv3FZS76l1RxWLfqjLzG3Trz7y8/zAtWXRbo1W+VuBdq4PltsCD6KYKTomI8+myh5tdaJUQEdsAD6fLAhwEvIcuOC7hS5Vax2tdVD2H7vX5WuDtEfHOQuPoBmgpYKnRMrjaRltPKTQmdG+qZ0XE41j+hrsNUDKq/89ZU2BDWGleOiJ2LlSF38RmZtOFmcD/KjRUjVb5KoH3Ch0sl1C4gyUzrwXOBc7ti40PpgvMvhkR/5CZRVb2jYgH0wVJDwbOB94G7JeZs+rv5qVWN0ati6pT6ILQO9EFLmcDt4uI4+gyo/829GPaEi7NP7AaLYN9JufwGHijrf4D+oCIOJBN3RWl56RhmFqKVWXm1RFx84h4Mt2H+G/SFbbN2/sj4hFZaTOzCoWZNd6xagXeZOYX6dbI2CgitouIR2eZlV+nx/9PugzHe/ogvOTvey7dKq/3zcwrACLiVQXHgy6bVMOval1UAfTv/ScBJ0W3IeLhwIfZ9JmkipoJWJZkt3PwxUtXpn1l/MFAkZbBfszL6Re6iog7R8TzKbjIV0TsR7dp3Dl0V0xLxx8KXFWqnRoonrZeSXQ7RB9C9yF+D7pVUh9Jt4dRCVU2M6tVmAk8vvD5N1Mx8N4ous3yDmJTBuITFMquRbeNx48zc7ru6jGsvurvDbUv3VX/RyLicuAddKt0l/SdwudfyT+t/S3DyMwvRsS5rF7r2IR1kmBpL2CpcGVaY5GvlzC7nfpLlG2nrpLmjYgzgf9Ot+v2a+jqgy7LzI8WHPa2WWczs1qFmfeKiIcurRcREd+k+xBdAJ7ZT8kVkZnn0wfeAxSD0o9zP7rX68PoiiXvQ9fV8fNSYwKPAzZbyRg4g24a+ZQSg2bm54HP02WgD6ALzraOiHPopitK7Cy/oVKX0Esi4r6ZeQFsDBKX6t7OzMzLCo27UUTcg+659Wi6Kar3lB5T108zAUuNK9MZi3w9mW6RrxeUGrNXq526VkHbXsCPgC8DX87Mawf4EK+1mVmtwsyn0q2dseSqzLx9RGwH/D3lijOHLgYlIr5B9z7xOuAv+mnGKwoHKwA3ysxrpg9m5q9KtlNPjfVJ4JMR8Wd0GwU+FigRsNTqEnop8LcTt4+i+/1uQveZ8LgSg0bEHnSv2cOB7wPvBBYy88AS482bNSzDq3FlWmWRL+q1U9cqaLt7ROxJ92bwkYj4PrBDwYJbqLSZWa3CTLo31x9M3P67/vH8sp+Om7tKxaAA76bLwB4GXBsR72OY7OGGWc/ZiCg2Xb2K3eiyPbMyPvNQq0soMvODE7d/npkvB4iIkrs1f4VuOvHgpSxORBxbcDz9F7QUsNS4Mq21yFetdupqBW2Z+RXgBOCEiLgn3dX4pyLiG5l5QIEhq29mNnBh5rIW48w8CSAiNgClsnY1ikHJzGP6D5P7071fvJRuHZrHAB/OGasqz8nJwIci4s9Z/pw6GXhZoTE3GnjqulaX0PQGhw+c+P+S2edD6f4tz+/rVt5Bvb3mtIJmApYaV6YVF/larZ36yEJjQiMFbX1R8Wci4i/oaltKjHFRn015GgNuZtY/j+640hx8qXGB8yLixMx83tTxF9LVDpVQoxgUgD7QP5/uA2ZruumwpXU0inywZebbIuJ7dP+md6X7UL8EOD6n9iObp0pT17W6hK6OiD2W2oiXamX6DG2xlW8z82y67Q+2p2sOOAa4TUS8ju6zoNRrSFugmYAlJjbmm7oyvRnl9svYaMhFvmq1UwNXRMSTp7sc+hbjHfq1CIqLiL3o3oAfC/yYrhV27vrA5PgS517FyVSYg6dbk+SNEXEZ8K/9saJBcKVi0FmP4xq6/cY+UGr6CyC6RS1PBYoFJyuoMXVdq0voBLodwF/E8izWc4E/Kz14/958JnBmX3T8aLpsbdMByzopYWknYGFiD4lJmfkTurnx4mKgRb4i4iC6AOHd9O3U/fFiO1P3jqBClwNsXIp/qajtGuAOwG9n5r8XGu8QYJfMPK2/fSGb9ts5ruBaHVXm4FcIgr+U5TYgnB5/qGLQtf62z6KrcSnhSXTBw9BqTF1X6RLKzHOj22LiWcCf9oe/CBzar70ziIi4PV228FwG3FBUq2spYKmmQiv1SuuAfJRyO1NDpS6HiPhn4GZ0Uwa/n5mX9l0d/15qTLo3vMks2bbAfnRb1r+FcivhVpmDrxgETytdDApr/21LBSxVVJq6rtIlFBEn9b/PE0qcf5Vxn0O3q/wL+0P/TJf93Rp4K/DiIR+PZmspYBm85bbiIl81dqaGel0O36Wbf9+Z7kr4UsoX9W2TmV+fuH1B/8b/g8L/xlXm4KkXBNdYx6jW37bWDuAbzZi6PrzQULW6hB5CN/0ztEezvJ7uB5l5j+gWJvwYjQcstjUPr0bLba1FvmrsTA2Vuhwy85ERsSNdJf5f9m+0N4+I/TPzokLDLmsdz8yjJ27uRDm15uAHD4IrrmNU629bZQfw6BbiW8jMM6buujdQaiG1Wl1CW9WYiurP/bOJm6/qj11bsi5KW6algKVGy22tRb5q7ExdrcuhH/vHdOn6t0TEbeiuyF8ZEbtm5m8UGPLCmL0x31F0K6MWUXEOvkYQXGsdoyp/24qezvKpxSXvpdvaokT3Wa0uoVoL1t00IrZemjLPzLcC9B2rxTNnN9iG2g9gGC0FLCu23M6axpiHiot8Te9MvQD8BmV3pga6nW6Z0eUQEftl5qdKjj3xGK4CXhMRb2TTbrvzdixdm+IRLM90bEvBrrNac/DUCYJrrWNU5W/LKnVPhV8/W89aWyYzfxaFNoalXpdQramodwOv718/P4dumwm6oPzXqiZqzJoJWKbSukTEzYHfp+yOvpPjTy/yVeyNL1fZmbrUmLNMtBcfDvwHhdqLp8ac3KzuQcAFJcbpg6IDIuIBbOqaGWJjvlpz8NNBMMCuFAyCa61jVOtvu7QY35IBXz83jojtp6Ys6N+ntik0Zq29hGp5PvAi4GtDX0TOw3qpYVlYXKw1Vbm5WGVH38y8boDxlwVJmVkkSOrXltk5My/tbz+aTWn7vy+8sNkdGbC9eGLcWZvV3SnL7/8y+Ri2p1tt9vAstDFfRPwr3QqsVd7o+9fQsiB4MtU9hKVi0ImOi9LjLbWgAnyr5HRujddPdAssPhB46tK0ef84TgM+mv2Gl3Me8z+Bb7LC1ExmluoS+hPg76brsSJiJ+DqzPxliXEnxtns9VNyvHn5zCveNugH+T2f8YQqEVIzGZaos6PvqkFSwWFfBnySrlsGuq6Kc+iClgPoNrKbu0rtxTU3qxt8Yz7qzcED0L/BXry0plA/bXIwXYfWXK0ReL9+3uNNjDvdgvpJuhbUbYC/oXs9lRi3yusnM18WET8FPt5P8wH8FHhxZr6u0LC1pmbuTjcdNT2NeV+6Pav+uMSgU8/li/vn8j0iAgpfROr6ayZgocKOvrWCJLo1I46auH11Zj69f0xFpkh6NdqLocJmdVFvY75ab/TA4GsKVQm82bwF9YdTLahFAhYqvX6iWwV8aeptB4DMLNkiD/W6hO4Aijc/AAAV8UlEQVSZmX80fTAzz4qIEwuOW+u5rC3QTG1xZt4deAxdhuMj/Qf3DoXXCNksSGKYF+qNst/0sPf4if+/+fQ3z0tmPpJunYzP0LUXXwHcIiL2LzVmP+4xdAuKvZxuuiSBnSLiMRNXjPN2Ll02476Z+T8z8wNA8WlFKr3RR8RJEXEp3Tz8F+iyhd/LzL/JzB8VGnY/uozGkqsz8+mZeSRdF1oxK7WgUnBZgFqvH7r6pKXHcPUAwQrU6xJabbf6kp9X1Z7L87CwMOxXLc0ELNDt6JuZJ2TmnnRrVryNbkffTxYar0aQBHBd31Wx9Di+CBvn4ot+qGbmjzPzLZn5YOBedAVlr4yIr6/xozd03MXMPL+/etqNLvtxCPDvhYbcl67l9iMR8X+i2y9piI35ar3RH0mXAXgdcEZfEFs6eKoSeNO3oC7dGLIFtdbrp4JaXUJXzQoAI2I/YLN1huao1nNZW6ClKaFlcoAdfftxvkK32NcJEXFPug/ST0XENzLzgELDnky3UdufA5/rj+1Ll5acewHdkojYjm759u/Bxm6LUyPiXcCtCo771sx84tLtvgD0g3QLrBW5Is56G/PVeqOvsabQdRHx3zLzOzBo4F2lBbXW64cKq4BTr0vomcC7IuKtdJks6LqvnkDZ1ZNrPZe1BZoNWGKAHX1j0+6rwLIg6ZmUDZL+d0R8n64NdW+GW8Dt1XRTJdMFbfehYEEbsOIb6hBV+Ln5xnyHU2hjPuptGldjTaEqgTf1WlBrvX5qrAJepXg8My/qMyxPA57YH74EuFcfIJZS67k8F7Y1VzB0y2BEfDYz9y1x7hZFxGcy854r3HdJZu496745jPsVur/pSh/in511/AaOuRVw4+wX3OqLUZfWrPhcqTqAWu2gqzyeHYDfy8wiO55HxNK6M0vPnS/Sda8UXTm5H3vQFtSKr5/PDV3IXWPMftxl2diBx672XL6hPnfKGYN+kN/jmMev+7bmKi2DNUTEyXRvsK+fOn4UsFtmPrvQ0LUK2m5PV3C70tXaAwqM+RLgKuCl/e23070BbUd35Vjq37hKl1BEPINuV+Y3Td21VKNVRGaeS5d1GEzFFtRar58VVwH/NVRieut6qfFcnpd1kmBpJ2ChTstgrd1XH0C318y00+k6PEp9mF4VMzYcHKCg7bLMLBGUrOaBdJX/S/4jM3+3X5/kEwM/liE8jm4zvGlnAJ8GTpn3gBGxN3DnzHx/f/uVwI793aeWyJz1arWg1nr9XBERT54ORvtC8h0yc+5/W/rOqwpuEhH3YMBsLFR9LmsLNBOwZJ0dfavsvkq3s+5mwVhmXtd/oJZSq6Ctxrzjhqli0+Og61Yq2EoN3X4+O+XwK3XeKGesZpuZvyr4nHoxy9c8OYiuhuQmwPGU296i1jpGtV4/RzBwMAp8NSKesDSVGBHvplvXB+DELLcNQo1sLNR7Ls/HOkmxNBOwwMwdfR9D2R19a/lFRNylT2lv1AdpxebhKxa0lW4Tn2WbiNhhqVYlM88D6IPi7QqOW2WlTrpi3802CS3con/bvqB5yU8y8z39uEet8DPzUGsdo1qvnxrB6F+yfGPSoPudt6er8ygVsNTIxkK957K2QDMBS6WWwVK72K7leOCcfuXGySu15wDHlBq0v8q/dWaeMHV8r4hYnM4KzFHJN/OVnA68MyKemplfA4iIO9CtU/LGguPWWqnzZOBDfZfD5A7GJ9NNoZSwrDYmMyezALcpNCZUakGt+PqpEYzeLDO/NHH70r6LkogotZJwTbWey9oCzQQs1GkZ/D3gfxU476oy85yIeCRdinnpKuYSumLjiwsO/RrgtTOO34puNc0Sra8A2w09L52Zr4iInwMX9Gt0LABXU3b/FahUmJmZb4uI7wEvpFuZc4hW+W9FxL0y88LJg31H1rcKjQn1WlBrvX5qBKPLMlWZeejEzZKB0l9FxF5TwdLSMhffKxgU1nouawu0FLDUujKtor8q/IPJYxGxXUQ8OjP/rtCwu2fmZps6ZuYnIqLkh/guVJiXzuH3X4F6hZn0gclmwUlE7JeZnyow5HF0Way3svyD9A/o9o0qouI6RlVePzOCUeg63kr+vl+JiIdn5ocmD0bEwXRba5RyKLMXXywdFFZ5Ls/LwgZrWIZW48q0VpfQRv16IQexaaO+TwClApbV2lu3XuW+G2rweemI2AW4Y2ZekN3u0M+YKLY9MzMvKzR0rcLMZWLTwouHA/9BgYUX+5qOewFHs7ym494FW4uXxp7ZglowOIN6r58Vg9GCnkG3EvWjWP4BfgDdooSl1AoKqz2Xdf21FLDUuDKt1SVERNyP7mrhYcBFdFNfu2W/1Hghl0XEwzLzw1OP5aHA5QXHreFk4G8nbh9Ft7rtTYAX0LUBz93EG9+fMGxh5uALL8LGWrPjpx7Hb0TEMzNzkBVChwjOelVePzVabrNbB2sfutfJ0kJqHweeWrDTDSoFhRML1h2/1ve2aJ00CTUVsDRxZTqEiPgG8DW6AtC/6DMAVxQOVgCOpbtqegzL/41/h7JXTTXmpSMzPzhx++eZ+fJ+3KLrsPRXZCes+Y1zFJUXXuwLUh9NFzTcDjir8Hh3ZODgjHqvn8FbbiPivOw2eHzzvM+9hloXVdUWrNP110zAUqllsNTUy1reTfcmcxhwbUS8jwHWKsnMf4uIu9Fldpbmwj8GHFX4qqnGvPR06/IDJ/7/1gXGAyAiDgF2yczT+tsX0i2ECHBcwfqkwRde7GuDDqX7++1BVzC/W2buUnjcKsFZxddPjZbbndb+liJqBYVVFqzTlmkmYIGN6eXplsGS6eX3R8Qjhky1AmTmMRFxLHB/uivElwI79i/SD2e//828TVw1vaXE+VdRY1766ojYIzP/rR/rhwARsSddt1Apz2J5RnBbuoXOtqf7dy8SsGSdhRevopvOfB5wQXaL8v1eobEm1VgVu+brp0bL7Y4RcehKd2ZmkSUhKgaFtRasm4v1svlhUwHLkgHTy39FpdUNs1v46nzg/IjYGngI3QfdaymXAah11VRjXvoEuiu1F7G8aPC5wJ8VGhNgm8z8+sTtCzLzB8AP+vbqYnL4hRefw6bn7Nsj4p0FxthMpeAM6r1+arTc7kiX0VjpA7xIwFIxKKy1YJ22QDMBS6X0co1U62ayW8XyAxHxr5RtGaxy1USFeenMPLf/XZ8F/Gl/+BLg0L6lvJRbTD2OoyduFvvAiwoLL2a3h80pEXEnusDlbOB2EXEccNZSdqvQ2NPB2WGUXxW71uunRsvtlZn5pELnXk2toHDU1kmCpZ2AhTrp5eqrGw5crFjlqolu9d4PDT0v3QcmTyh1/hVcGBFPyczTJw/2AXDJq/8aCy8CkJmXAycBJ0XEXemeyx8Gdi815tT4VwGviYg3snw5+Xmr8vqp1HI78yMwIu4LHJ6ZTys0bs2gUI1rKWCpkV6usrphrWJF6l01LQJPAu7C8nnp04FrSwzYv7HeKYffvO1Y4OyIOILlV8PbUnYDtSYWXszML0bEuUxlmkqZWsfoQUDJzQ9rvX5qtI9v3J+pL0Y9gu7C6grKbmlS66LqxhHxtBWK5Z+Vme8uNK62QDMByyrp5WcBZxdKL6+Uan0i3fx/KbWKFSMi7pOZ/zR18D7AdzLzq4XGPQV4TmYum5fui+tOAX63wJgvoM7mbedm5r4R8UBgr/7YhwoGSEuqbAmwZMaH2nsKjzdrHaM7FV4aoNbrZ3KsoTKyv4qIE/pxvg+8E1jIzAMLjbekVlC4VrG8AUsDmglYImJ3YOf+zWApvXw34FV0hbFbzXvMGanWpSW+9y+8yFeVYkXgQmDWyr4/oVzgAN3fdbM9kjLz4n49jRJqbd62AJCZ/wD8Q8Fxpg2+8GJE7MGmtVAG+1CruI5RlddPpYzsV+hW3T44+1Wh+87G0moFhdWK5edinRSxNBOw0F+FTx7oP9COoQtg5m5izYzj+9sX0WVYHh8RxdKAlbJJ0BVlDh04wNRGalNuPMSYOdzmbTtFxDNWujMzX1Fo3JUWXixZmFnrQ63KOkbUe/3UyMgeSvfedH4/xfcOVqhrmbNaF1VViuW1ZYqnirfASlfhX6BbxbKEZwHvn7i9DV3Acn8KFilGxO79VcTlmXlSZt6NLv34EODLpcZl9bqCUoEDwKcj4inTByPiSDZ9uM7bVyLi4TPGLL1521bATekKumd9FdFnVvan+1B5Ips21txvukZrjg4Fvk33oXZ6Pw1W/EMtM48BdqNbN+P+dH/P20TEYbFpv6gSar1+nkM3RfFa4DkRceeCYwGQmWdn5mOBPemWXziG7t/4dRHx4IJDrxgUAncsOO6FK7xHlS6Wn4uFDQuDftXSUoalxlX4rDTgD4EfFk4DDp5N6n1qhQ6WkoEDdG92Z0XE41h+9b8NUOpK8Vi6zqShN2/7dma+sOD5Z5rIFp7Q3x4iW/jBzDy7f60cwsSHGl1b83kFxgRmrmO0VHh7GuXWMary+qmYkSUzfwacCZwZEbegq585Dij1t60VFNYqltcWaClg+XSFN4NaacAVs0kRUSqbBHUCh6W9dQ6IiAPZ1CVUtBA1My+L5Zu3LdJ1Jr2ZbuG4Um2ZtS4/posGl7KFN6Vc0eBFwL5Df6jF1PYHdJ1BS8sQlJySqvL6qVHfN0tm/ohuA9E3FBym1kVVrWL5uVgnJSxNBSw13gxqrZlRI5tUJXCYGv98uqviQWTmfwJvjoh96a6+T6B8B8sD1/6WImpkCzd7mxzoQ21WR8dvs6mj44wSg1Z8/dTKyNZQJSikXrG8tkAzAUulN4NaacAa2aSNhg4caqjVwdIHCTXUyBbWKjCu2tFR4fVTKyM7uIpBYa3nsrZAMwHLkiHfDPrW5QMi4gF00wYwzIuj1lXEelKrg6WWGtnCpQLjoRPS662jo0pGtqYKQWGt5/J8rJM5oeYClhr6AGWwucraUzPrRK22zFpqZAurFBhTbyq3lqoZ2XWi1nNZW8CApaL1MDVTS2aeTfcBPngHSw2VsoW1AsD11tFhRra8X+eLmV8bC4uLQ6y3JNU30cFyWGbWKo79tRERt6xYs8NUcHbJr3uGcioj+2v/+w6p9nP5hvrSG9856Af5XkceViXAM2CRJGnEvvymYQOW33xynYClpZVuJUmSZrKGRZKkEau5XP6QzLBIkqTmmWGRJGnEFtbJOixmWCRJUvMMWCRJUvOcEpIkaczWx4yQGRZJktQ+AxZJktQ8p4QkSdJcRcRDgFPoEiNvysyXTN1/c+DNwJ2BXwBPyswvrXZOMyySJI3YwsLCoF9riYgNwKnAQXT7fR0eEXtOfdtzgc9l5m8BfwC8eq3zGrBIkqR52h+4NDOvzMxrgHcAh0x9z17APwJkZgJ3jIidVjupAYskSSPWWoYFuD3w9Ynb3+iPTfpX4FCAiNgf2BXYZbWTGrBIkqShvRi4RUR8Fnga8Dng2tV+wKJbSZLGrL3UwzfpMiZLdumPbZSZVwNPWrodEVcAl692UgMWSZI0T58Cdo+IOwDfBh4LHD75DRGxI/DzzLwmIp4CfCwzf7raSQ1YJEkasdY2P8zMayPiaOA8NrU1fzkijgIWM/MNwG8CfxMR1wGXAE9e67wLi4uLJR+3JEkq6LIz3zvoB/nuRxxaJUJqb+ZLkiRpigGLJElqngGLJElqnkW3kiSNWGtFt6WYYZEkSc0zwyJJ0pitjwSLGRZJktQ+MyySJI3Ywob1kWIxwyJJkppnhkWSpDGzS0iSJKkNBiySJKl5BiySJKl5BiySJKl5Ft1KkjRi66Tm1gyLJElqnxkWSZJGzM0PJUmSGmGGRZKkMXNpfkmSpDaYYZEkacSsYZEkSWqEAYskSWqeAYskSWqeAYskSWqeRbeSJI3Z+qi5NcMiSZLaZ4ZFkqQRs61ZkiSpEWZYJEkasQWX5pckSWqDGRZJksbMGhZJkqQ2mGGRJGnE7BKSJElqhAGLJElqngGLJElqngGLJElqnkW3kiSN2fqouTXDIkmS2meGRZKkEXNpfkmSpEaYYZEkacxcOE6SJKkNZlgkSRoxl+aXJElqhAGLJElqngGLJElqngGLJElqnkW3kiSNmQvHSZIktcEMiyRJI2ZbsyRJUiPMsEiSNGbrI8FihkWSJLXPDIskSSNmDYskSVIjDFgkSVLzDFgkSVLzrGGRJGnMXOlWkiSpDQYskiSpeU4JSZI0YrY1S5IkNcIMiyRJY2aGRZIkqQ1mWCRJGjFrWCRJkhphwCJJkppnwCJJkppnDYskSWPm0vySJEltMGCRJEnNc0pIkqQRs61ZkiSpEWZYJEkaMzMskiRJbTDDIknSiC3Y1ixJktQGAxZJktQ8AxZJktQ8a1gkSRozu4QkSZLaYIZFkqQRc6VbSZKkRhiwSJKk5jklJEnSmDklJEmS1AYzLJIkjZhL80uSJDXCgEWSJDXPgEWSJDXPGhZJksbMLiFJkqQ2mGGRJGnMGsywRMRDgFPoEiNvysyXzPie+wOvBLYGvpeZB652TjMskiRpbiJiA3AqcBCwN3B4ROw59T07AqcBB2fmXYFHr3VeAxZJkjRP+wOXZuaVmXkN8A7gkKnvOQJ4T2Z+EyAzv7/WSZ0SkiRpxBrcrfn2wNcnbn+DLoiZtAewdUScD9wUeHVmnrHaSc2wSJKkod0I2Bd4KPAQ4PkRsftaPyBJksaqvaX5vwnsOnF7l/7YpG8A38/MXwK/jIiPA78FXLbSSQ1YJEnSPH0K2D0i7gB8G3gscPjU97wPeE1EbAVsC9wLeMVqJ3VKSJIkzU1mXgscDZwHXAK8IzO/HBFHRcQf9d/zFeDvgS8A/wK8ITO/tNp5FxYXF8s+ckmSVMyPLvnsoB/kt9h73ypzUE4JSZI0YgsL62OyZH38lpIkadTMsEiSNGbtrcNShBkWSZLUPDMskiSNWIMr3RZhhkWSJDXPgEWSJDXPKSFJksasvaX5izDDIkmSmmfAIkmSmmfAIkmSmmcNiyRJI2ZbsyRJUiPMsEiSNGZmWCRJktpghkWSpDFbWB+5h/XxW0qSpFEzYJEkSc1zSkiSpBFbcGl+SZKkNhiwSJKk5hmwSJKk5lnDIknSmLlwnCRJUhvMsEiSNGJufihJktQIMyySJI2ZS/NLkiS1wQyLJEkj5kq3kiRJjTBgkSRJzTNgkSRJzTNgkSRJzbPoVpKkMXPhOEmSpDaYYZEkacRcml+SJKkRZlgkSRozl+aXJElqgxkWSZLGzKX5JUmS2mDAIkmSmmfAIkmSmmfAIkmSmmfRrSRJI+bCcZIkSY0wwyJJ0pi5cJwkSVIbzLBIkjRi1rBIkiQ1wgyLJEljZg2LJElSGwxYJElS8wxYJElS8wxYJElS8yy6lSRpxBY22NYsSZLUBDMskiSNmQvHSZIktcEMiyRJI7bgwnGSJEltMMMiSdKYWcMiSZLUhoXFxcXaj0GSJGlVZlgkSVLzDFgkSVLzDFgkSVLzDFgkSVLzDFgkSVLzDFgkSVLz/h/RaCY7o9mp4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efae8e51198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "\n",
    "sns.heatmap(summed_attention.T,\n",
    "            square = True,\n",
    "            xticklabels=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
